{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Classification\n",
    "\n",
    "In this notebook we are going to explore the use of Neural Networks for image classification. We are going to use a dataset of small images of clothes and accessories, the Fashion MNIST. You can find more information regarding the dataset here: https://pravarmahajan.github.io/fashion/\n",
    "\n",
    "Each instance in the dataset consist of an image, in a format similar to the digit images you have seen in the previous homework, and a label. The labels correspond to the type of clothing, as follows:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a function to load the data, that we are going to use later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset from disk\n",
    "def load_fashion_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 0\n",
    "Place your ID (\"numero di matricola\") that will be used as seed for random generator. Change the ID number in case you observe unexpected behaviours and want to test if this is due to randomization (e.g., train/test split). If you change the ID number explain why you have change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1231829# COMPLETE\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the dataset using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the fashion MNIST dataset and normalize the features so that each value is in [0,1]\n",
    "X, y = load_fashion_mnist(\"data\")\n",
    "# rescale the data\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training and test. Make sure that each label is present at least 10 times\n",
    "in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [54 51 50 49 48 74 45 44 42 43]\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rest as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 500\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function plots an image and the corresponding label, to be used to inspect the data when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the function above and check few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 7\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,10)\n",
    "plot_input(X_test,y_test,50)\n",
    "plot_input(X_test,y_test,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "\n",
    "Now use a (feed-forward) Neural Network for prediction. Use the multi-layer perceptron (MLP) classifier MLPClassifier(...) in scikit-learn, with the following parameters: max_iter=300, alpha=1e-4, solver='sgd', tol=1e-4, learning_rate_init=.1, random_state=ID (this last parameter ensures the run is the same even if you run it more than once). The alpha parameter is the regularization parameter for L2 regularization that is used by the MLP in sklearn.\n",
    "\n",
    "Then, using the default activation function, pick four or five architectures to consider, with different numbers of hidden layers and different sizes. It is not necessary to create huge neural networks, you can limit to 3 layers and, for each layer, its maximum size can be of 100. You can evaluate the architectures you chose using the GridSearchCV with a 5-fold cross-validation, and use the results to pick the best architecture. The code below provides some architectures you can use, but you can choose other ones if you prefer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "Score with best parameters:\n",
      "0.686\n",
      "\n",
      "All scores on the grid:\n",
      "[0.544 0.622 0.312 0.632 0.658 0.686 0.34  0.608]\n",
      "[0.52427184 0.78640777 0.58252427 0.75728155 0.78640777 0.82524272\n",
      " 0.29126214 0.74757282]\n",
      "[0.80392157 0.78431373 0.21568627 0.7745098  0.78431373 0.80392157\n",
      " 0.57843137 0.58823529]\n",
      "[0.74257426 0.74257426 0.34653465 0.8019802  0.78217822 0.8019802\n",
      " 0.56435644 0.8019802 ]\n",
      "[0.2020202  0.29292929 0.1010101  0.1010101  0.26262626 0.31313131\n",
      " 0.1010101  0.32323232]\n",
      "[0.43157895 0.48421053 0.30526316 0.71578947 0.66315789 0.67368421\n",
      " 0.14736842 0.56842105]\n"
     ]
    }
   ],
   "source": [
    "#MLPclassifier requires in input the parameter hidden_layer_sizes, that is a tuple specifying the number of \n",
    "#neurons in the hidden layers; for example: (10,) means that there is only 1 hidden layer with 10 neurons; \n",
    "#(10,50) means that there are 2 hidden layers, the first with 10 neurons, the second with 50 neurons\n",
    "\n",
    "#these are examples of possible architectures you can test, but feel free to use different architectures! \n",
    "hl_parameters = {'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,), (80, 80), (100, 100), (10, 10, 10), (50, 50, 50)]}\n",
    "\n",
    "mlp_cv = MLPClassifier(max_iter = 300, alpha = 1e-4, solver = 'sgd', learning_rate_init = .1, random_state = ID)#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "#ADD YOUR CODE\n",
    "grid_cv = GridSearchCV(mlp_cv, hl_parameters, cv = 5)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "best_architecture = grid_cv.best_params_['hidden_layer_sizes']\n",
    "print(best_architecture)\n",
    "\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "best_score = grid_cv.best_score_\n",
    "print(best_score)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "#ADD YOUR CODE\n",
    "grid_score = grid_cv.cv_results_\n",
    "print(grid_score['mean_test_score'])\n",
    "\n",
    "#Printing the results for each k fold\n",
    "print(grid_score['split0_test_score'])\n",
    "print(grid_score['split1_test_score'])\n",
    "print(grid_score['split2_test_score'])\n",
    "print(grid_score['split3_test_score'])\n",
    "print(grid_score['split4_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "\n",
    "What do you observe for different architectures and their scores? How do the number of layers and their sizes affect the performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "I noticed that architectures with only 2 hidden layers are the ones who give the best score in the training set. In the first time I ran the classifier with the default hl_params, the best one was the architecture (50,50). So I added the architecture (80, 80) in the list and this one was the better one. So at the last trial I added architecture (100, 100) and I noticed again that the new architecture gives the best result. \n",
    "I've added also architectures with 3 layers, but the results were lower than the architecture with hidden 2 layers.\n",
    "\n",
    "On the other hand adding more nodes on the architecture and also more layers the performances is getting worse. Since the 3 hidden layers architectures give worse performances than 2 hidden layer architectures and their computational power is higher, there's no point using the 3 hidden layer architectutes. \n",
    "\n",
    "For the 2 hidden layer architecture there's a tradeoff to consider. If we need the highest score, we should consider the (100, 100) architecture despite the computational power. On the other hand, if we don't need the highest accuracy, we can use the (50, 50) architecture which requires lower computational power but gives an accetable score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now get training and test error (according to the initial split) for a NN with best parameters chosen from the cross-validation above (and learning the NN weights from the entire training set). Use verbose=True\n",
    "in input so to see how loss changes in iterations. (Note that the loss used by the MLPclassifier may be different from the 0-1 loss, also called *accuracy*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.20821500\n",
      "Iteration 2, loss = 1.55407174\n",
      "Iteration 3, loss = 1.57807665\n",
      "Iteration 4, loss = 1.15298773\n",
      "Iteration 5, loss = 0.80653980\n",
      "Iteration 6, loss = 0.76662858\n",
      "Iteration 7, loss = 0.75271795\n",
      "Iteration 8, loss = 0.66164988\n",
      "Iteration 9, loss = 0.58968409\n",
      "Iteration 10, loss = 0.50350103\n",
      "Iteration 11, loss = 0.45897501\n",
      "Iteration 12, loss = 0.50550794\n",
      "Iteration 13, loss = 0.49887294\n",
      "Iteration 14, loss = 0.42395595\n",
      "Iteration 15, loss = 0.34179380\n",
      "Iteration 16, loss = 0.31065713\n",
      "Iteration 17, loss = 0.30252146\n",
      "Iteration 18, loss = 0.32393189\n",
      "Iteration 19, loss = 0.46486932\n",
      "Iteration 20, loss = 0.29760487\n",
      "Iteration 21, loss = 0.27012411\n",
      "Iteration 22, loss = 0.25725823\n",
      "Iteration 23, loss = 0.20284936\n",
      "Iteration 24, loss = 0.18026086\n",
      "Iteration 25, loss = 0.15953658\n",
      "Iteration 26, loss = 0.16353775\n",
      "Iteration 27, loss = 0.14333420\n",
      "Iteration 28, loss = 0.20214512\n",
      "Iteration 29, loss = 0.19937797\n",
      "Iteration 30, loss = 0.15397035\n",
      "Iteration 31, loss = 0.10670361\n",
      "Iteration 32, loss = 0.12486375\n",
      "Iteration 33, loss = 0.12053480\n",
      "Iteration 34, loss = 0.11013353\n",
      "Iteration 35, loss = 0.08355476\n",
      "Iteration 36, loss = 0.05544915\n",
      "Iteration 37, loss = 0.33640661\n",
      "Iteration 38, loss = 0.82339177\n",
      "Iteration 39, loss = 0.38447914\n",
      "Iteration 40, loss = 0.27340846\n",
      "Iteration 41, loss = 0.25452198\n",
      "Iteration 42, loss = 0.26054626\n",
      "Iteration 43, loss = 0.24358877\n",
      "Iteration 44, loss = 0.16734195\n",
      "Iteration 45, loss = 0.15237676\n",
      "Iteration 46, loss = 0.13688263\n",
      "Iteration 47, loss = 0.16317110\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "RESULTS FOR BEST NN\n",
      "\n",
      "Best NN training error: 0.128000\n",
      "Best NN test error: 0.286420\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best NN model from CV\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = best_architecture, max_iter = 300, alpha = 1e-4, solver = 'sgd', learning_rate_init = .1, random_state = ID, verbose = True).fit(X_train, y_train)#ADD YOUR CODE\n",
    "\n",
    "training_error = 1. - mlp.score(X_train, y_train)#ADD YOUR CODE\n",
    "\n",
    "test_error = 1. - mlp.score(X_test, y_test)#ADD YOUR CODE\n",
    "\n",
    "print ('\\nRESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (\"Best NN training error: %f\" % training_error)\n",
    "print (\"Best NN test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data \n",
    "Now let's do the same but using 10000 (or less if it takes too long on your machine) data points for training. Use the same NN architectures as before, but you can try more if you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([ 980, 1030, 1010,  946,  969, 1013, 1044, 1032,  978,  998]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 10000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "\n",
    "Now train the NNs with the added data points. Feel free to try more different architectures than before if you want, or less if it takes too much time. You can use 'verbose=True' so have an idea of how long it takes to run 1 iteration (eventually reduce also the number of iterations to 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n",
      "Iteration 1, loss = 1.27469498\n",
      "Iteration 2, loss = 0.66108634\n",
      "Iteration 3, loss = 0.58633187\n",
      "Iteration 4, loss = 0.53254321\n",
      "Iteration 5, loss = 0.51804278\n",
      "Iteration 6, loss = 0.48353103\n",
      "Iteration 7, loss = 0.46969248\n",
      "Iteration 8, loss = 0.46283424\n",
      "Iteration 9, loss = 0.43830998\n",
      "Iteration 10, loss = 0.44653920\n",
      "Iteration 11, loss = 0.43788304\n",
      "Iteration 12, loss = 0.41929495\n",
      "Iteration 13, loss = 0.41568015\n",
      "Iteration 14, loss = 0.41642666\n",
      "Iteration 15, loss = 0.41134138\n",
      "Iteration 16, loss = 0.38485696\n",
      "Iteration 17, loss = 0.38964334\n",
      "Iteration 18, loss = 0.39015403\n",
      "Iteration 19, loss = 0.39677252\n",
      "Iteration 20, loss = 0.37516510\n",
      "Iteration 21, loss = 0.38100861\n",
      "Iteration 22, loss = 0.36910006\n",
      "Iteration 23, loss = 0.36687819\n",
      "Iteration 24, loss = 0.36674977\n",
      "Iteration 25, loss = 0.35150316\n",
      "Iteration 26, loss = 0.34980951\n",
      "Iteration 27, loss = 0.35272414\n",
      "Iteration 28, loss = 0.35134913\n",
      "Iteration 29, loss = 0.33708182\n",
      "Iteration 30, loss = 0.34643631\n",
      "Iteration 31, loss = 0.33716598\n",
      "Iteration 32, loss = 0.34026816\n",
      "Iteration 33, loss = 0.33460734\n",
      "Iteration 34, loss = 0.33403980\n",
      "Iteration 35, loss = 0.33329271\n",
      "Iteration 36, loss = 0.31971322\n",
      "Iteration 37, loss = 0.32539685\n",
      "Iteration 38, loss = 0.31492697\n",
      "Iteration 39, loss = 0.31555377\n",
      "Iteration 40, loss = 0.31476527\n",
      "Iteration 41, loss = 0.31675478\n",
      "Iteration 42, loss = 0.31993102\n",
      "Iteration 43, loss = 0.31937281\n",
      "Iteration 44, loss = 0.32665422\n",
      "Iteration 45, loss = 0.31324788\n",
      "Iteration 46, loss = 0.30597802\n",
      "Iteration 47, loss = 0.31272627\n",
      "Iteration 48, loss = 0.30360327\n",
      "Iteration 49, loss = 0.29712913\n",
      "Iteration 50, loss = 0.29795370\n",
      "Iteration 51, loss = 0.30774544\n",
      "Iteration 52, loss = 0.30346249\n",
      "Iteration 53, loss = 0.28742378\n",
      "Iteration 54, loss = 0.28905093\n",
      "Iteration 55, loss = 0.28689469\n",
      "Iteration 56, loss = 0.28810592\n",
      "Iteration 57, loss = 0.30595372\n",
      "Iteration 58, loss = 0.29213163\n",
      "Iteration 59, loss = 0.27108486\n",
      "Iteration 60, loss = 0.28852639\n",
      "Iteration 61, loss = 0.28548176\n",
      "Iteration 62, loss = 0.27461105\n",
      "Iteration 63, loss = 0.29154838\n",
      "Iteration 64, loss = 0.27665452\n",
      "Iteration 65, loss = 0.27360082\n",
      "Iteration 66, loss = 0.27449572\n",
      "Iteration 67, loss = 0.27753559\n",
      "Iteration 68, loss = 0.26948245\n",
      "Iteration 69, loss = 0.30217894\n",
      "Iteration 70, loss = 0.27462887\n",
      "Iteration 71, loss = 0.26941579\n",
      "Iteration 72, loss = 0.26938777\n",
      "Iteration 73, loss = 0.27106986\n",
      "Iteration 74, loss = 0.26408769\n",
      "Iteration 75, loss = 0.27392205\n",
      "Iteration 76, loss = 0.26527595\n",
      "Iteration 77, loss = 0.27010992\n",
      "Iteration 78, loss = 0.26668505\n",
      "Iteration 79, loss = 0.26458032\n",
      "Iteration 80, loss = 0.27042109\n",
      "Iteration 81, loss = 0.26174447\n",
      "Iteration 82, loss = 0.26396280\n",
      "Iteration 83, loss = 0.25948938\n",
      "Iteration 84, loss = 0.26620219\n",
      "Iteration 85, loss = 0.25398697\n",
      "Iteration 86, loss = 0.26718431\n",
      "Iteration 87, loss = 0.26095941\n",
      "Iteration 88, loss = 0.25249916\n",
      "Iteration 89, loss = 0.24146572\n",
      "Iteration 90, loss = 0.26394733\n",
      "Iteration 91, loss = 0.25766007\n",
      "Iteration 92, loss = 0.24351538\n",
      "Iteration 93, loss = 0.24243948\n",
      "Iteration 94, loss = 0.24137081\n",
      "Iteration 95, loss = 0.23738742\n",
      "Iteration 96, loss = 0.25001526\n",
      "Iteration 97, loss = 0.23893539\n",
      "Iteration 98, loss = 0.23959422\n",
      "Iteration 99, loss = 0.23594109\n",
      "Iteration 100, loss = 0.23980897\n",
      "Iteration 101, loss = 0.24475119\n",
      "Iteration 102, loss = 0.23648119\n",
      "Iteration 103, loss = 0.25495320\n",
      "Iteration 104, loss = 0.24516028\n",
      "Iteration 105, loss = 0.23126277\n",
      "Iteration 106, loss = 0.24398387\n",
      "Iteration 107, loss = 0.25229161\n",
      "Iteration 108, loss = 0.22551714\n",
      "Iteration 109, loss = 0.23624986\n",
      "Iteration 110, loss = 0.24292418\n",
      "Iteration 111, loss = 0.24046950\n",
      "Iteration 112, loss = 0.25522506\n",
      "Iteration 113, loss = 0.22912992\n",
      "Iteration 114, loss = 0.23785390\n",
      "Iteration 115, loss = 0.22688539\n",
      "Iteration 116, loss = 0.22707446\n",
      "Iteration 117, loss = 0.23747421\n",
      "Iteration 118, loss = 0.22242080\n",
      "Iteration 119, loss = 0.23677372\n",
      "Iteration 120, loss = 0.25073632\n",
      "Iteration 121, loss = 0.22892417\n",
      "Iteration 122, loss = 0.22510001\n",
      "Iteration 123, loss = 0.22735670\n",
      "Iteration 124, loss = 0.25263610\n",
      "Iteration 125, loss = 0.22948987\n",
      "Iteration 126, loss = 0.21991997\n",
      "Iteration 127, loss = 0.24453446\n",
      "Iteration 128, loss = 0.22736258\n",
      "Iteration 129, loss = 0.23664220\n",
      "Iteration 130, loss = 0.22537000\n",
      "Iteration 131, loss = 0.22516063\n",
      "Iteration 132, loss = 0.21705633\n",
      "Iteration 133, loss = 0.21799264\n",
      "Iteration 134, loss = 0.21266917\n",
      "Iteration 135, loss = 0.22637182\n",
      "Iteration 136, loss = 0.23553123\n",
      "Iteration 137, loss = 0.21082401\n",
      "Iteration 138, loss = 0.22497363\n",
      "Iteration 139, loss = 0.22339006\n",
      "Iteration 140, loss = 0.21428392\n",
      "Iteration 141, loss = 0.22109620\n",
      "Iteration 142, loss = 0.21309056\n",
      "Iteration 143, loss = 0.22265804\n",
      "Iteration 144, loss = 0.21717304\n",
      "Iteration 145, loss = 0.22026511\n",
      "Iteration 146, loss = 0.21091147\n",
      "Iteration 147, loss = 0.20355454\n",
      "Iteration 148, loss = 0.21179409\n",
      "Iteration 149, loss = 0.21939396\n",
      "Iteration 150, loss = 0.21729642\n",
      "Iteration 151, loss = 0.22058073\n",
      "Iteration 152, loss = 0.21698753\n",
      "Iteration 153, loss = 0.21947441\n",
      "Iteration 154, loss = 0.20444780\n",
      "Iteration 155, loss = 0.20198416\n",
      "Iteration 156, loss = 0.20666172\n",
      "Iteration 157, loss = 0.21554504\n",
      "Iteration 158, loss = 0.21175172\n",
      "Iteration 159, loss = 0.21145916\n",
      "Iteration 160, loss = 0.20222825\n",
      "Iteration 161, loss = 0.20525751\n",
      "Iteration 162, loss = 0.20666353\n",
      "Iteration 163, loss = 0.22128330\n",
      "Iteration 164, loss = 0.20943978\n",
      "Iteration 165, loss = 0.22300092\n",
      "Iteration 166, loss = 0.21044647\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.30225434\n",
      "Iteration 2, loss = 0.71480317\n",
      "Iteration 3, loss = 0.63813027\n",
      "Iteration 4, loss = 0.57787427\n",
      "Iteration 5, loss = 0.53716355\n",
      "Iteration 6, loss = 0.54382980\n",
      "Iteration 7, loss = 0.51362151\n",
      "Iteration 8, loss = 0.49752751\n",
      "Iteration 9, loss = 0.48923253\n",
      "Iteration 10, loss = 0.48133413\n",
      "Iteration 11, loss = 0.47739670\n",
      "Iteration 12, loss = 0.46170510\n",
      "Iteration 13, loss = 0.46753649\n",
      "Iteration 14, loss = 0.44834437\n",
      "Iteration 15, loss = 0.44899319\n",
      "Iteration 16, loss = 0.42155035\n",
      "Iteration 17, loss = 0.42237611\n",
      "Iteration 18, loss = 0.43843697\n",
      "Iteration 19, loss = 0.43402503\n",
      "Iteration 20, loss = 0.41708259\n",
      "Iteration 21, loss = 0.41184734\n",
      "Iteration 22, loss = 0.40138156\n",
      "Iteration 23, loss = 0.41144526\n",
      "Iteration 24, loss = 0.39143329\n",
      "Iteration 25, loss = 0.41344949\n",
      "Iteration 26, loss = 0.43495209\n",
      "Iteration 27, loss = 0.38905881\n",
      "Iteration 28, loss = 0.39945914\n",
      "Iteration 29, loss = 0.39733330\n",
      "Iteration 30, loss = 0.39481937\n",
      "Iteration 31, loss = 0.39155704\n",
      "Iteration 32, loss = 0.38089561\n",
      "Iteration 33, loss = 0.37572751\n",
      "Iteration 34, loss = 0.37863120\n",
      "Iteration 35, loss = 0.38693858\n",
      "Iteration 36, loss = 0.37354179\n",
      "Iteration 37, loss = 0.36076878\n",
      "Iteration 38, loss = 0.36000946\n",
      "Iteration 39, loss = 0.36600538\n",
      "Iteration 40, loss = 0.37041127\n",
      "Iteration 41, loss = 0.37990646\n",
      "Iteration 42, loss = 0.36638008\n",
      "Iteration 43, loss = 0.34390917\n",
      "Iteration 44, loss = 0.34132994\n",
      "Iteration 45, loss = 0.35940409\n",
      "Iteration 46, loss = 0.37121767\n",
      "Iteration 47, loss = 0.37021394\n",
      "Iteration 48, loss = 0.33743371\n",
      "Iteration 49, loss = 0.35357063\n",
      "Iteration 50, loss = 0.35169518\n",
      "Iteration 51, loss = 0.35551832\n",
      "Iteration 52, loss = 0.33548833\n",
      "Iteration 53, loss = 0.34544581\n",
      "Iteration 54, loss = 0.35518964\n",
      "Iteration 55, loss = 0.33684454\n",
      "Iteration 56, loss = 0.36227617\n",
      "Iteration 57, loss = 0.34244722\n",
      "Iteration 58, loss = 0.32890160\n",
      "Iteration 59, loss = 0.33434124\n",
      "Iteration 60, loss = 0.34354671\n",
      "Iteration 61, loss = 0.34011111\n",
      "Iteration 62, loss = 0.35382181\n",
      "Iteration 63, loss = 0.34325763\n",
      "Iteration 64, loss = 0.32811031\n",
      "Iteration 65, loss = 0.33014960\n",
      "Iteration 66, loss = 0.32851393\n",
      "Iteration 67, loss = 0.32626287\n",
      "Iteration 68, loss = 0.32398147\n",
      "Iteration 69, loss = 0.31370208\n",
      "Iteration 70, loss = 0.32416591\n",
      "Iteration 71, loss = 0.33988124\n",
      "Iteration 72, loss = 0.32253097\n",
      "Iteration 73, loss = 0.31545275\n",
      "Iteration 74, loss = 0.30611174\n",
      "Iteration 75, loss = 0.34226694\n",
      "Iteration 76, loss = 0.31270852\n",
      "Iteration 77, loss = 0.32114835\n",
      "Iteration 78, loss = 0.31325711\n",
      "Iteration 79, loss = 0.32055227\n",
      "Iteration 80, loss = 0.31451659\n",
      "Iteration 81, loss = 0.32775933\n",
      "Iteration 82, loss = 0.32132594\n",
      "Iteration 83, loss = 0.37409156\n",
      "Iteration 84, loss = 0.31696863\n",
      "Iteration 85, loss = 0.31828743\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22367072\n",
      "Iteration 2, loss = 0.67641432\n",
      "Iteration 3, loss = 0.60295781\n",
      "Iteration 4, loss = 0.55618740\n",
      "Iteration 5, loss = 0.52092819\n",
      "Iteration 6, loss = 0.49491655\n",
      "Iteration 7, loss = 0.49395327\n",
      "Iteration 8, loss = 0.45945088\n",
      "Iteration 9, loss = 0.46206099\n",
      "Iteration 10, loss = 0.44052052\n",
      "Iteration 11, loss = 0.42604541\n",
      "Iteration 12, loss = 0.42041856\n",
      "Iteration 13, loss = 0.41539996\n",
      "Iteration 14, loss = 0.39153779\n",
      "Iteration 15, loss = 0.38282687\n",
      "Iteration 16, loss = 0.38613551\n",
      "Iteration 17, loss = 0.36572264\n",
      "Iteration 18, loss = 0.36538830\n",
      "Iteration 19, loss = 0.36258361\n",
      "Iteration 20, loss = 0.35870515\n",
      "Iteration 21, loss = 0.35235353\n",
      "Iteration 22, loss = 0.35051522\n",
      "Iteration 23, loss = 0.34357527\n",
      "Iteration 24, loss = 0.35580091\n",
      "Iteration 25, loss = 0.33682640\n",
      "Iteration 26, loss = 0.33228846\n",
      "Iteration 27, loss = 0.32308560\n",
      "Iteration 28, loss = 0.33702800\n",
      "Iteration 29, loss = 0.33180374\n",
      "Iteration 30, loss = 0.33301804\n",
      "Iteration 31, loss = 0.33115232\n",
      "Iteration 32, loss = 0.31164218\n",
      "Iteration 33, loss = 0.32568421\n",
      "Iteration 34, loss = 0.31496798\n",
      "Iteration 35, loss = 0.30702938\n",
      "Iteration 36, loss = 0.30802648\n",
      "Iteration 37, loss = 0.30722632\n",
      "Iteration 38, loss = 0.29557271\n",
      "Iteration 39, loss = 0.32203794\n",
      "Iteration 40, loss = 0.29794019\n",
      "Iteration 41, loss = 0.28293550\n",
      "Iteration 42, loss = 0.28917846\n",
      "Iteration 43, loss = 0.29248512\n",
      "Iteration 44, loss = 0.29028408\n",
      "Iteration 45, loss = 0.28362717\n",
      "Iteration 46, loss = 0.28439601\n",
      "Iteration 47, loss = 0.28017193\n",
      "Iteration 48, loss = 0.28650543\n",
      "Iteration 49, loss = 0.27870151\n",
      "Iteration 50, loss = 0.28519268\n",
      "Iteration 51, loss = 0.27142203\n",
      "Iteration 52, loss = 0.26733454\n",
      "Iteration 53, loss = 0.26863348\n",
      "Iteration 54, loss = 0.27118955\n",
      "Iteration 55, loss = 0.27983509\n",
      "Iteration 56, loss = 0.28361225\n",
      "Iteration 57, loss = 0.27701005\n",
      "Iteration 58, loss = 0.26507164\n",
      "Iteration 59, loss = 0.26427189\n",
      "Iteration 60, loss = 0.26182095\n",
      "Iteration 61, loss = 0.26175787\n",
      "Iteration 62, loss = 0.25617652\n",
      "Iteration 63, loss = 0.27978689\n",
      "Iteration 64, loss = 0.26231157\n",
      "Iteration 65, loss = 0.25584737\n",
      "Iteration 66, loss = 0.25050486\n",
      "Iteration 67, loss = 0.25573327\n",
      "Iteration 68, loss = 0.25447353\n",
      "Iteration 69, loss = 0.25031488\n",
      "Iteration 70, loss = 0.24776187\n",
      "Iteration 71, loss = 0.25769203\n",
      "Iteration 72, loss = 0.24982831\n",
      "Iteration 73, loss = 0.24112643\n",
      "Iteration 74, loss = 0.25548680\n",
      "Iteration 75, loss = 0.23875925\n",
      "Iteration 76, loss = 0.25397470\n",
      "Iteration 77, loss = 0.25586748\n",
      "Iteration 78, loss = 0.26389831\n",
      "Iteration 79, loss = 0.24883391\n",
      "Iteration 80, loss = 0.23912861\n",
      "Iteration 81, loss = 0.25448137\n",
      "Iteration 82, loss = 0.23602484\n",
      "Iteration 83, loss = 0.23745594\n",
      "Iteration 84, loss = 0.23426522\n",
      "Iteration 85, loss = 0.24932086\n",
      "Iteration 86, loss = 0.22726919\n",
      "Iteration 87, loss = 0.23300440\n",
      "Iteration 88, loss = 0.23602220\n",
      "Iteration 89, loss = 0.23732752\n",
      "Iteration 90, loss = 0.22785870\n",
      "Iteration 91, loss = 0.23516147\n",
      "Iteration 92, loss = 0.23504345\n",
      "Iteration 93, loss = 0.22624846\n",
      "Iteration 94, loss = 0.22751401\n",
      "Iteration 95, loss = 0.23141882\n",
      "Iteration 96, loss = 0.22440299\n",
      "Iteration 97, loss = 0.23254861\n",
      "Iteration 98, loss = 0.21871487\n",
      "Iteration 99, loss = 0.22516214\n",
      "Iteration 100, loss = 0.24335287\n",
      "Iteration 101, loss = 0.21753464\n",
      "Iteration 102, loss = 0.22587397\n",
      "Iteration 103, loss = 0.21849346\n",
      "Iteration 104, loss = 0.23487363\n",
      "Iteration 105, loss = 0.24095326\n",
      "Iteration 106, loss = 0.22603466\n",
      "Iteration 107, loss = 0.21296243\n",
      "Iteration 108, loss = 0.21256329\n",
      "Iteration 109, loss = 0.20882542\n",
      "Iteration 110, loss = 0.21105700\n",
      "Iteration 111, loss = 0.24055253\n",
      "Iteration 112, loss = 0.20567303\n",
      "Iteration 113, loss = 0.21761039\n",
      "Iteration 114, loss = 0.20546193\n",
      "Iteration 115, loss = 0.21132157\n",
      "Iteration 116, loss = 0.24199203\n",
      "Iteration 117, loss = 0.21462983\n",
      "Iteration 118, loss = 0.20893679\n",
      "Iteration 119, loss = 0.20816826\n",
      "Iteration 120, loss = 0.20449428\n",
      "Iteration 121, loss = 0.21973938\n",
      "Iteration 122, loss = 0.20476975\n",
      "Iteration 123, loss = 0.21325294\n",
      "Iteration 124, loss = 0.20327341\n",
      "Iteration 125, loss = 0.22462071\n",
      "Iteration 126, loss = 0.20445692\n",
      "Iteration 127, loss = 0.23690927\n",
      "Iteration 128, loss = 0.21642622\n",
      "Iteration 129, loss = 0.19300499\n",
      "Iteration 130, loss = 0.19210211\n",
      "Iteration 131, loss = 0.20710476\n",
      "Iteration 132, loss = 0.20313875\n",
      "Iteration 133, loss = 0.20565790\n",
      "Iteration 134, loss = 0.19204329\n",
      "Iteration 135, loss = 0.19788012\n",
      "Iteration 136, loss = 0.19772367\n",
      "Iteration 137, loss = 0.19671929\n",
      "Iteration 138, loss = 0.18849804\n",
      "Iteration 139, loss = 0.20201513\n",
      "Iteration 140, loss = 0.19713800\n",
      "Iteration 141, loss = 0.20180941\n",
      "Iteration 142, loss = 0.20491694\n",
      "Iteration 143, loss = 0.18511411\n",
      "Iteration 144, loss = 0.19727556\n",
      "Iteration 145, loss = 0.20423689\n",
      "Iteration 146, loss = 0.21585665\n",
      "Iteration 147, loss = 0.18754033\n",
      "Iteration 148, loss = 0.19691659\n",
      "Iteration 149, loss = 0.22128593\n",
      "Iteration 150, loss = 0.19185514\n",
      "Iteration 151, loss = 0.19374303\n",
      "Iteration 152, loss = 0.19122385\n",
      "Iteration 153, loss = 0.18766523\n",
      "Iteration 154, loss = 0.18998066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.15819881\n",
      "Iteration 2, loss = 1.23400209\n",
      "Iteration 3, loss = 0.97955753\n",
      "Iteration 4, loss = 0.75753670\n",
      "Iteration 5, loss = 0.66773764\n",
      "Iteration 6, loss = 1.18536127\n",
      "Iteration 7, loss = 0.80656598\n",
      "Iteration 8, loss = 0.77786919\n",
      "Iteration 9, loss = 1.16158198\n",
      "Iteration 10, loss = 0.92859989\n",
      "Iteration 11, loss = 1.53422588\n",
      "Iteration 12, loss = 1.75121235\n",
      "Iteration 13, loss = 1.48333450\n",
      "Iteration 14, loss = 1.42151984\n",
      "Iteration 15, loss = 1.12538552\n",
      "Iteration 16, loss = 0.98568772\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.22100091\n",
      "Iteration 2, loss = 0.72357826\n",
      "Iteration 3, loss = 0.67908517\n",
      "Iteration 4, loss = 0.64565603\n",
      "Iteration 5, loss = 0.52514649\n",
      "Iteration 6, loss = 0.49430233\n",
      "Iteration 7, loss = 0.51614189\n",
      "Iteration 8, loss = 0.45605140\n",
      "Iteration 9, loss = 0.46528745\n",
      "Iteration 10, loss = 0.46204336\n",
      "Iteration 11, loss = 0.49068059\n",
      "Iteration 12, loss = 0.47558877\n",
      "Iteration 13, loss = 0.41343207\n",
      "Iteration 14, loss = 0.72221178\n",
      "Iteration 15, loss = 0.50677853\n",
      "Iteration 16, loss = 0.46441929\n",
      "Iteration 17, loss = 0.43777104\n",
      "Iteration 18, loss = 0.42813724\n",
      "Iteration 19, loss = 0.41229008\n",
      "Iteration 20, loss = 0.41426921\n",
      "Iteration 21, loss = 0.45851870\n",
      "Iteration 22, loss = 0.40375367\n",
      "Iteration 23, loss = 0.43816621\n",
      "Iteration 24, loss = 0.39298077\n",
      "Iteration 25, loss = 0.38026911\n",
      "Iteration 26, loss = 0.37371139\n",
      "Iteration 27, loss = 1.06430268\n",
      "Iteration 28, loss = 0.70129698\n",
      "Iteration 29, loss = 0.69313857\n",
      "Iteration 30, loss = 1.21571353\n",
      "Iteration 31, loss = 0.93102975\n",
      "Iteration 32, loss = 0.89490080\n",
      "Iteration 33, loss = 0.77967520\n",
      "Iteration 34, loss = 0.73100466\n",
      "Iteration 35, loss = 0.69191309\n",
      "Iteration 36, loss = 0.70549600\n",
      "Iteration 37, loss = 1.08714860\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.00100061\n",
      "Iteration 2, loss = 0.53845278\n",
      "Iteration 3, loss = 0.47138653\n",
      "Iteration 4, loss = 0.42016942\n",
      "Iteration 5, loss = 0.39028625\n",
      "Iteration 6, loss = 0.36421383\n",
      "Iteration 7, loss = 0.34062651\n",
      "Iteration 8, loss = 0.33279253\n",
      "Iteration 9, loss = 0.31712534\n",
      "Iteration 10, loss = 0.29892813\n",
      "Iteration 11, loss = 0.29062332\n",
      "Iteration 12, loss = 0.29399305\n",
      "Iteration 13, loss = 0.26724895\n",
      "Iteration 14, loss = 0.25653437\n",
      "Iteration 15, loss = 0.24822745\n",
      "Iteration 16, loss = 0.25171714\n",
      "Iteration 17, loss = 0.23298412\n",
      "Iteration 18, loss = 0.23227927\n",
      "Iteration 19, loss = 0.22129041\n",
      "Iteration 20, loss = 0.21045908\n",
      "Iteration 21, loss = 0.21156315\n",
      "Iteration 22, loss = 0.18833408\n",
      "Iteration 23, loss = 0.20408029\n",
      "Iteration 24, loss = 0.18314632\n",
      "Iteration 25, loss = 0.18456712\n",
      "Iteration 26, loss = 0.17892202\n",
      "Iteration 27, loss = 0.16935745\n",
      "Iteration 28, loss = 0.16667612\n",
      "Iteration 29, loss = 0.16114756\n",
      "Iteration 30, loss = 0.16454139\n",
      "Iteration 31, loss = 0.15357937\n",
      "Iteration 32, loss = 0.14725237\n",
      "Iteration 33, loss = 0.15598628\n",
      "Iteration 34, loss = 0.12840394\n",
      "Iteration 35, loss = 0.13837973\n",
      "Iteration 36, loss = 0.15153861\n",
      "Iteration 37, loss = 0.12734911\n",
      "Iteration 38, loss = 0.12301730\n",
      "Iteration 39, loss = 0.11792686\n",
      "Iteration 40, loss = 0.12733061\n",
      "Iteration 41, loss = 0.11361032\n",
      "Iteration 42, loss = 0.10691973\n",
      "Iteration 43, loss = 0.09645088\n",
      "Iteration 44, loss = 0.09905170\n",
      "Iteration 45, loss = 0.09701493\n",
      "Iteration 46, loss = 0.09713627\n",
      "Iteration 47, loss = 0.09034488\n",
      "Iteration 48, loss = 0.08140326\n",
      "Iteration 49, loss = 0.09721865\n",
      "Iteration 50, loss = 0.08531723\n",
      "Iteration 51, loss = 0.08607591\n",
      "Iteration 52, loss = 0.08277625\n",
      "Iteration 53, loss = 0.09087908\n",
      "Iteration 54, loss = 0.07390723\n",
      "Iteration 55, loss = 0.08886348\n",
      "Iteration 56, loss = 0.06815122\n",
      "Iteration 57, loss = 0.07708269\n",
      "Iteration 58, loss = 0.07110990\n",
      "Iteration 59, loss = 0.07192568\n",
      "Iteration 60, loss = 0.06249045\n",
      "Iteration 61, loss = 0.05915138\n",
      "Iteration 62, loss = 0.06186706\n",
      "Iteration 63, loss = 0.05884373\n",
      "Iteration 64, loss = 0.08449432\n",
      "Iteration 65, loss = 0.06507841\n",
      "Iteration 66, loss = 0.07542637\n",
      "Iteration 67, loss = 0.05060444\n",
      "Iteration 68, loss = 0.05775383\n",
      "Iteration 69, loss = 0.07021873\n",
      "Iteration 70, loss = 0.05292485\n",
      "Iteration 71, loss = 0.04542736\n",
      "Iteration 72, loss = 0.04290723\n",
      "Iteration 73, loss = 0.05178515\n",
      "Iteration 74, loss = 0.04756729\n",
      "Iteration 75, loss = 0.04876734\n",
      "Iteration 76, loss = 0.05046062\n",
      "Iteration 77, loss = 0.03626434\n",
      "Iteration 78, loss = 0.03817157\n",
      "Iteration 79, loss = 0.05000315\n",
      "Iteration 80, loss = 0.05662638\n",
      "Iteration 81, loss = 0.04673365\n",
      "Iteration 82, loss = 0.04132585\n",
      "Iteration 83, loss = 0.04511993\n",
      "Iteration 84, loss = 0.03500875\n",
      "Iteration 85, loss = 0.04371402\n",
      "Iteration 86, loss = 0.03176212\n",
      "Iteration 87, loss = 0.02661153\n",
      "Iteration 88, loss = 0.03575244\n",
      "Iteration 89, loss = 0.02630883\n",
      "Iteration 90, loss = 0.02634435\n",
      "Iteration 91, loss = 0.02210040\n",
      "Iteration 92, loss = 0.02671653\n",
      "Iteration 93, loss = 0.02508800\n",
      "Iteration 94, loss = 0.02589063\n",
      "Iteration 95, loss = 0.03717444\n",
      "Iteration 96, loss = 0.02850016\n",
      "Iteration 97, loss = 0.03448654\n",
      "Iteration 98, loss = 0.03994151\n",
      "Iteration 99, loss = 0.02388933\n",
      "Iteration 100, loss = 0.01838494\n",
      "Iteration 101, loss = 0.02133795\n",
      "Iteration 102, loss = 0.02131098\n",
      "Iteration 103, loss = 0.01795900\n",
      "Iteration 104, loss = 0.02372370\n",
      "Iteration 105, loss = 0.07990410\n",
      "Iteration 106, loss = 0.03381044\n",
      "Iteration 107, loss = 0.02107898\n",
      "Iteration 108, loss = 0.01792584\n",
      "Iteration 109, loss = 0.02127329\n",
      "Iteration 110, loss = 0.01419946\n",
      "Iteration 111, loss = 0.01587645\n",
      "Iteration 112, loss = 0.05926626\n",
      "Iteration 113, loss = 0.03776889\n",
      "Iteration 114, loss = 0.02398500\n",
      "Iteration 115, loss = 0.02066302\n",
      "Iteration 116, loss = 0.01436616\n",
      "Iteration 117, loss = 0.01347507\n",
      "Iteration 118, loss = 0.01226935\n",
      "Iteration 119, loss = 0.01398358\n",
      "Iteration 120, loss = 0.02225493\n",
      "Iteration 121, loss = 0.01252401\n",
      "Iteration 122, loss = 0.00932573\n",
      "Iteration 123, loss = 0.00690099\n",
      "Iteration 124, loss = 0.00873255\n",
      "Iteration 125, loss = 0.00647269\n",
      "Iteration 126, loss = 0.00675166\n",
      "Iteration 127, loss = 0.00928396\n",
      "Iteration 128, loss = 0.01210541\n",
      "Iteration 129, loss = 0.00773767\n",
      "Iteration 130, loss = 0.00738946\n",
      "Iteration 131, loss = 0.00611580\n",
      "Iteration 132, loss = 0.00525587\n",
      "Iteration 133, loss = 0.00488294\n",
      "Iteration 134, loss = 0.00492954\n",
      "Iteration 135, loss = 0.00497845\n",
      "Iteration 136, loss = 0.00538591\n",
      "Iteration 137, loss = 0.00747840\n",
      "Iteration 138, loss = 0.00568815\n",
      "Iteration 139, loss = 0.00429359\n",
      "Iteration 140, loss = 0.00414532\n",
      "Iteration 141, loss = 0.00518653\n",
      "Iteration 142, loss = 0.00383647\n",
      "Iteration 143, loss = 0.00474416\n",
      "Iteration 144, loss = 0.00443967\n",
      "Iteration 145, loss = 0.00411835\n",
      "Iteration 146, loss = 0.00353365\n",
      "Iteration 147, loss = 0.00388181\n",
      "Iteration 148, loss = 0.00313616\n",
      "Iteration 149, loss = 0.00321200\n",
      "Iteration 150, loss = 0.00293127\n",
      "Iteration 151, loss = 0.00274876\n",
      "Iteration 152, loss = 0.00284971\n",
      "Iteration 153, loss = 0.00268663\n",
      "Iteration 154, loss = 0.00280343\n",
      "Iteration 155, loss = 0.00277202\n",
      "Iteration 156, loss = 0.00255674\n",
      "Iteration 157, loss = 0.00274216\n",
      "Iteration 158, loss = 0.00274339\n",
      "Iteration 159, loss = 0.00257416\n",
      "Iteration 160, loss = 0.00238539\n",
      "Iteration 161, loss = 0.00234083\n",
      "Iteration 162, loss = 0.00232892\n",
      "Iteration 163, loss = 0.00226195\n",
      "Iteration 164, loss = 0.00226536\n",
      "Iteration 165, loss = 0.00228515\n",
      "Iteration 166, loss = 0.00229218\n",
      "Iteration 167, loss = 0.00227970\n",
      "Iteration 168, loss = 0.00230863\n",
      "Iteration 169, loss = 0.00208166\n",
      "Iteration 170, loss = 0.00227621\n",
      "Iteration 171, loss = 0.00227957\n",
      "Iteration 172, loss = 0.00221296\n",
      "Iteration 173, loss = 0.00209440\n",
      "Iteration 174, loss = 0.00208095\n",
      "Iteration 175, loss = 0.00208583\n",
      "Iteration 176, loss = 0.00209716\n",
      "Iteration 177, loss = 0.00195868\n",
      "Iteration 178, loss = 0.00201724\n",
      "Iteration 179, loss = 0.00199701\n",
      "Iteration 180, loss = 0.00193102\n",
      "Iteration 181, loss = 0.00192110\n",
      "Iteration 182, loss = 0.00187514\n",
      "Iteration 183, loss = 0.00186099\n",
      "Iteration 184, loss = 0.00186968\n",
      "Iteration 185, loss = 0.00181149\n",
      "Iteration 186, loss = 0.00177358\n",
      "Iteration 187, loss = 0.00178679\n",
      "Iteration 188, loss = 0.00174264\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.96893137\n",
      "Iteration 2, loss = 0.54309009\n",
      "Iteration 3, loss = 0.46764549\n",
      "Iteration 4, loss = 0.42665521\n",
      "Iteration 5, loss = 0.40433623\n",
      "Iteration 6, loss = 0.37512110\n",
      "Iteration 7, loss = 0.35062388\n",
      "Iteration 8, loss = 0.33506926\n",
      "Iteration 9, loss = 0.32330381\n",
      "Iteration 10, loss = 0.30217843\n",
      "Iteration 11, loss = 0.29029328\n",
      "Iteration 12, loss = 0.28124733\n",
      "Iteration 13, loss = 0.26258110\n",
      "Iteration 14, loss = 0.25472771\n",
      "Iteration 15, loss = 0.25268282\n",
      "Iteration 16, loss = 0.24228412\n",
      "Iteration 17, loss = 0.22807002\n",
      "Iteration 18, loss = 0.22391803\n",
      "Iteration 19, loss = 0.22166406\n",
      "Iteration 20, loss = 0.21121306\n",
      "Iteration 21, loss = 0.21096916\n",
      "Iteration 22, loss = 0.19204527\n",
      "Iteration 23, loss = 0.19030468\n",
      "Iteration 24, loss = 0.18753227\n",
      "Iteration 25, loss = 0.17970707\n",
      "Iteration 26, loss = 0.16529042\n",
      "Iteration 27, loss = 0.17688123\n",
      "Iteration 28, loss = 0.16740363\n",
      "Iteration 29, loss = 0.16290132\n",
      "Iteration 30, loss = 0.16445034\n",
      "Iteration 31, loss = 0.14384098\n",
      "Iteration 32, loss = 0.14512932\n",
      "Iteration 33, loss = 0.14018947\n",
      "Iteration 34, loss = 0.14168030\n",
      "Iteration 35, loss = 0.12852769\n",
      "Iteration 36, loss = 0.12349434\n",
      "Iteration 37, loss = 0.13289234\n",
      "Iteration 38, loss = 0.12491559\n",
      "Iteration 39, loss = 0.12520180\n",
      "Iteration 40, loss = 0.11787336\n",
      "Iteration 41, loss = 0.11192552\n",
      "Iteration 42, loss = 0.12095886\n",
      "Iteration 43, loss = 0.09960700\n",
      "Iteration 44, loss = 0.10586011\n",
      "Iteration 45, loss = 0.09561930\n",
      "Iteration 46, loss = 0.09037391\n",
      "Iteration 47, loss = 0.09501054\n",
      "Iteration 48, loss = 0.08215818\n",
      "Iteration 49, loss = 0.08164425\n",
      "Iteration 50, loss = 0.08968301\n",
      "Iteration 51, loss = 0.09421159\n",
      "Iteration 52, loss = 0.08041370\n",
      "Iteration 53, loss = 0.08197991\n",
      "Iteration 54, loss = 0.07770632\n",
      "Iteration 55, loss = 0.06984588\n",
      "Iteration 56, loss = 0.06771570\n",
      "Iteration 57, loss = 0.06509864\n",
      "Iteration 58, loss = 0.06081548\n",
      "Iteration 59, loss = 0.07174510\n",
      "Iteration 60, loss = 0.06898695\n",
      "Iteration 61, loss = 0.07676981\n",
      "Iteration 62, loss = 0.06584970\n",
      "Iteration 63, loss = 0.06852823\n",
      "Iteration 64, loss = 0.04977358\n",
      "Iteration 65, loss = 0.05022397\n",
      "Iteration 66, loss = 0.04693983\n",
      "Iteration 67, loss = 0.05518804\n",
      "Iteration 68, loss = 0.05735822\n",
      "Iteration 69, loss = 0.05392771\n",
      "Iteration 70, loss = 0.04043580\n",
      "Iteration 71, loss = 0.04574344\n",
      "Iteration 72, loss = 0.04689245\n",
      "Iteration 73, loss = 0.04200312\n",
      "Iteration 74, loss = 0.04480782\n",
      "Iteration 75, loss = 0.03708522\n",
      "Iteration 76, loss = 0.03628897\n",
      "Iteration 77, loss = 0.04193750\n",
      "Iteration 78, loss = 0.04437601\n",
      "Iteration 79, loss = 0.03869854\n",
      "Iteration 80, loss = 0.03577605\n",
      "Iteration 81, loss = 0.07187712\n",
      "Iteration 82, loss = 0.03791654\n",
      "Iteration 83, loss = 0.03186998\n",
      "Iteration 84, loss = 0.06516937\n",
      "Iteration 85, loss = 0.05665871\n",
      "Iteration 86, loss = 0.04009419\n",
      "Iteration 87, loss = 0.03244252\n",
      "Iteration 88, loss = 0.02901017\n",
      "Iteration 89, loss = 0.02778984\n",
      "Iteration 90, loss = 0.02345610\n",
      "Iteration 91, loss = 0.02403854\n",
      "Iteration 92, loss = 0.02243005\n",
      "Iteration 93, loss = 0.01903567\n",
      "Iteration 94, loss = 0.01799196\n",
      "Iteration 95, loss = 0.01776565\n",
      "Iteration 96, loss = 0.01782766\n",
      "Iteration 97, loss = 0.01577029\n",
      "Iteration 98, loss = 0.01592084\n",
      "Iteration 99, loss = 0.01329633\n",
      "Iteration 100, loss = 0.01178212\n",
      "Iteration 101, loss = 0.01005774\n",
      "Iteration 102, loss = 0.00790321\n",
      "Iteration 103, loss = 0.00998010\n",
      "Iteration 104, loss = 0.01590312\n",
      "Iteration 105, loss = 0.01401692\n",
      "Iteration 106, loss = 0.00861935\n",
      "Iteration 107, loss = 0.00911443\n",
      "Iteration 108, loss = 0.00651690\n",
      "Iteration 109, loss = 0.00769564\n",
      "Iteration 110, loss = 0.00599198\n",
      "Iteration 111, loss = 0.00631115\n",
      "Iteration 112, loss = 0.00852679\n",
      "Iteration 113, loss = 0.00557930\n",
      "Iteration 114, loss = 0.00458050\n",
      "Iteration 115, loss = 0.00464029\n",
      "Iteration 116, loss = 0.00460321\n",
      "Iteration 117, loss = 0.00426720\n",
      "Iteration 118, loss = 0.00410503\n",
      "Iteration 119, loss = 0.00415220\n",
      "Iteration 120, loss = 0.00387111\n",
      "Iteration 121, loss = 0.00357785\n",
      "Iteration 122, loss = 0.00357694\n",
      "Iteration 123, loss = 0.00353873\n",
      "Iteration 124, loss = 0.00345360\n",
      "Iteration 125, loss = 0.00331824\n",
      "Iteration 126, loss = 0.00357221\n",
      "Iteration 127, loss = 0.00330863\n",
      "Iteration 128, loss = 0.00370719\n",
      "Iteration 129, loss = 0.00337357\n",
      "Iteration 130, loss = 0.00305655\n",
      "Iteration 131, loss = 0.00303120\n",
      "Iteration 132, loss = 0.00294280\n",
      "Iteration 133, loss = 0.00304493\n",
      "Iteration 134, loss = 0.00279850\n",
      "Iteration 135, loss = 0.00286305\n",
      "Iteration 136, loss = 0.00272415\n",
      "Iteration 137, loss = 0.00273709\n",
      "Iteration 138, loss = 0.00269931\n",
      "Iteration 139, loss = 0.00268017\n",
      "Iteration 140, loss = 0.00256155\n",
      "Iteration 141, loss = 0.00253715\n",
      "Iteration 142, loss = 0.00248842\n",
      "Iteration 143, loss = 0.00245026\n",
      "Iteration 144, loss = 0.00246504\n",
      "Iteration 145, loss = 0.00251594\n",
      "Iteration 146, loss = 0.00241901\n",
      "Iteration 147, loss = 0.00235833\n",
      "Iteration 148, loss = 0.00235945\n",
      "Iteration 149, loss = 0.00228119\n",
      "Iteration 150, loss = 0.00234511\n",
      "Iteration 151, loss = 0.00226669\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.97931700\n",
      "Iteration 2, loss = 0.54696153\n",
      "Iteration 3, loss = 0.46802113\n",
      "Iteration 4, loss = 0.42091770\n",
      "Iteration 5, loss = 0.38474411\n",
      "Iteration 6, loss = 0.36609255\n",
      "Iteration 7, loss = 0.34542831\n",
      "Iteration 8, loss = 0.32206579\n",
      "Iteration 9, loss = 0.31160738\n",
      "Iteration 10, loss = 0.30136710\n",
      "Iteration 11, loss = 0.29342773\n",
      "Iteration 12, loss = 0.27931968\n",
      "Iteration 13, loss = 0.27153492\n",
      "Iteration 14, loss = 0.25779063\n",
      "Iteration 15, loss = 0.24755159\n",
      "Iteration 16, loss = 0.23877257\n",
      "Iteration 17, loss = 0.23483779\n",
      "Iteration 18, loss = 0.22596043\n",
      "Iteration 19, loss = 0.21963972\n",
      "Iteration 20, loss = 0.20196939\n",
      "Iteration 21, loss = 0.20153487\n",
      "Iteration 22, loss = 0.19240717\n",
      "Iteration 23, loss = 0.19329864\n",
      "Iteration 24, loss = 0.17870219\n",
      "Iteration 25, loss = 0.18718218\n",
      "Iteration 26, loss = 0.18316622\n",
      "Iteration 27, loss = 0.16471418\n",
      "Iteration 28, loss = 0.16350404\n",
      "Iteration 29, loss = 0.16746471\n",
      "Iteration 30, loss = 0.15717069\n",
      "Iteration 31, loss = 0.14901854\n",
      "Iteration 32, loss = 0.14279633\n",
      "Iteration 33, loss = 0.14328982\n",
      "Iteration 34, loss = 0.13269377\n",
      "Iteration 35, loss = 0.13797486\n",
      "Iteration 36, loss = 0.14464884\n",
      "Iteration 37, loss = 0.12188923\n",
      "Iteration 38, loss = 0.12118239\n",
      "Iteration 39, loss = 0.12016921\n",
      "Iteration 40, loss = 0.11539229\n",
      "Iteration 41, loss = 0.11264752\n",
      "Iteration 42, loss = 0.11502370\n",
      "Iteration 43, loss = 0.10647625\n",
      "Iteration 44, loss = 0.10582476\n",
      "Iteration 45, loss = 0.10233853\n",
      "Iteration 46, loss = 0.10094247\n",
      "Iteration 47, loss = 0.09221515\n",
      "Iteration 48, loss = 0.08484638\n",
      "Iteration 49, loss = 0.10316631\n",
      "Iteration 50, loss = 0.09211412\n",
      "Iteration 51, loss = 0.07986485\n",
      "Iteration 52, loss = 0.07664572\n",
      "Iteration 53, loss = 0.07963554\n",
      "Iteration 54, loss = 0.08146188\n",
      "Iteration 55, loss = 0.07792629\n",
      "Iteration 56, loss = 0.06705892\n",
      "Iteration 57, loss = 0.06193695\n",
      "Iteration 58, loss = 0.06775943\n",
      "Iteration 59, loss = 0.08133625\n",
      "Iteration 60, loss = 0.07753186\n",
      "Iteration 61, loss = 0.06613137\n",
      "Iteration 62, loss = 0.06278355\n",
      "Iteration 63, loss = 0.06640857\n",
      "Iteration 64, loss = 0.06149042\n",
      "Iteration 65, loss = 0.06127599\n",
      "Iteration 66, loss = 0.05110424\n",
      "Iteration 67, loss = 0.06085758\n",
      "Iteration 68, loss = 0.04274135\n",
      "Iteration 69, loss = 0.05997134\n",
      "Iteration 70, loss = 0.04980393\n",
      "Iteration 71, loss = 0.04360056\n",
      "Iteration 72, loss = 0.04061368\n",
      "Iteration 73, loss = 0.04364056\n",
      "Iteration 74, loss = 0.04147826\n",
      "Iteration 75, loss = 0.03933562\n",
      "Iteration 76, loss = 0.04347704\n",
      "Iteration 77, loss = 0.04074010\n",
      "Iteration 78, loss = 0.03271135\n",
      "Iteration 79, loss = 0.03165528\n",
      "Iteration 80, loss = 0.03551340\n",
      "Iteration 81, loss = 0.02989847\n",
      "Iteration 82, loss = 0.02573688\n",
      "Iteration 83, loss = 0.03016173\n",
      "Iteration 84, loss = 0.02906706\n",
      "Iteration 85, loss = 0.02698826\n",
      "Iteration 86, loss = 0.03219095\n",
      "Iteration 87, loss = 0.04892598\n",
      "Iteration 88, loss = 0.02382607\n",
      "Iteration 89, loss = 0.02728710\n",
      "Iteration 90, loss = 0.02234710\n",
      "Iteration 91, loss = 0.02051787\n",
      "Iteration 92, loss = 0.03324684\n",
      "Iteration 93, loss = 0.02515952\n",
      "Iteration 94, loss = 0.05410398\n",
      "Iteration 95, loss = 0.03261690\n",
      "Iteration 96, loss = 0.02001166\n",
      "Iteration 97, loss = 0.02047511\n",
      "Iteration 98, loss = 0.01611583\n",
      "Iteration 99, loss = 0.01798398\n",
      "Iteration 100, loss = 0.01590906\n",
      "Iteration 101, loss = 0.01839683\n",
      "Iteration 102, loss = 0.03558683\n",
      "Iteration 103, loss = 0.01858427\n",
      "Iteration 104, loss = 0.01258126\n",
      "Iteration 105, loss = 0.01242072\n",
      "Iteration 106, loss = 0.01059389\n",
      "Iteration 107, loss = 0.01113085\n",
      "Iteration 108, loss = 0.01084996\n",
      "Iteration 109, loss = 0.01194147\n",
      "Iteration 110, loss = 0.01314410\n",
      "Iteration 111, loss = 0.01175767\n",
      "Iteration 112, loss = 0.00939134\n",
      "Iteration 113, loss = 0.00868993\n",
      "Iteration 114, loss = 0.00935828\n",
      "Iteration 115, loss = 0.01261524\n",
      "Iteration 116, loss = 0.00690331\n",
      "Iteration 117, loss = 0.00774936\n",
      "Iteration 118, loss = 0.00747818\n",
      "Iteration 119, loss = 0.00622671\n",
      "Iteration 120, loss = 0.00495595\n",
      "Iteration 121, loss = 0.00544068\n",
      "Iteration 122, loss = 0.00666763\n",
      "Iteration 123, loss = 0.00500788\n",
      "Iteration 124, loss = 0.00455005\n",
      "Iteration 125, loss = 0.00424165\n",
      "Iteration 126, loss = 0.00480628\n",
      "Iteration 127, loss = 0.00467931\n",
      "Iteration 128, loss = 0.00455675\n",
      "Iteration 129, loss = 0.00435859\n",
      "Iteration 130, loss = 0.00410564\n",
      "Iteration 131, loss = 0.00416911\n",
      "Iteration 132, loss = 0.00401093\n",
      "Iteration 133, loss = 0.00377242\n",
      "Iteration 134, loss = 0.00369967\n",
      "Iteration 135, loss = 0.00364044\n",
      "Iteration 136, loss = 0.00408182\n",
      "Iteration 137, loss = 0.00355556\n",
      "Iteration 138, loss = 0.00339344\n",
      "Iteration 139, loss = 0.00315605\n",
      "Iteration 140, loss = 0.00328206\n",
      "Iteration 141, loss = 0.00351985\n",
      "Iteration 142, loss = 0.00322190\n",
      "Iteration 143, loss = 0.00302803\n",
      "Iteration 144, loss = 0.00326124\n",
      "Iteration 145, loss = 0.00320599\n",
      "Iteration 146, loss = 0.00297365\n",
      "Iteration 147, loss = 0.00333315\n",
      "Iteration 148, loss = 0.00310191\n",
      "Iteration 149, loss = 0.00285034\n",
      "Iteration 150, loss = 0.00281079\n",
      "Iteration 151, loss = 0.00287511\n",
      "Iteration 152, loss = 0.00283921\n",
      "Iteration 153, loss = 0.00278262\n",
      "Iteration 154, loss = 0.00273140\n",
      "Iteration 155, loss = 0.00274870\n",
      "Iteration 156, loss = 0.00278599\n",
      "Iteration 157, loss = 0.00287048\n",
      "Iteration 158, loss = 0.00297846\n",
      "Iteration 159, loss = 0.00252224\n",
      "Iteration 160, loss = 0.00255985\n",
      "Iteration 161, loss = 0.00254191\n",
      "Iteration 162, loss = 0.00241116\n",
      "Iteration 163, loss = 0.00247991\n",
      "Iteration 164, loss = 0.00247639\n",
      "Iteration 165, loss = 0.00237753\n",
      "Iteration 166, loss = 0.00229708\n",
      "Iteration 167, loss = 0.00225965\n",
      "Iteration 168, loss = 0.00257471\n",
      "Iteration 169, loss = 0.00243103\n",
      "Iteration 170, loss = 0.00235732\n",
      "Iteration 171, loss = 0.00233094\n",
      "Iteration 172, loss = 0.00218533\n",
      "Iteration 173, loss = 0.00220014\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.97421445\n",
      "Iteration 2, loss = 0.54604514\n",
      "Iteration 3, loss = 0.63873075\n",
      "Iteration 4, loss = 0.68875129\n",
      "Iteration 5, loss = 0.58406928\n",
      "Iteration 6, loss = 0.42313586\n",
      "Iteration 7, loss = 0.65196796\n",
      "Iteration 8, loss = 0.41197719\n",
      "Iteration 9, loss = 0.38012927\n",
      "Iteration 10, loss = 0.37189968\n",
      "Iteration 11, loss = 0.34158934\n",
      "Iteration 12, loss = 0.32747541\n",
      "Iteration 13, loss = 1.16254265\n",
      "Iteration 14, loss = 0.50918432\n",
      "Iteration 15, loss = 0.46270297\n",
      "Iteration 16, loss = 0.41398392\n",
      "Iteration 17, loss = 0.39289764\n",
      "Iteration 18, loss = 0.40121467\n",
      "Iteration 19, loss = 0.37933092\n",
      "Iteration 20, loss = 0.34456186\n",
      "Iteration 21, loss = 0.32893821\n",
      "Iteration 22, loss = 0.49501210\n",
      "Iteration 23, loss = 0.39931952\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.97885562\n",
      "Iteration 2, loss = 0.55132558\n",
      "Iteration 3, loss = 0.49043123\n",
      "Iteration 4, loss = 0.45995586\n",
      "Iteration 5, loss = 0.39330298\n",
      "Iteration 6, loss = 0.45110636\n",
      "Iteration 7, loss = 0.41283199\n",
      "Iteration 8, loss = 0.35700699\n",
      "Iteration 9, loss = 0.66304564\n",
      "Iteration 10, loss = 0.48023092\n",
      "Iteration 11, loss = 0.46134800\n",
      "Iteration 12, loss = 0.39459116\n",
      "Iteration 13, loss = 0.45274336\n",
      "Iteration 14, loss = 0.38993267\n",
      "Iteration 15, loss = 0.36004091\n",
      "Iteration 16, loss = 0.36477428\n",
      "Iteration 17, loss = 0.33518509\n",
      "Iteration 18, loss = 0.34207610\n",
      "Iteration 19, loss = 0.32051481\n",
      "Iteration 20, loss = 0.31647514\n",
      "Iteration 21, loss = 0.29638535\n",
      "Iteration 22, loss = 0.71153102\n",
      "Iteration 23, loss = 0.39782014\n",
      "Iteration 24, loss = 0.41195333\n",
      "Iteration 25, loss = 0.64357266\n",
      "Iteration 26, loss = 0.49627516\n",
      "Iteration 27, loss = 0.43484208\n",
      "Iteration 28, loss = 0.37906057\n",
      "Iteration 29, loss = 0.36501045\n",
      "Iteration 30, loss = 0.34640361\n",
      "Iteration 31, loss = 0.32787030\n",
      "Iteration 32, loss = 0.39923591\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.84089327\n",
      "Iteration 2, loss = 1.39475229\n",
      "Iteration 3, loss = 1.13127222\n",
      "Iteration 4, loss = 0.96643241\n",
      "Iteration 5, loss = 0.85720137\n",
      "Iteration 6, loss = 0.84422763\n",
      "Iteration 7, loss = 0.76083984\n",
      "Iteration 8, loss = 0.72373467\n",
      "Iteration 9, loss = 0.68349657\n",
      "Iteration 10, loss = 0.66675225\n",
      "Iteration 11, loss = 0.64209874\n",
      "Iteration 12, loss = 0.62288580\n",
      "Iteration 13, loss = 0.60268322\n",
      "Iteration 14, loss = 0.59762597\n",
      "Iteration 15, loss = 0.59120565\n",
      "Iteration 16, loss = 0.57636310\n",
      "Iteration 17, loss = 0.56906621\n",
      "Iteration 18, loss = 0.56885758\n",
      "Iteration 19, loss = 0.55129115\n",
      "Iteration 20, loss = 0.57622890\n",
      "Iteration 21, loss = 0.54954012\n",
      "Iteration 22, loss = 0.57222017\n",
      "Iteration 23, loss = 0.54170125\n",
      "Iteration 24, loss = 0.53075627\n",
      "Iteration 25, loss = 0.52372610\n",
      "Iteration 26, loss = 0.52467645\n",
      "Iteration 27, loss = 0.51871563\n",
      "Iteration 28, loss = 0.53344590\n",
      "Iteration 29, loss = 0.54823696\n",
      "Iteration 30, loss = 0.51897683\n",
      "Iteration 31, loss = 0.50522891\n",
      "Iteration 32, loss = 0.51456141\n",
      "Iteration 33, loss = 0.52728821\n",
      "Iteration 34, loss = 1.47340643\n",
      "Iteration 35, loss = 1.76873625\n",
      "Iteration 36, loss = 1.25122529\n",
      "Iteration 37, loss = 1.15356338\n",
      "Iteration 38, loss = 1.03051082\n",
      "Iteration 39, loss = 0.98318339\n",
      "Iteration 40, loss = 0.93739317\n",
      "Iteration 41, loss = 0.91928678\n",
      "Iteration 42, loss = 0.93514164\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.47812686\n",
      "Iteration 2, loss = 0.73816803\n",
      "Iteration 3, loss = 0.63213124\n",
      "Iteration 4, loss = 0.56809844\n",
      "Iteration 5, loss = 0.50692383\n",
      "Iteration 6, loss = 0.48739506\n",
      "Iteration 7, loss = 0.51353816\n",
      "Iteration 8, loss = 0.49255814\n",
      "Iteration 9, loss = 0.45471420\n",
      "Iteration 10, loss = 0.43124233\n",
      "Iteration 11, loss = 0.40013433\n",
      "Iteration 12, loss = 0.39430705\n",
      "Iteration 13, loss = 0.41140295\n",
      "Iteration 14, loss = 0.39894046\n",
      "Iteration 15, loss = 0.38510873\n",
      "Iteration 16, loss = 0.36454621\n",
      "Iteration 17, loss = 0.37890938\n",
      "Iteration 18, loss = 0.36435622\n",
      "Iteration 19, loss = 0.36331098\n",
      "Iteration 20, loss = 0.34490327\n",
      "Iteration 21, loss = 0.33284327\n",
      "Iteration 22, loss = 0.34519269\n",
      "Iteration 23, loss = 0.31244302\n",
      "Iteration 24, loss = 0.33128668\n",
      "Iteration 25, loss = 0.32319676\n",
      "Iteration 26, loss = 0.31282297\n",
      "Iteration 27, loss = 0.31445834\n",
      "Iteration 28, loss = 0.41274291\n",
      "Iteration 29, loss = 0.37495820\n",
      "Iteration 30, loss = 0.31359306\n",
      "Iteration 31, loss = 0.31393311\n",
      "Iteration 32, loss = 0.29868357\n",
      "Iteration 33, loss = 0.30134986\n",
      "Iteration 34, loss = 0.28055239\n",
      "Iteration 35, loss = 0.29310264\n",
      "Iteration 36, loss = 0.28647951\n",
      "Iteration 37, loss = 0.28439421\n",
      "Iteration 38, loss = 0.33046076\n",
      "Iteration 39, loss = 0.27960135\n",
      "Iteration 40, loss = 0.28423358\n",
      "Iteration 41, loss = 0.26493067\n",
      "Iteration 42, loss = 0.27176481\n",
      "Iteration 43, loss = 0.26567867\n",
      "Iteration 44, loss = 0.29377811\n",
      "Iteration 45, loss = 0.26729730\n",
      "Iteration 46, loss = 0.28050072\n",
      "Iteration 47, loss = 0.28108608\n",
      "Iteration 48, loss = 0.25690810\n",
      "Iteration 49, loss = 0.26104747\n",
      "Iteration 50, loss = 0.25081542\n",
      "Iteration 51, loss = 0.25649392\n",
      "Iteration 52, loss = 0.25121622\n",
      "Iteration 53, loss = 0.26304968\n",
      "Iteration 54, loss = 0.24698444\n",
      "Iteration 55, loss = 0.23645386\n",
      "Iteration 56, loss = 0.23635087\n",
      "Iteration 57, loss = 0.24573184\n",
      "Iteration 58, loss = 0.24248504\n",
      "Iteration 59, loss = 0.24526971\n",
      "Iteration 60, loss = 0.23844518\n",
      "Iteration 61, loss = 0.24366308\n",
      "Iteration 62, loss = 0.23475595\n",
      "Iteration 63, loss = 0.22643031\n",
      "Iteration 64, loss = 0.23108593\n",
      "Iteration 65, loss = 0.25766316\n",
      "Iteration 66, loss = 0.23063070\n",
      "Iteration 67, loss = 0.23785128\n",
      "Iteration 68, loss = 0.23672513\n",
      "Iteration 69, loss = 0.26089222\n",
      "Iteration 70, loss = 0.24313597\n",
      "Iteration 71, loss = 0.22436975\n",
      "Iteration 72, loss = 0.23872738\n",
      "Iteration 73, loss = 0.24359126\n",
      "Iteration 74, loss = 0.23384364\n",
      "Iteration 75, loss = 0.22228993\n",
      "Iteration 76, loss = 0.23037981\n",
      "Iteration 77, loss = 0.22887317\n",
      "Iteration 78, loss = 0.23208773\n",
      "Iteration 79, loss = 0.22308755\n",
      "Iteration 80, loss = 0.23178489\n",
      "Iteration 81, loss = 0.20710480\n",
      "Iteration 82, loss = 0.20973970\n",
      "Iteration 83, loss = 0.25394484\n",
      "Iteration 84, loss = 0.23648744\n",
      "Iteration 85, loss = 0.21806455\n",
      "Iteration 86, loss = 0.22162626\n",
      "Iteration 87, loss = 0.20272058\n",
      "Iteration 88, loss = 0.20436409\n",
      "Iteration 89, loss = 0.21025667\n",
      "Iteration 90, loss = 0.21259611\n",
      "Iteration 91, loss = 0.20913785\n",
      "Iteration 92, loss = 0.21683930\n",
      "Iteration 93, loss = 0.20917763\n",
      "Iteration 94, loss = 0.19288805\n",
      "Iteration 95, loss = 0.20390904\n",
      "Iteration 96, loss = 0.19306797\n",
      "Iteration 97, loss = 0.19682158\n",
      "Iteration 98, loss = 0.21381140\n",
      "Iteration 99, loss = 0.18483303\n",
      "Iteration 100, loss = 0.20519774\n",
      "Iteration 101, loss = 0.20814403\n",
      "Iteration 102, loss = 0.21553376\n",
      "Iteration 103, loss = 0.19064844\n",
      "Iteration 104, loss = 0.20124774\n",
      "Iteration 105, loss = 0.18854075\n",
      "Iteration 106, loss = 0.17964442\n",
      "Iteration 107, loss = 0.20678386\n",
      "Iteration 108, loss = 0.17985402\n",
      "Iteration 109, loss = 0.56571356\n",
      "Iteration 110, loss = 0.26636352\n",
      "Iteration 111, loss = 0.22654799\n",
      "Iteration 112, loss = 0.21364766\n",
      "Iteration 113, loss = 0.19243328\n",
      "Iteration 114, loss = 0.18210003\n",
      "Iteration 115, loss = 0.19136812\n",
      "Iteration 116, loss = 0.19326513\n",
      "Iteration 117, loss = 0.18733121\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.43265026\n",
      "Iteration 2, loss = 0.73302256\n",
      "Iteration 3, loss = 0.61792099\n",
      "Iteration 4, loss = 0.56187861\n",
      "Iteration 5, loss = 0.52904453\n",
      "Iteration 6, loss = 0.50456673\n",
      "Iteration 7, loss = 0.49261185\n",
      "Iteration 8, loss = 0.46152060\n",
      "Iteration 9, loss = 0.46646010\n",
      "Iteration 10, loss = 0.45993505\n",
      "Iteration 11, loss = 0.43725617\n",
      "Iteration 12, loss = 0.42703447\n",
      "Iteration 13, loss = 0.41819507\n",
      "Iteration 14, loss = 0.39820639\n",
      "Iteration 15, loss = 0.40282804\n",
      "Iteration 16, loss = 0.40384032\n",
      "Iteration 17, loss = 0.38574252\n",
      "Iteration 18, loss = 0.38272427\n",
      "Iteration 19, loss = 0.38383109\n",
      "Iteration 20, loss = 0.35737548\n",
      "Iteration 21, loss = 0.35689991\n",
      "Iteration 22, loss = 0.35518858\n",
      "Iteration 23, loss = 0.34497760\n",
      "Iteration 24, loss = 0.34894880\n",
      "Iteration 25, loss = 0.34489139\n",
      "Iteration 26, loss = 0.36539210\n",
      "Iteration 27, loss = 0.33305123\n",
      "Iteration 28, loss = 0.33176847\n",
      "Iteration 29, loss = 0.33101995\n",
      "Iteration 30, loss = 0.31581445\n",
      "Iteration 31, loss = 0.32027335\n",
      "Iteration 32, loss = 0.32225134\n",
      "Iteration 33, loss = 0.30115830\n",
      "Iteration 34, loss = 0.32382102\n",
      "Iteration 35, loss = 0.31462420\n",
      "Iteration 36, loss = 0.30086657\n",
      "Iteration 37, loss = 0.29941288\n",
      "Iteration 38, loss = 0.33555473\n",
      "Iteration 39, loss = 0.29514780\n",
      "Iteration 40, loss = 0.30944644\n",
      "Iteration 41, loss = 0.30892096\n",
      "Iteration 42, loss = 0.28857067\n",
      "Iteration 43, loss = 0.28820708\n",
      "Iteration 44, loss = 0.29276431\n",
      "Iteration 45, loss = 0.28980412\n",
      "Iteration 46, loss = 0.28127675\n",
      "Iteration 47, loss = 0.28327734\n",
      "Iteration 48, loss = 0.28034723\n",
      "Iteration 49, loss = 0.28572546\n",
      "Iteration 50, loss = 0.26575385\n",
      "Iteration 51, loss = 0.29739600\n",
      "Iteration 52, loss = 0.26321357\n",
      "Iteration 53, loss = 0.29254103\n",
      "Iteration 54, loss = 0.26331461\n",
      "Iteration 55, loss = 0.25552655\n",
      "Iteration 56, loss = 0.25405729\n",
      "Iteration 57, loss = 0.28983475\n",
      "Iteration 58, loss = 0.28146049\n",
      "Iteration 59, loss = 0.29335056\n",
      "Iteration 60, loss = 0.26411946\n",
      "Iteration 61, loss = 0.29048674\n",
      "Iteration 62, loss = 0.26290093\n",
      "Iteration 63, loss = 0.24871421\n",
      "Iteration 64, loss = 0.25379767\n",
      "Iteration 65, loss = 0.23998605\n",
      "Iteration 66, loss = 0.23194434\n",
      "Iteration 67, loss = 0.23204382\n",
      "Iteration 68, loss = 0.23915403\n",
      "Iteration 69, loss = 0.24420005\n",
      "Iteration 70, loss = 0.23950136\n",
      "Iteration 71, loss = 0.23902402\n",
      "Iteration 72, loss = 0.21947924\n",
      "Iteration 73, loss = 0.24039201\n",
      "Iteration 74, loss = 0.21500253\n",
      "Iteration 75, loss = 0.25026627\n",
      "Iteration 76, loss = 0.22561631\n",
      "Iteration 77, loss = 0.20644827\n",
      "Iteration 78, loss = 0.23424444\n",
      "Iteration 79, loss = 0.23582727\n",
      "Iteration 80, loss = 0.25582892\n",
      "Iteration 81, loss = 0.23586747\n",
      "Iteration 82, loss = 0.23526695\n",
      "Iteration 83, loss = 0.22130146\n",
      "Iteration 84, loss = 0.21714597\n",
      "Iteration 85, loss = 0.21388218\n",
      "Iteration 86, loss = 0.21067858\n",
      "Iteration 87, loss = 0.22727139\n",
      "Iteration 88, loss = 0.20862679\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.44329303\n",
      "Iteration 2, loss = 0.77944947\n",
      "Iteration 3, loss = 0.72087906\n",
      "Iteration 4, loss = 0.58661283\n",
      "Iteration 5, loss = 1.62452961\n",
      "Iteration 6, loss = 0.91373269\n",
      "Iteration 7, loss = 0.78935941\n",
      "Iteration 8, loss = 0.72713995\n",
      "Iteration 9, loss = 1.08268876\n",
      "Iteration 10, loss = 0.92788829\n",
      "Iteration 11, loss = 0.85936298\n",
      "Iteration 12, loss = 1.95358864\n",
      "Iteration 13, loss = 1.65298265\n",
      "Iteration 14, loss = 1.57134695\n",
      "Iteration 15, loss = 1.54010208\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.41499985\n",
      "Iteration 2, loss = 2.32705762\n",
      "Iteration 3, loss = 1.45838333\n",
      "Iteration 4, loss = 1.32128611\n",
      "Iteration 5, loss = 1.36950561\n",
      "Iteration 6, loss = 1.21021396\n",
      "Iteration 7, loss = 1.14260721\n",
      "Iteration 8, loss = 1.19693529\n",
      "Iteration 9, loss = 1.13621194\n",
      "Iteration 10, loss = 1.48988759\n",
      "Iteration 11, loss = 1.33997743\n",
      "Iteration 12, loss = 1.05887837\n",
      "Iteration 13, loss = 0.95278961\n",
      "Iteration 14, loss = 0.92491071\n",
      "Iteration 15, loss = 1.15607357\n",
      "Iteration 16, loss = 3.01193258\n",
      "Iteration 17, loss = 2.01800067\n",
      "Iteration 18, loss = 1.95493749\n",
      "Iteration 19, loss = 1.92685320\n",
      "Iteration 20, loss = 1.89594711\n",
      "Iteration 21, loss = 1.81443916\n",
      "Iteration 22, loss = 1.77688143\n",
      "Iteration 23, loss = 1.74013686\n",
      "Iteration 24, loss = 1.84807164\n",
      "Iteration 25, loss = 1.88971430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.12259615\n",
      "Iteration 2, loss = 0.59589998\n",
      "Iteration 3, loss = 0.48611037\n",
      "Iteration 4, loss = 0.43263192\n",
      "Iteration 5, loss = 0.40112420\n",
      "Iteration 6, loss = 0.36992622\n",
      "Iteration 7, loss = 0.34561137\n",
      "Iteration 8, loss = 0.33577860\n",
      "Iteration 9, loss = 0.31482304\n",
      "Iteration 10, loss = 0.30403356\n",
      "Iteration 11, loss = 0.28210492\n",
      "Iteration 12, loss = 0.26311062\n",
      "Iteration 13, loss = 0.27518812\n",
      "Iteration 14, loss = 0.25172849\n",
      "Iteration 15, loss = 0.24119889\n",
      "Iteration 16, loss = 0.24117713\n",
      "Iteration 17, loss = 0.22292244\n",
      "Iteration 18, loss = 0.21680933\n",
      "Iteration 19, loss = 0.22034830\n",
      "Iteration 20, loss = 0.20082928\n",
      "Iteration 21, loss = 0.20918799\n",
      "Iteration 22, loss = 0.19524339\n",
      "Iteration 23, loss = 0.18323115\n",
      "Iteration 24, loss = 0.18271267\n",
      "Iteration 25, loss = 0.17582881\n",
      "Iteration 26, loss = 0.17248091\n",
      "Iteration 27, loss = 0.17048458\n",
      "Iteration 28, loss = 0.15727011\n",
      "Iteration 29, loss = 0.16827335\n",
      "Iteration 30, loss = 0.14842343\n",
      "Iteration 31, loss = 0.15401044\n",
      "Iteration 32, loss = 0.13625980\n",
      "Iteration 33, loss = 0.14164629\n",
      "Iteration 34, loss = 0.15293754\n",
      "Iteration 35, loss = 0.14428888\n",
      "Iteration 36, loss = 0.13915212\n",
      "Iteration 37, loss = 0.12310985\n",
      "Iteration 38, loss = 0.11031355\n",
      "Iteration 39, loss = 0.11124374\n",
      "Iteration 40, loss = 0.12552974\n",
      "Iteration 41, loss = 0.10048862\n",
      "Iteration 42, loss = 0.11529010\n",
      "Iteration 43, loss = 0.11343625\n",
      "Iteration 44, loss = 0.10825687\n",
      "Iteration 45, loss = 0.10907563\n",
      "Iteration 46, loss = 0.09045070\n",
      "Iteration 47, loss = 0.10194530\n",
      "Iteration 48, loss = 0.11071984\n",
      "Iteration 49, loss = 0.08618187\n",
      "Iteration 50, loss = 0.09038165\n",
      "Iteration 51, loss = 0.07677739\n",
      "Iteration 52, loss = 0.09248351\n",
      "Iteration 53, loss = 0.08043409\n",
      "Iteration 54, loss = 0.11901182\n",
      "Iteration 55, loss = 0.09562677\n",
      "Iteration 56, loss = 0.11788353\n",
      "Iteration 57, loss = 0.09822333\n",
      "Iteration 58, loss = 0.06790049\n",
      "Iteration 59, loss = 0.07365600\n",
      "Iteration 60, loss = 0.11158846\n",
      "Iteration 61, loss = 0.11188904\n",
      "Iteration 62, loss = 0.07827761\n",
      "Iteration 63, loss = 0.06648812\n",
      "Iteration 64, loss = 0.06928325\n",
      "Iteration 65, loss = 0.06823151\n",
      "Iteration 66, loss = 0.06417077\n",
      "Iteration 67, loss = 0.05549356\n",
      "Iteration 68, loss = 0.06765118\n",
      "Iteration 69, loss = 0.06006038\n",
      "Iteration 70, loss = 0.06483104\n",
      "Iteration 71, loss = 0.16701423\n",
      "Iteration 72, loss = 0.10122752\n",
      "Iteration 73, loss = 0.09613315\n",
      "Iteration 74, loss = 0.07296692\n",
      "Iteration 75, loss = 0.06763369\n",
      "Iteration 76, loss = 0.06949719\n",
      "Iteration 77, loss = 0.05575737\n",
      "Iteration 78, loss = 0.06729903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.10457028\n",
      "Iteration 2, loss = 0.57882744\n",
      "Iteration 3, loss = 0.47585461\n",
      "Iteration 4, loss = 0.45950141\n",
      "Iteration 5, loss = 0.40071170\n",
      "Iteration 6, loss = 0.36685423\n",
      "Iteration 7, loss = 0.34511513\n",
      "Iteration 8, loss = 0.33061465\n",
      "Iteration 9, loss = 0.32070730\n",
      "Iteration 10, loss = 0.30458387\n",
      "Iteration 11, loss = 0.29322219\n",
      "Iteration 12, loss = 0.28049781\n",
      "Iteration 13, loss = 0.26919110\n",
      "Iteration 14, loss = 0.27098797\n",
      "Iteration 15, loss = 0.24321702\n",
      "Iteration 16, loss = 0.23319691\n",
      "Iteration 17, loss = 0.22827727\n",
      "Iteration 18, loss = 0.23977906\n",
      "Iteration 19, loss = 0.22118714\n",
      "Iteration 20, loss = 0.20075289\n",
      "Iteration 21, loss = 0.21712296\n",
      "Iteration 22, loss = 0.19904749\n",
      "Iteration 23, loss = 0.20783637\n",
      "Iteration 24, loss = 0.18281948\n",
      "Iteration 25, loss = 0.16268356\n",
      "Iteration 26, loss = 0.16958789\n",
      "Iteration 27, loss = 0.16867939\n",
      "Iteration 28, loss = 0.19662574\n",
      "Iteration 29, loss = 0.18895373\n",
      "Iteration 30, loss = 0.18134919\n",
      "Iteration 31, loss = 0.17046345\n",
      "Iteration 32, loss = 0.15653918\n",
      "Iteration 33, loss = 0.16942795\n",
      "Iteration 34, loss = 0.15108823\n",
      "Iteration 35, loss = 0.15551843\n",
      "Iteration 36, loss = 0.16438849\n",
      "Iteration 37, loss = 0.15560332\n",
      "Iteration 38, loss = 0.13011805\n",
      "Iteration 39, loss = 0.12928418\n",
      "Iteration 40, loss = 0.13135440\n",
      "Iteration 41, loss = 0.11305309\n",
      "Iteration 42, loss = 0.11199520\n",
      "Iteration 43, loss = 0.11137165\n",
      "Iteration 44, loss = 0.10356760\n",
      "Iteration 45, loss = 0.15995184\n",
      "Iteration 46, loss = 0.17336930\n",
      "Iteration 47, loss = 0.14637877\n",
      "Iteration 48, loss = 0.11224395\n",
      "Iteration 49, loss = 0.09467953\n",
      "Iteration 50, loss = 0.09351985\n",
      "Iteration 51, loss = 0.10202888\n",
      "Iteration 52, loss = 0.09911313\n",
      "Iteration 53, loss = 0.08949448\n",
      "Iteration 54, loss = 0.08516579\n",
      "Iteration 55, loss = 0.07355308\n",
      "Iteration 56, loss = 0.07691197\n",
      "Iteration 57, loss = 0.07818355\n",
      "Iteration 58, loss = 0.09324782\n",
      "Iteration 59, loss = 0.06374114\n",
      "Iteration 60, loss = 0.05595879\n",
      "Iteration 61, loss = 0.07463959\n",
      "Iteration 62, loss = 0.07391500\n",
      "Iteration 63, loss = 0.05412275\n",
      "Iteration 64, loss = 0.16564332\n",
      "Iteration 65, loss = 0.09166402\n",
      "Iteration 66, loss = 0.08821589\n",
      "Iteration 67, loss = 0.09539714\n",
      "Iteration 68, loss = 0.09377336\n",
      "Iteration 69, loss = 0.06745688\n",
      "Iteration 70, loss = 0.07441593\n",
      "Iteration 71, loss = 0.09974486\n",
      "Iteration 72, loss = 0.06857011\n",
      "Iteration 73, loss = 0.05090682\n",
      "Iteration 74, loss = 0.04253570\n",
      "Iteration 75, loss = 0.04486135\n",
      "Iteration 76, loss = 0.03167603\n",
      "Iteration 77, loss = 0.04294601\n",
      "Iteration 78, loss = 0.04499874\n",
      "Iteration 79, loss = 0.03313090\n",
      "Iteration 80, loss = 0.03560896\n",
      "Iteration 81, loss = 0.07824119\n",
      "Iteration 82, loss = 0.06267140\n",
      "Iteration 83, loss = 0.08594314\n",
      "Iteration 84, loss = 0.09014169\n",
      "Iteration 85, loss = 0.06648353\n",
      "Iteration 86, loss = 0.03588962\n",
      "Iteration 87, loss = 0.05125389\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.13246379\n",
      "Iteration 2, loss = 0.58441770\n",
      "Iteration 3, loss = 0.48426837\n",
      "Iteration 4, loss = 0.43400413\n",
      "Iteration 5, loss = 0.40280463\n",
      "Iteration 6, loss = 0.36859201\n",
      "Iteration 7, loss = 0.35340235\n",
      "Iteration 8, loss = 0.32720620\n",
      "Iteration 9, loss = 0.31874064\n",
      "Iteration 10, loss = 0.32164369\n",
      "Iteration 11, loss = 0.30525465\n",
      "Iteration 12, loss = 0.29049715\n",
      "Iteration 13, loss = 0.28087424\n",
      "Iteration 14, loss = 0.30348707\n",
      "Iteration 15, loss = 0.27004166\n",
      "Iteration 16, loss = 0.24874270\n",
      "Iteration 17, loss = 0.23933336\n",
      "Iteration 18, loss = 0.22945508\n",
      "Iteration 19, loss = 0.21801747\n",
      "Iteration 20, loss = 0.21777952\n",
      "Iteration 21, loss = 0.22045028\n",
      "Iteration 22, loss = 0.22393378\n",
      "Iteration 23, loss = 0.20326927\n",
      "Iteration 24, loss = 0.20056679\n",
      "Iteration 25, loss = 0.23518834\n",
      "Iteration 26, loss = 0.21701862\n",
      "Iteration 27, loss = 0.20001689\n",
      "Iteration 28, loss = 0.19299560\n",
      "Iteration 29, loss = 0.19211479\n",
      "Iteration 30, loss = 0.21000759\n",
      "Iteration 31, loss = 0.17751303\n",
      "Iteration 32, loss = 0.18031128\n",
      "Iteration 33, loss = 0.16468157\n",
      "Iteration 34, loss = 0.15005917\n",
      "Iteration 35, loss = 0.14817491\n",
      "Iteration 36, loss = 0.15204634\n",
      "Iteration 37, loss = 0.14367375\n",
      "Iteration 38, loss = 0.13914354\n",
      "Iteration 39, loss = 0.13994704\n",
      "Iteration 40, loss = 0.14079468\n",
      "Iteration 41, loss = 0.13877829\n",
      "Iteration 42, loss = 0.12578072\n",
      "Iteration 43, loss = 0.12328911\n",
      "Iteration 44, loss = 0.12867598\n",
      "Iteration 45, loss = 0.12392072\n",
      "Iteration 46, loss = 0.11452689\n",
      "Iteration 47, loss = 0.12849008\n",
      "Iteration 48, loss = 0.11591898\n",
      "Iteration 49, loss = 0.10367754\n",
      "Iteration 50, loss = 0.11220204\n",
      "Iteration 51, loss = 0.15714743\n",
      "Iteration 52, loss = 0.12682733\n",
      "Iteration 53, loss = 0.11095619\n",
      "Iteration 54, loss = 0.09183740\n",
      "Iteration 55, loss = 0.10302319\n",
      "Iteration 56, loss = 0.13158280\n",
      "Iteration 57, loss = 0.12197806\n",
      "Iteration 58, loss = 0.10082602\n",
      "Iteration 59, loss = 0.09924909\n",
      "Iteration 60, loss = 0.08685848\n",
      "Iteration 61, loss = 0.06960734\n",
      "Iteration 62, loss = 0.07371734\n",
      "Iteration 63, loss = 0.09822364\n",
      "Iteration 64, loss = 0.10558347\n",
      "Iteration 65, loss = 0.08481448\n",
      "Iteration 66, loss = 0.07338780\n",
      "Iteration 67, loss = 0.09682720\n",
      "Iteration 68, loss = 0.09596676\n",
      "Iteration 69, loss = 0.07087436\n",
      "Iteration 70, loss = 0.06745942\n",
      "Iteration 71, loss = 0.12770572\n",
      "Iteration 72, loss = 0.10367396\n",
      "Iteration 73, loss = 0.09117505\n",
      "Iteration 74, loss = 0.08310886\n",
      "Iteration 75, loss = 0.07580097\n",
      "Iteration 76, loss = 0.07241913\n",
      "Iteration 77, loss = 0.05895162\n",
      "Iteration 78, loss = 0.07480047\n",
      "Iteration 79, loss = 0.06656299\n",
      "Iteration 80, loss = 0.08768530\n",
      "Iteration 81, loss = 0.07437820\n",
      "Iteration 82, loss = 0.06428540\n",
      "Iteration 83, loss = 0.04891051\n",
      "Iteration 84, loss = 0.04552503\n",
      "Iteration 85, loss = 0.04990636\n",
      "Iteration 86, loss = 0.05543258\n",
      "Iteration 87, loss = 0.04747034\n",
      "Iteration 88, loss = 0.04234903\n",
      "Iteration 89, loss = 0.04582268\n",
      "Iteration 90, loss = 0.11246314\n",
      "Iteration 91, loss = 0.09392291\n",
      "Iteration 92, loss = 0.06690448\n",
      "Iteration 93, loss = 0.04243869\n",
      "Iteration 94, loss = 0.04698095\n",
      "Iteration 95, loss = 0.02768445\n",
      "Iteration 96, loss = 0.03839472\n",
      "Iteration 97, loss = 0.05145554\n",
      "Iteration 98, loss = 0.06127568\n",
      "Iteration 99, loss = 0.04623384\n",
      "Iteration 100, loss = 0.04397697\n",
      "Iteration 101, loss = 0.03818874\n",
      "Iteration 102, loss = 0.04759340\n",
      "Iteration 103, loss = 0.05241010\n",
      "Iteration 104, loss = 0.04364079\n",
      "Iteration 105, loss = 0.04649350\n",
      "Iteration 106, loss = 0.02824534\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.19892904\n",
      "Iteration 2, loss = 0.91920653\n",
      "Iteration 3, loss = 0.81259248\n",
      "Iteration 4, loss = 0.59893549\n",
      "Iteration 5, loss = 0.66979186\n",
      "Iteration 6, loss = 0.49432545\n",
      "Iteration 7, loss = 0.46297736\n",
      "Iteration 8, loss = 0.42109196\n",
      "Iteration 9, loss = 0.39298016\n",
      "Iteration 10, loss = 3.48943744\n",
      "Iteration 11, loss = 1.11872089\n",
      "Iteration 12, loss = 1.79308628\n",
      "Iteration 13, loss = 1.23246690\n",
      "Iteration 14, loss = 1.21557243\n",
      "Iteration 15, loss = 1.15380710\n",
      "Iteration 16, loss = 0.98476902\n",
      "Iteration 17, loss = 0.97621656\n",
      "Iteration 18, loss = 0.82822794\n",
      "Iteration 19, loss = 1.19588008\n",
      "Iteration 20, loss = 2.06196731\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.25506462\n",
      "Iteration 2, loss = 0.59283585\n",
      "Iteration 3, loss = 1.09001377\n",
      "Iteration 4, loss = 0.56890111\n",
      "Iteration 5, loss = 0.57212580\n",
      "Iteration 6, loss = 0.44372883\n",
      "Iteration 7, loss = 0.79185383\n",
      "Iteration 8, loss = 0.53808237\n",
      "Iteration 9, loss = 0.48600943\n",
      "Iteration 10, loss = 0.44995299\n",
      "Iteration 11, loss = 0.44764110\n",
      "Iteration 12, loss = 0.57416932\n",
      "Iteration 13, loss = 0.48898452\n",
      "Iteration 14, loss = 0.46319559\n",
      "Iteration 15, loss = 1.05515843\n",
      "Iteration 16, loss = 0.85691020\n",
      "Iteration 17, loss = 0.60303446\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88510995\n",
      "Iteration 2, loss = 0.51256110\n",
      "Iteration 3, loss = 0.44223197\n",
      "Iteration 4, loss = 0.40297575\n",
      "Iteration 5, loss = 0.38147668\n",
      "Iteration 6, loss = 0.35580140\n",
      "Iteration 7, loss = 0.33476005\n",
      "Iteration 8, loss = 0.32376834\n",
      "Iteration 9, loss = 0.30806499\n",
      "Iteration 10, loss = 0.29380320\n",
      "Iteration 11, loss = 0.28406976\n",
      "Iteration 12, loss = 0.26436643\n",
      "Iteration 13, loss = 0.25925779\n",
      "Iteration 14, loss = 0.24928717\n",
      "Iteration 15, loss = 0.24266456\n",
      "Iteration 16, loss = 0.23457316\n",
      "Iteration 17, loss = 0.22443935\n",
      "Iteration 18, loss = 0.21679899\n",
      "Iteration 19, loss = 0.21856910\n",
      "Iteration 20, loss = 0.21416960\n",
      "Iteration 21, loss = 0.20045099\n",
      "Iteration 22, loss = 0.19231793\n",
      "Iteration 23, loss = 0.18432897\n",
      "Iteration 24, loss = 0.19198251\n",
      "Iteration 25, loss = 0.18044770\n",
      "Iteration 26, loss = 0.16924041\n",
      "Iteration 27, loss = 0.16702749\n",
      "Iteration 28, loss = 0.16480466\n",
      "Iteration 29, loss = 0.15405776\n",
      "Iteration 30, loss = 0.14869016\n",
      "Iteration 31, loss = 0.14612177\n",
      "Iteration 32, loss = 0.14029347\n",
      "Iteration 33, loss = 0.13947746\n",
      "Iteration 34, loss = 0.13861119\n",
      "Iteration 35, loss = 0.12718607\n",
      "Iteration 36, loss = 0.12079113\n",
      "Iteration 37, loss = 0.12821260\n",
      "Iteration 38, loss = 0.11510364\n",
      "Iteration 39, loss = 0.12051772\n",
      "Iteration 40, loss = 0.11608399\n",
      "Iteration 41, loss = 0.12183287\n",
      "Iteration 42, loss = 0.11516636\n",
      "Iteration 43, loss = 0.10798001\n",
      "Iteration 44, loss = 0.10585474\n",
      "Iteration 45, loss = 0.10285969\n",
      "Iteration 46, loss = 0.09777207\n",
      "Iteration 47, loss = 0.08629521\n",
      "Iteration 48, loss = 0.08341741\n",
      "Iteration 49, loss = 0.10922173\n",
      "Iteration 50, loss = 0.08678731\n",
      "Iteration 51, loss = 0.08241087\n",
      "Iteration 52, loss = 0.07652578\n",
      "Iteration 53, loss = 0.07837619\n",
      "Iteration 54, loss = 0.08211695\n",
      "Iteration 55, loss = 0.07303857\n",
      "Iteration 56, loss = 0.07847580\n",
      "Iteration 57, loss = 0.08074447\n",
      "Iteration 58, loss = 0.06854104\n",
      "Iteration 59, loss = 0.07323751\n",
      "Iteration 60, loss = 0.05837728\n",
      "Iteration 61, loss = 0.06677372\n",
      "Iteration 62, loss = 0.05537075\n",
      "Iteration 63, loss = 0.05050763\n",
      "Iteration 64, loss = 0.05686977\n",
      "Iteration 65, loss = 0.06164745\n",
      "Iteration 66, loss = 0.06805677\n",
      "Iteration 67, loss = 0.07224046\n",
      "Iteration 68, loss = 0.06854856\n",
      "Iteration 69, loss = 0.05416094\n",
      "Iteration 70, loss = 0.04671839\n",
      "Iteration 71, loss = 0.04879967\n",
      "Iteration 72, loss = 0.04517569\n",
      "Iteration 73, loss = 0.04324604\n",
      "Iteration 74, loss = 0.03114111\n",
      "Iteration 75, loss = 0.03781226\n",
      "Iteration 76, loss = 0.04244641\n",
      "Iteration 77, loss = 0.03680192\n",
      "Iteration 78, loss = 0.04645543\n",
      "Iteration 79, loss = 0.04186309\n",
      "Iteration 80, loss = 0.03204624\n",
      "Iteration 81, loss = 0.04232249\n",
      "Iteration 82, loss = 0.05694123\n",
      "Iteration 83, loss = 0.03650886\n",
      "Iteration 84, loss = 0.04458005\n",
      "Iteration 85, loss = 0.03235036\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "(50,)\n",
      "Score with best parameters:\n",
      "0.7695\n",
      "\n",
      "All scores on the grid:\n",
      "[0.7065 0.7695 0.5437 0.7087]\n",
      "[0.81078382 0.85721418 0.62156765 0.85921118]\n",
      "[0.79170829 0.84715285 0.83116883 0.85114885]\n",
      "[0.78510745 0.85157421 0.81109445 0.84207896]\n",
      "[0.52402402 0.498999   0.26626627 0.25775776]\n",
      "[0.62024048 0.79208417 0.18687375 0.73246493]\n"
     ]
    }
   ],
   "source": [
    "#for NN we try the same architectures as before\n",
    "hl_parameters = {'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,)]}\n",
    "\n",
    "mlp_large_cv = MLPClassifier(max_iter = 300, alpha = 1e-4, solver = 'sgd', learning_rate_init = .1, random_state = ID, verbose = True)#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "#ADD YOUR CODE\n",
    "grid_large_cv = GridSearchCV(mlp_large_cv, hl_parameters, cv = 5)\n",
    "grid_large_cv.fit(X_train, y_train)\n",
    "best_architecture = grid_large_cv.best_params_['hidden_layer_sizes']\n",
    "print(best_architecture)\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "best_score = grid_large_cv.best_score_\n",
    "print(best_score)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "#ADD YOUR CODE\n",
    "\n",
    "grid_score = grid_large_cv.cv_results_\n",
    "print(grid_score['mean_test_score'])\n",
    "\n",
    "#Printing the results for each k fold\n",
    "print(grid_score['split0_test_score'])\n",
    "print(grid_score['split1_test_score'])\n",
    "print(grid_score['split2_test_score'])\n",
    "print(grid_score['split3_test_score'])\n",
    "print(grid_score['split4_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Describe your architecture choices and the results you observe with respect to the architectures you used.\n",
    "\n",
    "Unfortunately I wasn't able to try more architectures in this step because the computational power required to finish all the calculations. But what I've noticed in this step, is that the architecture with one hidden layern (i.e. (50,)) is the one whose gives the best score. This is surprisingly because I thought that the architecture with the best score could be again the 2 hidden layers architecture. This results is really interesting because the architecture with one hidden layer uses much less computational power than others. So in this case we can obtain the best score with less computational power which is the result we wish to obtain always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "\n",
    "Get the train and test error for the best NN you obtained with 10000 points. This time you can run for 100 iterations if you cannot run for 300 iterations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88510995\n",
      "Iteration 2, loss = 0.51256110\n",
      "Iteration 3, loss = 0.44223197\n",
      "Iteration 4, loss = 0.40297575\n",
      "Iteration 5, loss = 0.38147668\n",
      "Iteration 6, loss = 0.35580140\n",
      "Iteration 7, loss = 0.33476005\n",
      "Iteration 8, loss = 0.32376834\n",
      "Iteration 9, loss = 0.30806499\n",
      "Iteration 10, loss = 0.29380320\n",
      "Iteration 11, loss = 0.28406976\n",
      "Iteration 12, loss = 0.26436643\n",
      "Iteration 13, loss = 0.25925779\n",
      "Iteration 14, loss = 0.24928717\n",
      "Iteration 15, loss = 0.24266456\n",
      "Iteration 16, loss = 0.23457316\n",
      "Iteration 17, loss = 0.22443935\n",
      "Iteration 18, loss = 0.21679899\n",
      "Iteration 19, loss = 0.21856910\n",
      "Iteration 20, loss = 0.21416960\n",
      "Iteration 21, loss = 0.20045099\n",
      "Iteration 22, loss = 0.19231793\n",
      "Iteration 23, loss = 0.18432897\n",
      "Iteration 24, loss = 0.19198251\n",
      "Iteration 25, loss = 0.18044770\n",
      "Iteration 26, loss = 0.16924041\n",
      "Iteration 27, loss = 0.16702749\n",
      "Iteration 28, loss = 0.16480466\n",
      "Iteration 29, loss = 0.15405776\n",
      "Iteration 30, loss = 0.14869016\n",
      "Iteration 31, loss = 0.14612177\n",
      "Iteration 32, loss = 0.14029347\n",
      "Iteration 33, loss = 0.13947746\n",
      "Iteration 34, loss = 0.13861119\n",
      "Iteration 35, loss = 0.12718607\n",
      "Iteration 36, loss = 0.12079113\n",
      "Iteration 37, loss = 0.12821260\n",
      "Iteration 38, loss = 0.11510364\n",
      "Iteration 39, loss = 0.12051772\n",
      "Iteration 40, loss = 0.11608399\n",
      "Iteration 41, loss = 0.12183287\n",
      "Iteration 42, loss = 0.11516636\n",
      "Iteration 43, loss = 0.10798001\n",
      "Iteration 44, loss = 0.10585474\n",
      "Iteration 45, loss = 0.10285969\n",
      "Iteration 46, loss = 0.09777207\n",
      "Iteration 47, loss = 0.08629521\n",
      "Iteration 48, loss = 0.08341741\n",
      "Iteration 49, loss = 0.10922173\n",
      "Iteration 50, loss = 0.08678731\n",
      "Iteration 51, loss = 0.08241087\n",
      "Iteration 52, loss = 0.07652578\n",
      "Iteration 53, loss = 0.07837619\n",
      "Iteration 54, loss = 0.08211695\n",
      "Iteration 55, loss = 0.07303857\n",
      "Iteration 56, loss = 0.07847580\n",
      "Iteration 57, loss = 0.08074447\n",
      "Iteration 58, loss = 0.06854104\n",
      "Iteration 59, loss = 0.07323751\n",
      "Iteration 60, loss = 0.05837728\n",
      "Iteration 61, loss = 0.06677372\n",
      "Iteration 62, loss = 0.05537075\n",
      "Iteration 63, loss = 0.05050763\n",
      "Iteration 64, loss = 0.05686977\n",
      "Iteration 65, loss = 0.06164745\n",
      "Iteration 66, loss = 0.06805677\n",
      "Iteration 67, loss = 0.07224046\n",
      "Iteration 68, loss = 0.06854856\n",
      "Iteration 69, loss = 0.05416094\n",
      "Iteration 70, loss = 0.04671839\n",
      "Iteration 71, loss = 0.04879967\n",
      "Iteration 72, loss = 0.04517569\n",
      "Iteration 73, loss = 0.04324604\n",
      "Iteration 74, loss = 0.03114111\n",
      "Iteration 75, loss = 0.03781226\n",
      "Iteration 76, loss = 0.04244641\n",
      "Iteration 77, loss = 0.03680192\n",
      "Iteration 78, loss = 0.04645543\n",
      "Iteration 79, loss = 0.04186309\n",
      "Iteration 80, loss = 0.03204624\n",
      "Iteration 81, loss = 0.04232249\n",
      "Iteration 82, loss = 0.05694123\n",
      "Iteration 83, loss = 0.03650886\n",
      "Iteration 84, loss = 0.04458005\n",
      "Iteration 85, loss = 0.03235036\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "RESULTS FOR BEST NN\n",
      "\n",
      "Best NN training error: 0.005800\n",
      "Best NN test error: 0.147500\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best NN model from CV\n",
    "\n",
    "best_mlp_large = MLPClassifier(hidden_layer_sizes = best_architecture, max_iter = 300, alpha = 1e-4, solver = 'sgd', learning_rate_init = .1, random_state = ID, verbose = True).fit(X_train, y_train)#ADD YOUR CODE\n",
    "\n",
    "training_error = 1. - best_mlp_large.score(X_train, y_train)#ADD YOUR CODE\n",
    "\n",
    "test_error = 1. - best_mlp_large.score(X_test, y_test)#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR BEST NN\\n')\n",
    "\n",
    "print (\"Best NN training error: %f\" % training_error)\n",
    "print (\"Best NN test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "\n",
    "Compare the train and test error you got with a large number of samples with the best one you obtained with only 500 data points. Are the architectures the same or do they differ? What about the errors you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "The architectures are not the same. In the previous step, the best architecture was the 2 hidden layer architecture (100, 100). In this step instead the best one was the one hidden layer architecture (50,).\n",
    "The (50,) architecture with 10000 elements in the set size gives lower error thant (100, 100) architecture with only 500 elements. One thing that I could say is that it's true that the latest architecture gives lower error, but it uses 10000 data samples. The computational power for this reason is too much higher. We have to consider also how much data we are able to obtain for the training. To obtain much more data in an real application increases the costs. Also since we have much more data, the computational power is much more higher so if we deploy the ML algorithm on a server, the costs could encrease a lot. \n",
    "\n",
    "So with those considerations in mind, the results of the first architecture with 500 samples for the training set are not too bad at the end. We should not consider only the lower error in general. Depends by the application type, the costs for the application, the time to complete the project and the maximum error we can accept. (e.g. in medical applications we want to have the lowest error possible, despite the costs to obtain this results. In a commercial application perhaps we could accept an error of 20%. Obviously depends by the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 8\n",
    "\n",
    "Plot an image that was missclassified by NN with m=500 training data points and it is now instead correctly classified by NN with m=10000 training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong prediction is 6\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n"
     ]
    }
   ],
   "source": [
    "#ADD YOUR CODE\n",
    "\n",
    "y_prediction = mlp.predict(X_test)\n",
    "y_prediction_large = best_mlp_large.predict(X_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if (y_prediction_large[i] == y_test[i]) and (y_prediction[i] != y_prediction_large[i]):\n",
    "        print(\"Wrong prediction is \" + str(y_prediction[i]))\n",
    "        plot_input(X_test, y_test, i)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some of the weigths of the multi-layer perceptron classifier, for the best NN we get with 500 data points and with 10000 data points. The code below plots the weights in a matrix form, where a figure represents all the weights of the edges entering in a hidden node. Notice that the code assumes that the NNs are called \"mlp\" and \"best_mlp_large\": you may need to replace such variables with your variable names. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights with 500 data points:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights with 10000 data points:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAADuCAYAAACqLcX5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOx9d3hc5Zn9mT4ajTQjyWpWtSXhJvduWoA4oRMgkDiUQAwhZQnZhGyekE2WVLKbQCCQkISlhJBQE0pC77YBVzAEV8m2ZPUujTTSSKOZ+f0xv3PuVcE8ygPLePeef2RLM3fmvvf73ve89bMlEglYsGDBgoWxsH/UX8CCBQsWUhGWcrRgwYKFSWApRwsWLFiYBJZytGDBgoVJYClHCxYsWJgElnK0YMGChUlgKUcLFixYmASWcrRgwYKFSWApRwsWLFiYBM6pvNjv9yeys7MBAOyssdlsAIDR0VEAgMPhQDQaTV7c6Rzz2sne19PTg+LiYgCA3Z7U1UNDQ4hEIgCAtLS0Mdd3Op1wOBxjfjf+M8Z/r3g8jr6+PgwODtqmcr//k0hPT08Eg0E4HI4JMuJPygQwZBuPxyWPeDw+5qfD4dC/zdfi64eHh8dca3R0FB6PZ8z3Gh0d1XMZ/6ydTidsNhu6u7sxMDCQsrL1+XyJYDCIRCIBl8sFwFgvvLdYLKZ/U852u11rmb8rKioCkFyjsVgMgCHvRCKBrKwsAEA4HAZgyHh4eFifye8AABkZGQAM2Y6MjOia/F1LS0tnIpHI/UCE8SGAemFkZGTMvQEYowvG3yMArTfKxry2xsvX6XTqGfEa/DybzTbh9S6XS/Ln6/h9vF4v4vE4uru7EQ6HJ127U1KOWVlZuOaaa7S5AKCtrQ0A4PP5AACDg4MYGhoCMFbZ9fX1AQBWr14NAMjPzwcAdHd3w+12AwBqa2sBAOeccw56enoAAL///e8BAB/72McAJIW3aNEiANA1Ozs7kZ6eDgDo6uoa8507OzsRDAZx0003TeVW/8cRDAZx1VVXYWBgQMqKMuVCcLvdGBwcBGDI1uv1or+/f8zrjjnmGABJWVBGlE9fXx8KCgrGvJ7PKy0tTa+jUYpEIlpQ3d3dAAxlarPZkJeXh5///OcfpCg+cGRnZ+NrX/sahoaGtPm4kZqbmwEABQUFOO644wAAJSUlAIClS5fii1/8IgBg9uzZAAxZdXd3Y/78+QAMxblo0SJtTL/fDwC49NJLAQBXX3015syZAwDYuXMnAOCll15Cbm5S582cOXPMtUKhkP72zW9+s/4DE8aHAL/fj3Xr1iEajeo+6urqAACBQABAUm7UGzQIra2t2vt8HZWZz+fDwMAAAEOxdXd3o7S0FACkH7hHent7tWZ5rYGBAa1d7hG+v729HS6XC3fcccd73teUlGM8Hpfy4+bkYuCimzZtGhoaGgAA+/fvBwAcOHBAX5IWlT9PPfVU7NixA4CxoOLxOH71q18BAKqrqwEAf/vb3wAkFzEF2tHRASBpDfg9aLmptJ1OJzwej/6eqrDb7fD7/fD5fFLwfNhUSiUlJXrIXBQOh0Ovmz59OgDDCgeDwQnyrqiokFLs7OwEYCymzMxMvY5wOp3wer0AkgsKgOSfl5eHxsZGPdtUx/DwsO6lsrISADBr1iwASTkWFhYCAP793/8dQJLVLFu2DIBhXBobGwEAX/jCF2QkuFEbGxvx0EMPAQAuv/xyAMCKFSsAAJs2bZKBXrJkCQBg/fr12LNnz5jrU7kcOHAALS0tH+Ttf2hIJBKIRqMoKyvDwYMHARgGlGvFZrMhMzMTgCHDadOmiU1ScXL9mfcrZRMIBGTUqGB5/VAohJycHACGgenv7xcz5X6hnvJ6vWM8z8lgxRwtWLBgYRJMiTnabDZ4vV7564DB3kh9Ozo6pLl37doFACgvL8exxx4LwKDN7777LgDg9ddf1/Xpcr/99ts477zzAEDWgBb1d7/7nazMjBkzACQZDS0JmRUtV0VFhVhkKoPWt7u7W0yQjIz33tzcPCEGlp+fLyY4/j7tdrvkTRetra0NwWAQgMGy6b4kEglZWMoxEAjIEygrK9PrAMhNTfXJTqOjo+jq6oLH45HH8+abbwIA1qxZAwDYvn27GArX4ZIlSyTvxx57DIDhcm/dulXP6YEHHgAAHHvssbj22msBALfddhsAiBleeumlqKioAGAw8HvvvRef/vSnARjeAZlUR0fHmPBVKsPtdqOkpAStra1aq2SHZOp9fX1ifcwx9PT0aL2RMXIfRyIR/Y3rOi8vzxyHBQCFiAYHB7WO+beZM2fqutRPDEtlZWVhYGBA62EyWMzRggULFibBlJhjNBpFS0sLsrOzxUjIJnp7ewEkmQY1OLXywMCAsnwbN24EYDCTkpISxQ3mzp0LANi8ebMswmuvvQYAiv1UV1fLYm/btg1A0sIz1sH4D5M2vb29yM7OTnkrHIvF0Nvbi2g0KstKK3n48GEASStJy0f5Hzp0CHl5eWN+xxhiNBqdEC9MS0uTNWWMLRQKAUiybV6DchwcHJQ1J0NlTDQSicDr9ep7pipcLhdyc3MRj8fl6ZAlkhWfeOKJOPPMMwEYcnz77bcl7/HZzuHhYWzZsgUAUFNTAwA477zz8I9//ANAMgkEGNnt++67D5///OcBJBOOQNJrIkt98MEHx1xreHhYeyDVEY/HEQ6HEQgEtA+nTZsGwPBwWDUCGDK02+3al9zT1Bk9PT3KQTBu2NPTo+dBuXJN5uTkKIbI2ObQ0JBeT1ly7TscjjFsdjJYzNGCBQsWJsGUmKPH48GMGTPQ1dWluBVZDS1lTU2NrAFZ5fLly2Wh+TpakcLCQmWkyRzvu+8+XZ+/Y3bx2GOPlUV55513ACQtEa0FLQm/17Rp09DV1fW+mamPGk6nE3l5eejp6ZmQ8aPM+vr6VEpC6+vxePS68bFKn88nS0nLabfbFZNhGQufhc/nk5z40+Vy6Xq0wmSOwWAQmZmZKc/KgaQsBwYGxBTIBCmD4447Dn/9618BGMxx06ZN+NznPgfAqKQgS6+pqRHLYXnIX//6V3z84x8HYMQQzz77bABJdk4W1draCiCZkWbFAME4m7lqIdURi8XQ398Pm82mmCzj0LzXkpISHDp0CMDYMjTGJuktcW1WVFRoD5sz1/SEuObppXq9XsncXBvN19NTJaONRqNHjDcCU1SOIyMjqK+vx+joqFxhcxEtAFRVVeHZZ58FYJQs+Hw+CYuJgYsvvhgAcN1116mcYsOGDQCSm47JHLoidN1cLheeeOIJAAZlHxgYkBtNpbpq1SoASSUZjUaPig1ss9kwPDys78qfVE5DQ0MT5B6Px8fUHQKGm+zxeKQEzO4y5cZQSFVVFQCgqalJLjndzry8PC1OLlwavb6+vqPC8BDp6elyq+lCM3HS3NysNcyQwoEDB3SvmzdvBgAZrgULFoxxGYFkIofPgKGI+++/HwCwdu1aPRcqjNzcXK397du3A4Dc8ry8vKNizQLJtej1euFwOOQCj3dxu7q6pADNcmYCh2Ef/i0cDusaNEjt7e2SOZUq5W2320WMqBzdbrf2CxWtOSzl8XiOGBKy3GoLFixYmARTYo5OpxPTpk2Dy+VCU1MTAIO9ma0c3UBag2OOOUalEyxUJtuJRqN46623xnxOIpGQ5eXrGIDNzc0V4/ntb38LADj33HP1OzIeWoRwOIzm5uYxLUupCBbYR6NRyY9uFa1pIBCQe0fZjoyM6N7Gl0/YbDbJg78zd9nQpWPHhs/nk5xpfc3toHwmdCMdDgdCodCElsNURCKRwOjoqNYFGxToBr7zzjv42te+BgDYu3cvgGSCheuKYR2yaLM7zHKg0tJSHDhwAMDEdfj000/Lk6IcAaPLi9027BLz+/1j2kVTGYlEArFYDJFIRPLiGqaHk0gk9G9z4TbXLuVlXpvjvaTMzEz9nR4ovZmhoSF5jeZyNF6DyUfug56eHrhcLquUx4IFCxamiikxx1gshlAoNKbvk8yOPxsbG6W5GVuZO3eurCBjEC+99BKAJPsgMzr55JMBAH/+85/VH8wSHhbTPv/883j++ecBGFY/LS1NCQcGXGmRKysrsX379pRvcRsdHUVnZycKCgokD8ZjaB0HBgZ0XyzgBow+Vv6O1juRSIjVkQkeOHBA12CvL2M7dXV1E9q3SkpKdF16C2bGOXfu3COWQ6QCWAQOGDFpxmDJJF588UXFrV9++WUASVbOWCPX64UXXqj3vfHGGwCAV155BUCyZZBJQsqYmDVrlp4B4+99fX146qmnABhxXJbylJSUTLhGqsJut8Pj8WBkZER7nx4Omd60adOkA8z5Az4HekJ8Pj09PZq/YB5YwfgjE2l8fi6XS94r94vP55uQODYXjZPdvhempBzZxZGdna3sM+mquf+XQW8qx61bt4rechHwJm+99Vb8+Mc/HvP6c845Z0K3h9nNpmLmpu7v78fy5csBGIFtc1aL025SGR6PB2VlZQiFQsqs8TtzUfn9frkBVFCVlZWSAzcTM/wdHR2SO13hl19+WYaMLiDf9/GPf1zv5aKORCJSmPwelG08Hj8qOmQSiQSGh4cRCARkSLiJy8vLASQND128xYsXA0h2Y33jG98AYIQsuN4DgYCUHY1GIpHQhqaB2r17NwDglFNOUfKFe6CjowPPPPMMAGNAhbnG8mipc4zFYujr69N6AAyFRiPb398vvcD1k56ePmYOgBmZmZla65R9RkaGZM11bd7nVMjUFfX19Vq7fD2TbdnZ2WM6piaD5VZbsGDBwiSYckImOzsbNTU1sgjmEUNAkh7zd3QL3W63Aq50wZgEuOaaa5RYYdC7srJSFn7Tpk0Axpb5sAyDdWnz588XzSYropV++OGHkZub+741TR812H2Uk5MjF4NWj7Lz+/1iNyy58fl8ujcyTZZB2e12zJs3DwCU9MrPz5e1psvN8ER5efkES15bW6tOJI7tYjlLZmYmBgYGUn7iETs4MjIyxIiZ+KDMbr/9dsnj7bffBpAMRdCD4d8Ynnn00UfF7FauXAkguRcoGzJSMkKn0ynWw7/FYjF1y3A/8DVbt27Fd77znQ9OCB8i2Fs9OjoqdkgdQHlFo1ExOuoKp9Mphk1mxzrevLw87WnOUGhoaFCIh8+R+2F0dFTeK59pIpGYMEPSPB2Mz+G9kNoaw4IFCxY+Ikw55hiLxeBwOBQzpMZnaYTNZpsw1ffWW2/FT37yEwBQlTxjW48++ihOOOEEAEbxclNTkxIrjBGsXbsWAPC9731PpRNkVn19fYpLLFy4UN8DAM466yzs27cv5WOODocDOTk5Y+JWBC1ienq6GJ25XIfyHh8DKy0tlWVmcfGCBQvENPk6dhnMnTtXz4csMTc3FyeddBIAw/oy7rZp0yZ0d3enfJkUZ2U2NjZqHXD9kcUUFRXhhRdeAGBM4Lnqqqvwl7/8BYARsyVjOf744xX4Z9Lm2GOP1RQpxo05G+Cmm25SUvHOO+8EkOwCoVdAZsrYeXt7u0qKUh1MeHm9XpWCcf9x/UUiESVAeM89PT1i31zjfH8sFpPMuSYdDof2PBmkOe/AvcHrh8NhPQe+ztxF9n6xcos5WrBgwcIk+KcmgXu9XllNWmJq8pUrV8riMfa1fPlyPPnkkwCM8hFzho/vpaUoLi7WJHCyFGb9Zs2apWwfrf7s2bMnTKZhjHLBggWYP3++LEaqgjHH/Px8WTtaQt7vnj171ILFv7GnFTBYDUtS0tPTdS1eY+vWrWLq5slFQLJchSVUZO7p6enYt2/fmO9qjnF6vd6Uj+cyW71kyRJl3BnfJpupra1VFQS9jyVLlqhs7E9/+hMA4OabbwaQzKByJimz23fddReuuOIKAMZ+YAXGvffei+eeew4A8PWvfx1Aki2STZKd85qzZ89O+SoAIhaLYWBgAJFIZMzkb8CQb1tbm9aJuUSJniHXoHmSP/MT1DH5+fl6fvRWzE0o9KbMrYvmqeDA2ONcenp6jtj6+k+V8nCcP2BsIirLnTt36nfm17A7gAuPQfxbbrlF5TdMMoRCISkB9v1SOXZ1dYmK04VpamrSTXJBMfg7ODiIV199NeVrxhwOBzIzM1FfX69EFpMBVHoLFy5UvR5DEC0tLbp3BrAZdF66dOmE8pvFixeP6VoAjE4cj8ej33HTvv3223qevD6fdW5uLrKysiYcqpRqcDgcyM7OxsGDB5Uw4L3QjS0tLdXfKPcf/vCHugZdtVtvvRUAcMUVVyjZRbf6tNNOw8MPPwwgOQINMM7z8fv9GvjMMqzt27dLATDpwGcxe/ZsrW+6+akKJmrdbreUHO+LBsfj8WgNmpMjTMBwzdfXJ4/LSU9P19/4vu7ubilKXp/rNSsrS4aIr8/Pz9f3YWcer1lYWPi+MxdS2+RbsGDBwkeEKTFHTt9oaGjQyHe6dwwo19XVqRiTB2eVlpbK7WU3AYd8btu2DVdddRUAY3S9y+WSBeXvyBYDgYC6CMg+BwYGxEzptrMUqKmpCW63O+UHsjocDmRkZCAtLU1sj0ya/589e7YYHVn5W2+9JWZHmTKAHQqFdA2erLdr1y6FPchWli5dqu9BRsrynVmzZk04BMmcMDoaisDtdrvkSreP7Nd8vAcLssnEFy1apNIwshEykbq6Oj0DskS73a6OLpaJUJ4ul0tJQ7LWjIwM7R/KmOGmJUuW6JmlOsgcW1paxOjGTzjKyclRl4q5S4lrm3uZ+9zj8UjWfB4jIyN6nbkRAUjKefyIP07eAYz9QtbO7hxr2K0FCxYsTBFTYo4ulwvFxcWYOXOmYoHmwZ1AMvBJtsfWq/7+fvn8tKSMi5100kmyKGQwZWVlYoAsQZlsXiQZU1pamv7NAPqpp54KIMmUioqKxBhSGYlEAgcOHJClpFVkkXFfX59YG48AnTNnjuJaLB7n630+n2IsLGxOJBKyzrwWGeSePXsUuGZJhcfjkaXnM2NsbsmSJWhubk75Mikgycza2tpU8E52zfVbXV2ts9Ep29raWs0CoKy4Dg8dOiRZfetb3wKQjCHSQ6Lnw2G3L774opg9Y5TDw8N61iweP/300wGMnT2Z6ojH44hEInA6nWLAjJeSJZu9N/NAX65P8zHLQDJGSNmQQdrtdrFDekQs7eFrACNGDxizHOhJ8jukpaWho6PjiMxxSsrR7XajqKgI/f39ygpz0VD5PfPMM8o4UYmtX79eyolZY37Z2tpaBarZr71r1y4t4vGHr9fU1Mgl4iDcRx99VFk+utcciHvw4EEUFxenfEaVFf7l5eUKWFM5UlYul0tuCJMBBQUFkofZxQCSC46JBMr98OHD+h2HJNDd8/v9yuISDodD1+fCYvAcSBq+VO+QCYfDeP311xGJRDQa7IILLgBg3HtnZ6eSgDxB8KGHHpKR4Cbm+5uampQkZPa5rKwMCxYsAGAkEOniDQwMKNnAtVxVVSX3m24iP++5557T61MdTNTa7fYJY8nMg5t5j9Qdg4ODUpTmrDbBv/Gavb29WoPUC1SKwWBQ4TzW7fLESfP3ITFobW1FaWnpEUlTamsMCxYsWPiIMCXmODw8jLq6Op0dAhj0mb2qc+bM0REF7BvNzs7GV77yFQDARRddBABYt24dgKRFoRtOFlpYWCj3hCyIFj4vLw/r168HYFBmr9crRnX33XePed+nPvWpMWUEqQoOY502bdqYIxAAI2mQm5urZBQZh3kUGxMjtKptbW0Thgv39fXJ2jKpRhclFoupl53XmjFjhlwelmHRzX7ppZcwMjKS8sckpKenY/Xq1ejs7MTxxx8PwBiFx8STy+XSeiLrc7vd6hRiOY25l5cuMJ9XeXn5hDOVuC927dqFF198EYCxzuPxuFg8nw+9rtzcXHlDqQ4makdGRsTUyLR5X/F4XPfNkENeXp5YHkvtyOxisdiEji+eXwUYz4Hru6GhYULZWm5u7oRBzfSCOG3qSF6PxRwtWLBgYRJMeSoPWQMtHONPPMO3sLBQMZVPfOITAJKWm5aasUQmD1pbWxWo5vuampoUaGV8gpZoZGRElpqlQuYyAbIs9s42Njbq4KpUBpljOByWhaU8aF3r6+slB8q/oaFBVnT8INC5c+eKJdKCrlmzRn9nQsF8ciMZqflccsZ+CHbM+Hw+zJs3D3//+98/GCF8SLDb7fD5fFi8eLHieFwvTOC53W4lSsyzHunVkI0z+fXKK69oL7Av+MQTT5RszAc/AclnyDgxu20qKyvFitjBxP0xb948sagbbrjhA5PFh4F4PI6hoSHYbDat1fHnfWdkZMjD4GvMp13SeyGzy8jIGOMZ8n2MYZqbPICk/MgCWT4UiUQkQzJOPhev1/u+E6Us5mjBggULk2BKzDEajaK9vR2rV6/WfECyN8ZpNmzYoDjNt7/9bQDJDB8zgJxSQotdWFioeCJjlQcOHMApp5wCALjjjjsAGCUOL7/8sqw/rUFRUdGYOIP5+9jtdqxYsSLle6vZPrhlyxZlPMlWaF0HBwcnHKZVWVkpVshMJ+M8zc3NKnHi6H+fzzdhSjPLWWbMmCE5kT21tLSIRbLchKU/ubm5aGtrS/kjKAYHB7Fjxw4UFhaqYJuxMWZH582bp1IespfTTz9dk3o++clPAjAqKvLy8pTd5nrctGnThMlFjDlmZWVNOPqjurpazJGfzZ+dnZ0p3zZIcOpRR0fHBM+S8urt7RWLZjy2t7d3wvEpfL/54DbzpKPxx3hwb/j9frFU7pvi4mI9X34fel78rCO1vk5JOXq9XlRVVaGpqUkLiG41axQPHTokN4PUt7u7Wy4flRdT6N3d3VKYdCdzc3NVN8nhCBRKXl4eNm7cCMBQBiUlJRIyA7uk7jk5OXj55ZflQqYqqBzz8vLGhCgA4979fr/+Tbfw3Xff1YbkgF/z+dIsA6J70d7eLhnR/aAc3W636lfZSdDZ2amFyGfGhdzQ0HDUdB9lZmbC7/fLDRt/YHx9fb2UF19zxx13yLg88MADAMaeK83Nzue0Y8cOEQOeL0MZx2IxJbZYw7t161bJjs+cisPlcmkQS6ojGo2itbUVOTk5UlYMm1H59Pb2ap2R1JgVGpWYeXg21xv/NjQ0JINEo0IjPjQ0pH/zfaOjo2MGWQBG2KKtrQ0jIyNH7O6y3GoLFixYmARTYo7hcBjbtm1DaWmpWAoD0ObOF/6NZSdz5szR5B1aZbLKdevWjUk4AMCKFSsmjDxiYqGjowOXX345gOQBSECyv5ifSRZFhhoMBlFRUaEgeKqC1jcvL0+MgeyZxa1ZWVly0+h+BINBMUGyY8qgpaVFz4UuivmEuPFngnd1del3ZI7mcARZK4+n4PtSfdgtEwa1tbVijOwYosdx/vnnS6ZkPdXV1WI2XI8M/WzatEmJLSZTTjnlFE3lYbE4f27cuFFlJ2TxmZmZcgGZDKLbl5OTI3mnOlgE3tDQoNIkusJcd3a7XS422VtdXZ1kR/ly3QWDQXmgfEalpaUTQjhk9tFoVF4A90Nvb6/2EhON5lFn7zcXwGKOFixYsDAJpsQcHQ4HAoEASkpKlBCgZWX8paKiYsKo/RNPPFEamkF9WpbnnntO1pKMJicnRxbhxhtvBGDE09xut4bomg8qopXl55iLcbdt25byVtjpdCIrKwuRSETlCrxnMpRp06ZpUgutYzwel8Xk+2iNh4aGZDlpcYPBoGTDGC+tu8PhELsxFyozDsRnTIY1OjqKwcHBlJ/naLPZ4HA44Ha79V0ZN2VMasOGDaiurgZgsBGv16uieMa+GfNasGDBhEOkPB7PhOJ8xnwdDodijSxbqa2t1TOmd8C1feaZZx4V8wCApHztdjuys7PFHBl7pLyHh4f1N3NbJPUI1xQ9l6amJq1drjvzPufv+LOlpUUy5DNoa2vTnmDMkTKdOXMm2tvbj1jKMyXlyIm/b7/9tm6e1JcfHgwGlXxZsWIFgKTC4u/YocC+67lz50qJMmu6Z88e0WvSbS7mRCIxYRpwd3e3XCEKlEHfjo4O9Pf3p/zB81RC2dnZWjC8Pyqq/fv3TzgFr6SkRA+choGudFpampIFVLCxWEyb03zWBpDsS+dzpIydTqcqASjD8edypPrIMpfLhZKSEpSWlkp+4+999uzZ6kihccnPz1doiKEfPpvS0tIJJ0EODAxoeC7DQOZBHiQGXKNnn322wkbjE22FhYWq6Eh1cCSc2U0l4TGHdXivJEG9vb0TErSUW3Z2ttYgjVBfX5+ME+U6vpsMMNajw+HQPqHS5TMbGRlBbm6ufj/pfU1ZEhYsWLDwfwBTnspTUlIypkuF7MF8BixZnvkcZabe6Rby/wsWLNAJb7Ssq1evVtkDg9ekzP39/QqK07IePHhQv2PCh2774OAgCgoKUt71A5IWr6+vT8kqWl9azunTp4/puACSzJgBblpdMr1QKCQ2RAvpdrsnlPLweXV3d0/oMigoKBDbIvvks+7p6UFWVtYRrW+qYHR0FHv37hUzpudCjyYajeLKK68EYNSEVlRUqOaUHhJLncLhsOo9n376aQDJcjayIyYq6QGFQiGtaXaEDQ0NqTSIzInPmn32RwPMU3koXzI07sNwODyGMQJjk4nmI1KAsccq0HPq7+8XY+TfmKAsKCiQl0kvsrCwUOt4/F7iyLIj1ehazNGCBQsWJsGUTP7g4CDefPPNMWUGZGpkFXa7XXEETn3p7++XBicLocavq6uTRaXmt9lssrhkSowh7t69WwzTbIFo2QmzJZo5c2bKsxueCZ6Tk6PYq3ncO5CMA9Jiku319vZKtmTxfDbmgD6Zc2trq5gfZWoumGcsjgypv79/TPIHMJIMGRkZ7zvZJBXgcrkwffp09Pb2ipmQ0TCulZ+frzXJpNRxxx2ne+XxFEzQ5Obmas0xTtjR0aEEDz0jXn/9+vUqDGcc+MUXX1SJGVkV50wODQ2lfFcXwQPMXC6X5EVWbT7yg+uIHqV5z46fO8r9ABhrt7+/X4yUCRz+jZ6l+VoDAwNjDuACjDXf39//vg0MFnO0YMGChUkwJTpls9ngcrnQ2toqDc6YIJme2+2WJaUVKSoqkkUY3+sYi8XUgkiGVFxcrN5tllcwNjQ4OKhyB1qi0XmwzDQAACAASURBVNFRsVWyUMYYXC4XDh48mPJTeex2OzweD9rb28X4aBUZQxkZGZHFJDPxeDxifoS5x3T8mdYlJSWyyGTllL95crj5iE1aerIBc/lFY2Njys9zjMVi6O/vh8/nU4sg1weZzYwZM/Czn/0MgOF1ANCUer6P63bXrl2qsmBc8oEHHpBsuW7JwIeHhxVf5PULCgr0urVr1wIwWGVeXt5Rc0wCkGR6HR0dWlPUB2Too6OjE9aWubfZPDEcSK5NPhuuYY/HI73DvW8+BoGxd3OZD70vlhdyrTc3N2N4ePiIlRZTUo4ejwcVFRWoqamRG8Cb40NNS0tTkJPu1ssvv4yrr74aQLIcBTAG4S5evBg//vGPARhCc7vduO2228Zcg/WOxcXFSlhQ8N3d3RIkhUGFUlZWJiqdyrDZbDo3mkFn3iddBo/Ho3sxK0DKnn8zD6/le+mqh0IhPR8uLLqaIyMjMiJcyMFgULI1j5MCkkrS4XCkfG91PB7HwMAAwuGwwj8M71COs2fPxuLFiwEY8r7nnns0DJfrimU+WVlZ2qAcAjw4ODiht5/rcOvWrZIp3fdp06bpWXDt89m98847R0USEUgqvs7OTjidTikm3ivXRm9vrwwL93R/f7+eg5n8AMm1S1nyd4WFhVp7lK+5v51uOnWT+QgPKk6G5MzJmveC5VZbsGDBwiSwTaWA12azdQA4Ok79mYiyRCKR+1F/ifeCJdsPD0e5bAFLvh8m3lO2U1KOFixYsPB/BZZbbcGCBQuTwFKOFixYsDAJLOVowYIFC5PAUo4WLFiwMAks5WjBggULk8BSjhYsWLAwCSzlaMGCBQuTwFKOFixYsDAJptRb7fP5EuMH2Y4fKxSPx9XMzQEKPMMDMPp4+fO9BkKwv5XX5eAKp9Op8WPms03Yw8khCPx/LBbTENmhoaGUbQL2+/2JrKwsfV/AGOhpHtDJ+2JvaTwel2z4Or7fPP6MyMjIUO82+3rNJ+zxebKH1Qz+jde32+2w2+3o7u5GOBxOWdn6fL5EMBiE0+nU4ILxAw/Mp9dRLhzJBhhj+dnPH41G1StsPp6Cz4CDLTj+zPxZ7Bn2+/0T1iv/73A4dN2GhobOVO6QSU9PT7D3nDLkd+easdls+hv7qcPhsPqmOTiGg2nS09PV+0+ZOp1ODVzh3qBM/X6/ZDiZLiL4Gsq3u7sbAwMDk67dKSnHYDCIL37xi/D7/dp0vHk2zGdnZ6sBnH/Lz88fMwcPAD75yU8CALZt26ZpJWzSX716tRrRqQg5TaO9vX3Mwd9AUmlQmfLITcLj8SAWi2mQRaoiIyMDF198MRKJhIYcjJ9lecYZZ2hh8ZjLXbt2YceOHQCSww2AsQebcRFxHmEsFtPG5SZ9/fXXAQCVlZU4/fTTARiLPD09XYqSC4vPPj09HcFgED//+c8/SFF84AgEArj00kuRn5+vzcefPDp17969mj/KzTU4OIgXX3wRgHHoFmdhFhUVSX733XcfAOAPf/iDZElwoMTIyIjWKD+zv79f03443IMTrRwOh+R8/fXXp3RrXmZmJi655BLk5+fLmJinywPJPcqDtebNmwcgOfyBU6a+/vWvAwC+/OUvA0jK6KyzzgJgKMdnn31W8l2yZAkA4JlnngGQnIz00ksvATBmPWZnZ+t1lP3evXv1vXJycvDrX//6Pe9rSsrR6XRqkfALcHwVF01fX58mX/ALrVy5Ug+fFphnH3/sYx+TwuQElLq6Om1mCpILau3atbrWa6+9ps+k0uC1qDgPHTqE/v7+lB+rBSQ3hNPplDXkPXFUWEZGhkbGmx8ylSk3d2Vlpa5JhWY+fZGvo1GioZo7d66eGSfwlJeXa3Hyc2iw9u/fD7/ff1QcsFVYWIje3l4d0MR74fQYri/AUJw1NTV45ZVXAABXXHEFAOCkk04CkNz8PCiLE6YWLVqk86dpqNasWQMAOO+883TOOg1bdXW1WCrXO2VdVFSkPZbqoGdot9s1qozg5JvNmzfryA4eUVFTU6NpXZdeeikAY53eeeedUqZnnHEGgKRCpGGnUuS0nWXLlum50ag8++yzIhh8bvSycnNzx3hpk8GKOVqwYMHCJJjy2QGJRGLMnDm6BRzM2d3dPYbWAkZ8ETDmPtKFrqmp0b8563FgYECWnDGiBx54QJ9HNvTpT38aQNL9JJNinJOxiXg8jszMTLGxVAVZeUtLi+6ZLJtsMScnB6+++ioA41iKuXPninWQFZElZ2Zm6uAxMpJ4PK7r0eUjkyktLZUbxCNGb775ZnziE58AYHgJDHHMnz8fg4ODKT/PMRqNoqOjAxUVFXL3KGPeU3d3t1jMV77yFQBJ1sdzpXlEKwctDw4OytPhoXF1dXVYuXIlACjUcddddwFIPrsf/OAHACBXbnR0VGEgDr01u+FHyzxHHrAVj8flWXK/7d69G0CSEX71q18FYHgzCxcu1CxMeohPPvkkAODaa69VaIdhndbW1gmHaPEwtIyMDB1cdscddwBIrmEeTcE1TOa4f/9+5OfnW8zRggULFqaKKTHH0dFRdHR0wOVyjTnmADCYTFdXl+I4PJ7y8OHDioOR0XHq8s6dO2UhyXjWrFmDxx9/HIBhlRl3+9vf/oYTTzwRAPCjH/0IAHDWWWfJujAeuWjRIgBAfX09gsFgyrObWCyG3t5eBAIBsZTxx952dXWJ2dFKDg8P48CBAwCAjRs3AjDiMHPnztXzofwqKyuxfv16AAZ7Ou200wAkY5D0BPg5F154oTKKjEOaj3FwOBz6jFRFIpHA8PAwRkdH9d35nckcV61apQoArsfm5mb9bs6cOQAMGf/gBz8QK+fz2rlzp1g1GeCKFSsAJJNeZEIc2V9dXS2Gyc889dRTASRjluOPv0hVOBwOZGVlwev1Kk5OZseY6ooVK7Bu3ToAwGWXXQYAuPrqq3H99dcDMBIx9JYOHDiAz3zmMwCMtb5+/XolGCl7JmE2bdqkXAdj6vv375c+IOM/+eST9Tk9PT0Wc7RgwYKFqWLKMUe73T4mhsdYH+NdnZ2d0ta0zsFgUJaUsQWWQSxduhTPPfccAIPxnHXWWWIu1OyPPvooAOCaa64R+6SVaW9v1/V5oBH/P336dDGcVIbdbkdaWhqam5vFUhgnJCt+/vnnVTfH8p5EIiFmSbZMFvL666/r+Xz84x8HANxyyy26Phkhn0l9fb1ed+uttwJIsksyHpZF0CPIy8t734xfKsDhcCAzMxMul0tsnBlNso2lS5cqe88445YtW8QEuTZ54NaBAwcUIz/llFMAAH/+85+1Nj/3uc8BMNbt8uXLlTk9/vjjASSrLZYtWwbAqOxg7N7n8x0VFRZAUr4ZGRnYtm2b8gz0VMjUjj/+eHzpS18CYOzRK6+8UmySJVNk8r29vfj+978PAIoFr1u3Tl4PmSOvBRgH+j399NMAgKuuugpf+9rXAADbt28HAB3cF41GMWvWLDHRyTAl5Wi320WdqbwoDG6QQCCAnTt3AoDqlMLhsNxqLhC6ItFoVDfKxMKGDRuUxGGAm4mIeDwuBfHggw8CSLqKvP6f//xnANCiy8jIQFNTU8ovNJ6Ql5mZKfmdffbZAAxD0t3drVIJumutra3azCwp4UKrrq6WgaL8pk2bpoQZNzyVwvLly/UczfLic6QyMDcA9Pb2prxbHY/HMTg4iI6OjgkHsTEhcOjQIa2/f/mXfwGQDPbzXhmCYMjo8OHD2sg07kVFRTLK5oO4gGRJC69BBdjR0aGQBo0dX+/xeFT6kuqIx+OIRCLIy8tTuGzDhg0AjKL5Z555Bh/72McAAA8//DCApPJiqRPLcPj/kpISKVgmXdLS0pSoZYkVDdPixYt1XaK7uxt/+MMfABhrlu8vLy/Hm2++eUS9YLnVFixYsDAJpnxutcfjQWtrq4LFZHikpwUFBaK6LBY2B+2ZGFm6dCmAJI1maQnLfBobG8VWyHLOP/98AElX57Of/SwA4Kc//SmAJKMhe6JVpqt58skn4/rrr09518/pdCIYDMotAwz2Rsbh9Xp1HyyRKCkpwZtvvgnAYB90x5988klZVrrSgUAATz31FAAjWE429cwzz4jZM0zS1dWl78SiXFrhcDic8uEKIPl9A4EA+vr6tJ547wzNLFy4UGUeTACcc845KtchA+K6f+yxx8SEKIMnn3xSLjOfCZlpW1sbioqKABjspba2Vh4UP5uJA5ZSHQ2w2+3w+/0oKSlR0o4Mkgx9eHhYxd9k1Tt27JBbzc4XrlO73Y7nn38egLHu2tralFCjp0gvsr6+Xolahn+effZZJRjpJTFZU11djd27dx8xUWsxRwsWLFiYBFNmji6XC5mZmbLAtKQM7nd0dIgJ8m9z584Vs2Rygb3Yy5YtU6vfPffcAyBZzkALSjbEREFBQcGEoRUOh0NWmbELWvMbbrgB06ZNE4tNVYyOjqK7uxt9fX1iFrSS5kEFZJGf+tSnACRjjiziZpkJmc+MGTMUFzMfgs5CaCZuyIqysrLUEsdyk1dffVVsnHFcWt+///3viMViKR9zdLlcKCoqQnt7u9rTyDz4s7a2VrJir/SsWbMkByZwyAhXrlypljS+5swzz9TvrrvuOgAGA58/f77eS6+psrJS65v7gwznmWeeGdPymcpgLqKhoUFF4Cy+5lpevnw5CgoKABie0IwZM8TcyAAZs923bx8+//nPAzBi4l6vV8+BMXQmIYeHh3H33XcDgHr9R0ZGpKfYxsiW48ceewwOh0PJxskwJY0RjUbR2tqKkpISbUh+OG9u1qxZeOGFFwAYbnIsFpPbS2HQXenp6dEX5EKqq6vDli1bACQbygGjcv7CCy/UAyDKysrwpz/9CQAkUFL3/v5+9Pf3p7xypGwHBgaUYebwDQ4jWLNmjQwDs5uNjY1yEWmgaGwKCgq0+SizUCgkRUkDRYMya9YsuUFmw0Y3hYaNiZmsrKwJvbSpilgshqysLN0DDQN/Hn/88aoXZThjeHhYrhrvk/LZuHGjDDJf09fXp4QgnxPddr/fr2fAMMXq1asleypM1gm63e6UDwURXLuhUEhDTxjW4r7r7OyUrBl2e+aZZ5R85OtonPfu3Ytf/OIXY6512mmnyVAzFMSEy7p16zB37lwA0DW9Xq8MF8MdJAbmDrr3guVWW7BgwcIkmBKdcrlcyM/PR29vryg/mSM1cDweV3U8reDQ0JCsJqdqULuHQiGsXbsWgBF4Xb58uVgTGSNHGh0+fBjvvPMOAMOKd3V1iUmx/IFJh5NOOul9K+FTAXa7HR6PB06nU1NyGJ4g+ysrKxOjpvvR3d2t7iR2E9EdP3z4sBg95V9VVaXrkWnSCm/YsEHlE2SjXV1demZk42T/LS0tqiNNZdjtdmRkZKCyslLuHmXLe2lsbJSXwqTAs88+q3umrFgXedlll6mLiy7biSeeqF5pvo+lKQ6HAyeccAIAw+1zu91i+bwu91N1dbV+l+pgSZfT6VQ9ITtXrr32WgDJhBNrRsn+KisrFcrg2mWNYl1dndxvJhXdbrcSPgyHMHxms9nkqdI7CIVCGlXIcivuH4fDAZvNZiVkLFiwYGGqmBJzjMfjGBoagsPhUBCf8RkmDUKhkKwyrWI4HFYhJ31+Ii0tTSyP1sNutytGydjXt771LQDJwlHGO2mxX3jhBfzsZz8DYDBHlroMDg4iJycn5YvAgWTcJRwOayYgGRnjOGVlZRMsc2VlpSa/kPkwuB8IBMSuaaGHh4dldRnc5uesWLFCsRjOI7zyyislOzIZJsJyc3OPiqQBi8C9Xq+SAuPjrsuXL8e3v/1tAFCp2KFDhyZM9qZsPR6Pkg2Mdb322mta+5QL3+92u/G3v/0NgLFX3G63EjBkRGyuiEQiSnylOpiQGRoa0jxVDk2ura0FkIyvUoZka4sXL1aSikXjXMMLFy7EQw89BMCYWJSZmSmPhh4O31daWqrkDMui7rvvPiUu6S3xb7FYDPX19WKnk97XPyUNCxYsWPhfjikzx3A4jLS0NMVgmMmkZj5w4IDiW4y77Nu3TxaX72Omz+fzqWyHlmX79u26HlnLhRdeCCBpdfhethbu379fbIsZbzLUzZs3Y9GiRbI4qQqv14vKykr4fD4xY8YOOfU4IyND8UHGUKuqqpTNI1OnpX311VclR3P5CI+sIKtkDMjj8SjuSxYfCoXEZvgMWbB73nnnYXR0VIXjqQqHw4H09PQxa5PMjvebl5eniTjs0U0kElqvfBZsMWSMGzD6ddeuXas+YMrkvPPO0+cxFsaY8v79+3V9xtjJ2NPS0rSWUx2xWAzhcBjRaFTZecqVDDIajYoxMu63atUq3T+9GbLljIwMZaJZvdHQ0KBKGJb2MV8Ri8XkzfLZnnvuudIfjOUy9njo0CEsW7bsiGt3SsrR4/GgoqIChw8f1hege0eaW11drYQJBxSsXLlS/+bm5rCDO++8U1XyPDphyZIl2vB0nUmHR0ZGpOgotPLycvVnc9HefvvtAJJKoaCgIOWTBuyt7urqUlkDlReV3fPPPy+50x3bvn27BnkypEBD4ff75ZKba8VojFjewH7e/fv363d8Flu3btUCp0JmwgJIKo1UHwfHGtJEIqHNwPAEwwiRSERrmMpxcHBQbiLdcZbtZGRkqAyHIaOysjKVolDZsdPl0Ucf1fPh8+3o6NA1uC/4tzlz5iixmergsNvi4mIZXiYJWR512mmn4YknngBghHEqKioUqqE+4Lq+4YYbVDPK8I/D4dD8AIY0aLgfeOABKUoamPXr1yusQeXIMrRly5ahr6/viDW6qW3yLViwYOEjwpSY48jICBobG8cwEgagqfHLy8sVSKUlrq+vF8vjFJKbbroJQNIN5ut5yI7b7RYjpctHBnnqqafKlacl6u/vl6WiJaKlt9vtiEQiRyz2TAUkEgmMjo4iEolMOJKSyYPp06fLApJxAEaogj/pvsXjcTFGBp5bW1sVuObryXZee+01/Y1M3263K5nDv1HWLLBN9Q6ZSCSC/fv3Y+bMmRPG3TGEMTw8LGbMMqn58+fLZebrGJ5IJBJizJyeVFxcLA+HoZ/HHnsMQDIcxGfHZ2G32+Wu01Mis+WxDkcDGBLq7e2dcBwBO1lmzpypEA+Z41NPPaV9TVmS0efk5KgMjfu9v78fN954IwBjUhSZ9vLly/WZ5557LgDgtttuU7KMa5fu++zZszE4OCg3ezJYzNGCBQsWJsGUmGMsFkNfXx/S09NleTlVhGwlkUjIr7/44osBJC0rrcBvfvMbAIZlXb58uXoiGSuw2WwKjjOeQyYYiUTEZMy9x4w9MBZB5mOz2bBy5Urce++9U7nVjwRkLmThZOdMgLzxxhsqrDfPYqRsWXBMtrhjxw4dQkaGH41G1drGZ8fPmTVrlsb2M2ZWWFioGBwZFeU+NDSEysrKlI/nAsl1EAqFFEOkJ0FW7vP5lHAik87IyFCSi33rLLkpKCiQx8Nk4Z49e3QNXp8laW+88YZiu1yjN954o37HeCSTjKFQKOWTiEQ8HsfIyAiOOeYYrSV6F1xrO3fuVFkPi+EffPBBTe9hzJWlPStWrFCJH3XFT3/6U3zhC18AYDBsc/E855hec801AJIMna9j3J56i8liss3JMCXlyKzf8PCwEgPjkweZmZlyBxi4v//++7WoGKCm6/jqq69qWjDds6ysLHUa8GY49KCurk4DR5mE8fl8UpjsgaUQH3nkEbz++uspfx7H8PAwDh06BKfTKUXPe2fWMhgMqiOAi8nlcslVGL/B2trapOTMJ0Ayk8jP4bPZuXOnDBsXsN1ul2Gi68Nr1tTU4N1331WVQaqCk6oBo6+X64T3mZGRoRo7ur1btmyRweK51dywDQ0NmkrN5zRv3jzV3bF+kqGLqqoqPR+6l7Nnz9ZzZFaVf6utrZVSSHWw0yQSicg4cE2Yu1Y4EIWu9Lp16xRq4P1TgY6MjCgsxzVfXV0tY8OQGhM+l112mao6OK29oqJCMxyY3Ln//vsBJEMB8+bNU83pZLDcagsWLFiYBFNijn6/H8ceeyyefvppjeln0oCWOBQKiWlQ8+fm5irgTLeNf5s2bZqsN691+PBhsUJaClpncwcO3Y6dO3fKpWSdGZktmeyRzopIBbjdbhQXF2NwcFDfnTJjMqu3t1cyYklJNBpVCIGgrDiMFTBYYkFBgWRPFkUrn5+fr1Iosqfm5maxfP6N14rFYu/bn5oKsNvtSE9Ph9PplLvL9UCP54YbbtCZJWTqZWVlCsfwmZCBOhwOJQvphicSCYUqxp/Ct3v3bnVtcd22tbWJOXEoK382NjYeFd1HgHEuuLn0ifuWXklPT4+YI9dbTU2N3FveK7uTBgYG1GfNMMSxxx6rxBi9Te77oaEheTR/+ctfAADvvPOO6lq5lxhm6ujoQEFBgZ7TZLCYowULFixMgn8qIeN0OjVjcHz5yOjoqJgdD8EJBoOy0PT9zacRMk7D+OWJJ56o2Mv42Obw8LCCsLQoCxcu1DEKDMqSGUyfPh0ejyfl2Q2QZB4DAwOydoyn8P+BQECHCLGDhQkywEhC0RrW1taqwJ6BaZfLJWZP1kI26vV6FY9kyUthYaHKHb74xS/quvxbWVmZLHyqwufzYeHChTh48KA8HMbzyMoHBwcVlzV3EDHZxeJ4sj+bzaaODHZ8zJkzR3ImA2Tpz0svvSS5kzkWFRUpzs71zsTP6Oio9kyqIz09HcuWLcMtt9wyoQOJeiIcDotVc716vV6ceeaZAIzD8ii/s88+G7/85S8BGOVA//jHPxRfJ2unLli+fLn2POOcK1asUMMDBxjTc3A4HGNmoU4GizlasGDBwiSYEnNkMW0oFFLMi62C1NaLFy9WnIHxgVNPPVWTutn+Q8uybds2ZQlplR955BGVBPC6ZISBQECxNPMEcbIbpuxZXhIMBnHLLbeMKZpORfAIioyMDGX5KRcWEmdkZMjSUi67d+9WNo9MkOUnTU1NsuTsSX333XfFmlhVQDnOmDFD5VRkTJ2dnYpNssWLmcW9e/fC5/OlPCsfHh5GfX096uvrxdRYwsF46vHHH6/MNDOcgUAAF1xwAQAjBkt52u12eUhkO01NTXo9mSAz1AUFBWLj7At+5513xpQSAUY812azpXyFBdHf349XX30VpaWlitdybiY9xGOOOUaxbu7VlpYWPY+LLroIgLHW33rrLXzmM58BYJTxbdq0Sf9m/JvsvaSkRDNf+VyWLl2qZ8nyM67VSCSCnTt3yvOdDFM+JqG9vR3Lli3TSWLcYKSn+/bt0xdndXp7e7uUFVPn3GDLli2TG8jNnZeXp+sxIE4hn3HGGRPc9r6+PtVLMSDMm25tbUVFRYXcp1SFzWaD2+3GvHnzFMTnQGBuvpaWFil5utz33HMPvvOd74x5HTd5MBiUvKkQi4qKJHsuYJZXORwOuR88DD0/P1+uEWXIXtfMzEzU1NSoHCVVEYvF0N3djaqqKiUDeJYI100ikdB9cq3NmTNHsmT9HcM7xcXFchP5u+bmZsmC5Sp0A/Py8iQ38+vZuUElSqOUmZmZ8kd7EHa7HWlpaaiurlaHCxOqdHvnzp0rF5cExnyujvloDyBpOJiopT757Gc/qxAOky+UUU9Pj2p/afj8fr8+i3qBBOy4445DIBDQIJFJ7+ufkoYFCxYs/C/HlEt5Vq5cib6+PrEbuggsH5k+fbrcamr8lpYWaW6yRLpq7777rqwrx6gPDAxMsKQMlps7XWjhFy1apM8i46SreOqpp46ZdJOqGB0dRXt7Ow4ePCiry8J2hiDC4bDcNSYWzANT+Tvz+d9kSHTVBwYGZC3ZnUG289ZbbynJZZ5WQ/eOLIAB8vz8fOTl5aX82dU8b91ut4tB091iuKaoqEjshWu1qqpKvdVk7Ozb3bZtm8JGfCaZmZkT+uL5MxaLaWAzGaTH41Fyi8+EpW6XXHKJOp2OFvT19WkPkxHyZ2lpqdYlQxQzZ87UAGDOXOBai8fjCtmRJba2tkqe7OHmgWZOp1OJMe6HoaEhhYKYBDKfWJqenn7EkWUWc7RgwYKFSTDlhExNTQ26u7ulzRn7YsDzj3/8o2KN1OD5+fligOPHwTudTjFA9mMCxkE71Oxsx5ozZ45ik/y5d+9eBYJ5fVqMpqYmVFdXH7GHMhXgcrlQXFyMkZERxcXIGPndvV6vYrdkdpWVlSprIDvms5k/f76YIH8+9dRTE9oMyZjeeustxWjI8OfPn68kDeNo/FlcXIyCgoKUZ+XRaBTNzc0YHh7WemKRMtlMeXm54q0soSkpKVFsncybMbHp06ersJj9/9OnT5eHw2swAeD3+8VC6dV4PB7tEX4Pts329vYeNVN5YrEYQqEQYrGY9j7jt1xH+/fv1x41H1XApCPXJGOwjY2NKvSmzPfs2SN9Q13Bte9yucRIf/e73wFItifeeeedAIzYL5m9z+d73/Psp7SqMzIycMIJJ+Dw4cMKrvInb2TmzJnKIHFggdvt1oZlMoDK9Nhjj5VyZKZqdHRU9XmsOWMlvNvtlktuPgGRAmfAlTc9OjqqB5fKsNlsE5QblaT5tEVuGLoHTU1NSipwEAJr6+bMmaNnweEVra2tcoPpDnLThkIhXHXVVQCMkMVpp52ma9DNp/w5+TnVx8F5PB5UVlbC7/crQUX3j8qyoaFBMmV/eW1trSoj6Ar/93//N4BkgoGGinW61113ndx1Kjuuy4GBASkMhqS8Xq/2A58JSUQ4HNb3SXV4PB6Ul5ejoaFhzBnogGGUe3p6ZGgY/mloaMD3vvc9AAaR4vpubGzUumQXzYYNG+R2kxyYT4fks2ToY86cOaqqYXKH+qG9vR2dnZ3WGTIWLFiwMFVMiTkODg7i7bffRjQalZvLgacMKAcCAQX42SUwMDAgd4NsiO8z90rTytbV1ckC09IzsFtWVqZBubQKkUhEHTp0Z2jVLkrvEAAAIABJREFUd+/ejenTp6e862c+IY/MkS4BZTt//nydeUwX8PXXX1dPMK0pEy2HDx8Wi2Qypbu7e4K7xpKU4eFhJdbofoTDYbFOXp9WfnBwEI2NjUe0vqkAJruCwaDujz+5TubNm4frrrsOAHTWcX19vdYN1yEZXjQaVRKQDG/z5s1iNnT3GObJy8tTfR9DPjabTWueiUSWDoVCIbGiVIfL5cL06dNRVVUl74/MmeVo+/fv17QcdmFFo1H9nXKmfujq6pILzZ/Tp08X8+NapPfT3t6ueQ+//vWvASQ9IoaE+DzojgcCAdVSvxcs5mjBggULk2BKdCqRSGB4eBgjIyPSwLR8jKOUlJSIObLMZ+PGjWI/ZHiM+ZSUlMh6kzGddtppiuOQVbIzIR6PK4hL68R+VMAIgLNAPBwOo7W1NeUnnNjtdvh8PvT09IjVsDib/7fZbGPONQaACy64QJ0HLOpmguW5557Tv8kWY7GYAuNkK0wszJ49W7FZyjEtLU3sh8+acbHc3Fx0dnam/LBbMpvu7m6xPcbDybJfeOEFjd5fuHAhgOR6Z+yVsiKbMw/HJSNKT0/X2iTzJuM844wz9NmU12OPPSaPil4W47t+v1/lJ6mOoaEhFW2zB52zFelhnn/++ZrJyvKyxx9/XKVMPMSNHqXNZpOsuXarqqokL8aA+XmxWEzMkd5jU1OTrk99xZKhyspK7N692yrlsWDBgoWpYsrnVvOYAjI/Fq2S2YVCIVlGTt11OByKKZDBTVa+w3hLXV2dLC9ZC2M52dnZip+Z24RYuMtYBBlWcXExWlpadO1UBY9mraysnNAaxTl4GzZsUI8044QPPvggfvKTnwBIjpEHjHKQqqoqTe8hAzdbU1pyxndvvPFGyf3b3/42gCTLufzyywEYcw4Zv6mrq4Pf70/5c6vp8Rw+fFhZVLISxr/8fr/mAHINfe5zn1MmnrFbtqXu3LlTFRfmw9y4vsl2+Cx/9KMfTThgKj8/X9cf33ZYWlp61GSrnU4ncnNzNQ0cMOYCMFcAGMclc6+eddZZiu/yefz4xz8GkKy84DqjZ7NgwQLFfPmMWC3D3AJgxNebmppULE59MH5O6ZEaGKacpUgkEjjmmGNEb/nhdB8qKytFa7mRI5GIXAQqOS7K/Px8ueTmBUKlSKXLm0tLS5sQjF2wYIFummUYfAAdHR0oKyvTQk5V2Gw22O12HDx4UKPH+LDZrwoYQ4IfffRRAEm5fPnLXwaQHNgKGANDHQ4HPvWpTwEwDInH49Gz4zCQBx54AEAyocBQCDfp7bffru9DBUuD5nK5EAgEUv6sk6GhIezZswczZ85UORLr7+gaR6NRnXvM8ERXV5eM+H/9138BMJKA8+bNk/Litfr7++U6cx1yTefn56uGj6fp7du3T3+nTOnup6WlHXEQayqBQ1N2796thIp5jQBJ95rlfiyHCgQCuPnmmwEY5Wq33norAIypmWQZX1dXF5588kkAE0nQmWeeqXpT8/Og+z1ePyxYsAB9fX1WKY8FCxYsTBW2qbibNputA0D9h/d1PlSUJRKJ3I/6S7wXLNl+eDjKZQtY8v0w8Z6ynZJytGDBgoX/K7DcagsWLFiYBJZytGDBgoVJYClHCxYsWJgElnK0YMGChUlgKUcLFixYmASWcrRgwYKFSWApRwsWLFiYBFNqH0xPT08Eg0E4nU5NMGb/r3maC1uI2JqTl5en17MtkNM6fD6f2s/YozsyMqLWQE7xYevayMiIrssWN/MxluN7JSORCOx2O3p7ezE4OJiyByynpaUlKBPKgXJhC9bw8LBao9imNjAwoHvmBB5OWvb7/ZIL61nT09PVz8tnwWuaJ3pT7kNDQ2qT46Qevj6RSMBut6O7uxvhcDhlZev3+xPZ2dmIRqOSLX/ynhKJhNYwZeV0OiUTPovJ5oKaZczr8Vr8ae4/N19//BxHyjYWi+k9jY2NnalcBO7z+RKBQABut1v3QzlQfqOjo7of3mMgEJB82E7MnnTztCf2s/f29uq4A/awU/ZOp1P/Zouo3W6f0ILJ78DvFQqFMDQ0NOnanZJyDAaD+OpXv4pgMKieRo5YYs+0w+HQeRD8kl/96le1YTkcgaODFi9ePOG0woMHD+KPf/wjAOCUU04BYJyjfPjwYV2XgwLWrl2rfm7+JPbt2wefz6dzJVIVgUAAl1xyCRKJhPqg2XjP0WwHDhxQbzWHUWzevFnDInhcwh133AEgeTavedQbkBw2QeP1wx/+EIAx0r6/v1+b9KSTTgKQbOxnIz8XKwcBcODrL3/5yw9QEh88srOz8W//9m9obm6WbKn8zcqRBpkyyMrK0iZk/z/Xuxns449Go5IRe7L50+/3j1EU/F48VoBKgrLt7e3Vd/zGN76R0t0ngUAAl19+OUpKSrSXKQfz8NrxJ4+efvrpmslw5ZVXAjD29F133aV1z+E2jz/+OO666y4AxrAUru/c3Fz9m6c8pqena7+YR/ABSYVrs9l0euFkmPI8x2g0isbGRrEUNsqzgX/btm2aP8iBCEVFRZqe8c1vfhMAdJ5EWVmZhlf84he/AABcffXVmoLCjfv3v/8dQLJhnIMVqEyfeuopnfVBy0A2FYvFMDAwkPLnnDgcDgQCATExwNjAnFhSXFysSTqcYenxeLSZ2bxPZh0MBvHUU08BMKakNDc3469//SsAY8NzKMi8efNkxCi/FStWiOXzDBQqy9zcXAwMDKT84IlEIoGRkRFEIpEJ02947w6HQ3LjlJ1YLCYDxU3FTe/1eqXQOAQhLS1Nr+fUKsoqEolo+AkNuNvtlmzHT8qPxWJS1qkOzstsaWmRfMniOPhh48aNWtccmtLQ0CA9wMlPv//97wEATzzxhIzOxRdfDCA5CYkDQMggSbLuvvtu6QoehrZp0yYpXypODv/w+/3w+/1HHO7xTw27LS0t1QLixiAtXrt2rYaFcgHW1NToy3GEFpVfeXm5xhadffbZAJKnCVIZUmg8b7iiokLs87zzzgMAXHvttbLQXMTc3CUlJWhra5PlSFW4XC4UFBSgt7d3wgLjBtq1axcef/zxMe8bGRnRsQU8T5qW84033tDBQrTCW7Zs0cLiM+Bz2rhxo4aN0tjs2LFD7IkLiac+pqWlISMjI+WH3VI5lpWVKURgPoANSCoqGngam7a2NrEcnlHN9/FwMcBQdm1tbSgtLQVgTIvhENvW1lZ9FsGRb4DBPs3GnR5BqsM8BJv7nLLk2pozZw5uueWWMe/73e9+hwsuuACAcQAcx+K9++67OlaCk3gWL14spv35z38eADSub8uWLfo3n99//ud/ipRxGo95klJra+sRDbuVkLFgwYKFSTAl5uh2u1FcXIyhoSHNa2OMgb79D37wAx1UxEOg7r//fsUJf/vb3wLAmODsE088AcBwk6uqqnD++ecnv+D/t9Rkhl1dXXodx60vX75cFp6DXskgi4qK0NjYeFQMux0YGEB3d7fiWmS7ZHOFhYViMDwcqLW1VfHZq6++GoDhVvf394uF0uXOy8ub4FISK1as0N/oKlZUVOh3/D5ksnv27EFPT0/KH3sLGEdMjE8UjE82AQabjMViGipMds71aE4Y8P6nT5+u645P7pSUlOiz6OoFAgGtZcqY4apgMHhUyJWw2WzIyspSqIbfnccf/P73v9eaMocvOHiZR7jSzb7wwgsVh6RXWlZWplg4Y5OrVq3S5/FoBrLRhx9+GN/4xjcAGJ4kw1FZWVlj4sCTwWKOFixYsDAJpsQcY7EY+vr64HK5FG9hiQ2PQFyyZImYj3kcOuMBtMTMNt1xxx2KHfIQ73g8jr179wIw0vjM4u3evVu/45GNF110kSwO2RAD4R6PB4FA4Ijj0FMB0WgUTU1NKCoq0nclm+F9BoNBBezJ2DMyMnRI1PjkwaFDhzTdmhbdZrOJ5fN1PMwsHA4rC06mGQgEFEcjU2KMzW63w+VypfwxCfF4HENDQ4hEIlqv9EQYI3O5XJI7Y6wul0sxLoLvSyQSkgfZYW1trY5FIMigotGongHfF4/HdX2ySrIqv9+v55nqGB0dRXd3N0KhkGJ4zBFQXsuXL1cikGz5Rz/6kY5a/fSnPw0A+I//+A8Ayen0XOsrV64EALz44ouKTfL6X//61wEk4+3V1dUAjORWcXGxpumTIdIDAJKe2JHi5am9qi1YsGDhI8KUmCOPDx0dHZVGJqP77ne/CyBZf0drzOzm2WefrYN2mGantfX5fIqpUbtv2rRJbIXXeuSRRwAkz5P413/9VwDGoff333+/XsfyBx7TyJhGqjNHr9eL2bNno6OjQ5aPFpZyzMnJUYyFsamamhrFW8n2yHzKysomHGYeCoVkzcnwae0bGhr0N2YN/X6/Mo9kq+ZSI3NtZKqC69Zut4850A0wZBCLxXRfXCtkeoAR96UsJjtYLJFIqFyHz4zsnDE5wIhpZmZm6nd85rxmXV2dWG6qw2azwel0wu/3ay3x/BfeT3l5ufY3s89f+tKXVCO7fv16AMYxxOvWrdO/uaf37dun13FvMAZ80UUX6fyje++9F0Ayprlz504A0NHQZI79/f2ora094iFmU1KOpM+zZ8+Wa8uyji984QsAgHPPPRf33HMPAKMc5JVXXtEi4al2LMres2ePkgYs5RkZGVEh869+9SsAwD/+8Q8AyU1O6s1asng8jksuuQSAcRgVF3pbWxvcbnfKB7djsRh6e3vR3Nys8g8qOxbYs0YLAJ5++mn9jQuFCs1cesNr0Hh0dHRoQdGwcQGnpaXJNaHyXbVqldxuunxUAIsWLUJPT0/KK0cgqbimTZume6CM+P9YLDYhPJGenq7XjXfP/H6/Npa5K4RKke8zu8vcKzRAoVBI1+PzoUIoKytTjeDRgoqKCiXruMa4/iorK/GHP/wBgEFqzjnnHNVJX3HFFQCMcrSuri6VoTHxeumll8pwMWT3m9/8BkBSbuPLBe+44w6tVXOJEN8/Y8aMI9Y5Wm61BQsWLEyCKTFHm80mzU0tzQJuWkifzyfXmcHT/Px8BT6ZuCEzefzxx9UaaKbDLP6mZufxoF/60pd0lCgZ53e/+12V8PC6TOjk5uaioaEh5Zkju4/M/dDLly8HYCSXhoaGlMgi2xsaGlJBPkMRLPJ+5ZVX1FFD9llQUCBZkv3Tqno8HgXBmXTZtWuXvg+LkplE2L9/v9zVVIbdbofX68XIyIjugeuVrNvcDcM1NzQ0JDmwc4hMMy0tTSyP78vOzlbCke8jk8rIyNAz4F7weDzaT3Srec1IJJLyXV0E3ery8nIxZv6kPE455RRcdNFFAIwysTVr1kj+LNbm0bebN28WW6e8zMx006ZNAIzE7k9+8hPtEyZnV69ereJvduGROWZkZLyvjFN7VVuwYMHCR4Qpl/KwsJhF3WxBY4zvtttuUxKEDPLmm28WOyRzZNylqKhI8UQWca5Zs0ZFzoxf8mDvk08+WRaCn7NlyxbFFniIPYO4GzduxOHDh494eHcqwG63Iy0tDXl5eUoasMyBFjQzM1Msjwxv48aNYsVkjLSuc+fOFbvm8wkGg+pHJct+8cUXASRLhs444wwABlstKyvTNfiTsd5wOIy8vLxJJ9WkEsjKR0ZGdM9k21wnOTk5YtIsoXI6nVo3ZBgsg4pGo2KMjH/ZbDY9H7JEvr+vr0+fyWdhs9mU4CEz5f8jkYhen+qgR9nW1ib5kh2ee+65AICHHnoImzdvBpD0/oBkTmL8YJQtW7YASLYGM4lLjygUCqncj+ye8xgcDocYJn++8MILyk/QWyJzPP3009HW1nZEr+efylY3NDSonos3xwfZ19en6TAMcEciEW1w/iT++Mc/qhuGrsUrr7yiDcepPFzEW7duVfKHU2WKi4uVxWX2kcLOzMxELBY7KpIGDocDWVlZEwwPXYMtW7bIHeQQiFmzZkmZMhPHEIPL5dLrXnnlFQDJJAw3LJ8FF5r5OdEtfPPNN2V4OLyChmvHjh1wuVwp37c+MjKC5uZmZGRkqDuF64OZ/t7eXq1pKrbi4mJtKsqWSiwSiWgTsrY2HA4rw013mRlnjncDxmZa+azHd9sUFhZK7qmORCKBRCKBPXv2qIOFcqCcV61apWoHJl3279+v7jjKmeuutbVVA1focpeUlCjZ8slPfhIAcP311wNIGhWG5cy/Y5iC4RQOp+D0qyMpR8uttmDBgoVJ8E9N5VmzZo0SHnQzqN07OzvFIs8880wASVeb1vX2228HYNR/LV26FA8++CAAw807+eSTZb2Z1GHnxt69eydMMLn//vvFslhDxTKVzZs3o7y8/Igp+1QAB3O6XC6xCTJvTtTZu3cv1q1bB8BwJ+LxuGo6x1f7d3d3y3JziGhHR4fcYrJxllC1trYqxMHA+JNPPqnnSdZE1+aYY44Zk1RIVXi9XlRWVqKrq0uyJKNm4sDv9yt5QO+jtbVVzI9MiKx7eHhYMiVzHh4eFis0d9IAybVNN5ylP2lpaWIy/D5c9y0tLSm/ZonR0VF0dnaipaVF9Y30/L7//e8DSK5X6gxO3HrnnXck87vvvhuAwTRnzpwpuZo75yhDvo5MsrS0VDqIsne73fqs448/HoARGtq8eTM8Hs8R6xwt5mjBggULk2BKzJFDLUOhkJgfizznzZsHIBmcZrEnrXR/f79iWQyu0opMnz5dyRYGY9PT0zWlhHFIMsd3331X1e5kmlVVVboeYxdklatXr8bu3btTPmnA/l+v16tCbFpOJl9KSkrGWFYgyTh4b4yfkQ0dPnx4wpzL6upqMdLxlrmkpEQMn+zphBNOUGKIz5NTUtLT05GdnZ3yZVLRaBStra1jyo6YOCET9Hq9YmpkE5mZmZI35cH1mJ6erk4XXsN8hAevRUY4Z84cJWKI4eFhJb4oQzLVtLQ0PcdUBxsY4vG4BjSffPLJAICXX34ZQHLqECfvcI8+8sgjmsvIeC87Wp5++mnFLxl7ra+v13NjPJJ656abbsJZZ50FwGCJzz77rArp2RzC0raCggI0NDRYMUcLFixYmCqmRKccDgeCwSBWrVolC0rLwKzTqlWr1MrHDKnD4RBjZIyAWaRwOCxrwSxofX29LA9LAmi5q6urxTDN/dfM0NLasuVozZo1KC0tTfnMn81mg8vlwltvvaXMGq0w7ykWi4mJMO66fft2xRrZ5sczN6qqqsQSOceuq6tLjJGFtJdddhmAZHE3WxR5jaVLl4rdMNvINrhdu3Zh3rx5Kc8cgbFHfABGrJzsr66uTrFAsme73a71R4bBUpucnBw9F5YApaeni6nz2ZER9ff3672s8GhsbJRHxe9FdhmJRHSNowHxeBwFBQXy6ihLznZNJBKKY9NTOXDggGKubIfl2p8xY4Zkx5/bt29XqRmZIL2YuXPn6ndk3z09PWKKrDZg5Ud/fz+am5uPOAl8yr6mzWZDQ0ODHiaHr1JZ/uUvf9Hm4Q2fccYZWjQMiLL7IycnR0kALsRjjjlGNVFUAkzTB4NB3RCTOxdccIEWOeuYmAyaNm0ahoaGUr7cJB6PY3BwEC6XS8qOG4X35vF4tMGIZcuWSUZ05TjOKRqN6r10URoaGnQNLkSGLDwej2RL16esrEzXZ+iCPfNHC5xOJ/Ly8tDU1DShrpAoKSmRAqTSGxoakhvHHmDKuLGxUaEK88mE43/HdQ+MVZTA2BMJKWOzK53qa5aw2+06LoOKjwlRJlQvu+wylZzRMG3YsEEzFGiQ2MmyZcsWuc5M2K5Zs0aGiOPPOGyCpVqAUcq2aNEiETQmypgAKi8vR1VVldVbbcGCBQtTxZSYYzQaRUtLC+rq6mQFaAWZHAmHwxPG75uPS6XrzKSNy+XS79g943a7RY1Jm+mONzY2KoHDYOvg4KBcbAbQzVNBSktLU77/lwXggMEeyELYP7pq1SqFFMwFyEzYkJWzQ6atrU3X4jU8Ho8G4DKB89hjjwFIBqnptpPlzJgxQ5aY16WM/197XxojaVW2fdW+dXV19b5MT8/OOLKDEIdhccCICIK4oAIiatSEhBii/jIaf5GgiRoh8mI0MYC4EUXQyJ4IDDAMYYZhZsBZmpnel6qurq7urr2+H5XrqlNVzZAm8vLM9577T89UPfVUPfe5z7mve49EIggEAo5HOETlkUikafAT03Gmpqaagim9vb1K4WmssW5ra2vq+DIzMyO55ZoQOW7btk33Iprv7+8Xv3kv/ob29vZTavpgT09PXVUPZZFBvGeeeUYBGSbi79ixQ9dT1mkaezweWaM0x0+cOKGqGa4R1+XOO+9U8QktoenpaXX2oXXK63t7e+va8a1Ezj4xLFmyZOkDoveUBB4MBuWveuqppwDU/Fxut1tJwaxz3rlzp9IjHnzwQQA19PHcc88pHYiDcdra2uT8Z4IztXMwGJR2ITocHx8XEqDPkRqpo6MD8/Pzjg8aFItFzMzMwO/3KwBCxz15HQqF6upMgSrfmRhLNMlr3G63fF8mXxr9vkQ3IyMj4ht9ys8++6xQN/1ifO/iiy9GqVRyfBI4kaPX6xWSJlKjnJnPQf/U2NiYUB75yMBgJBIREiRK7OjoEPIjmma9+8TEhD7L35DNZuWb43ry8+aYV6dToVCos1KAGk+YFN7T06P4BBOzb7rpJgUDObaV58KVV14puWd5cbFYVJzhoosuAgDNZf/Od76jc4EocWZmRoFdWplEjpVKBcPDw/+9ZrdAddHn5ua0EQllCZ9zuZycpOye/Mc//lHBhSuvvBJALZLNzwO1DTwzMyOYTXOaZvwvf/lLCRzN989//vN6eJo9FLpKpYI333xTB4KTifWpjKzxECJvN27cqKAVo8p79+6VS4MCyeh/S0uLhJNC19XVJV5xQzKiNzExoWAalV2lUpEgchg7eZtIJNDZ2el4s9qcAU3+0XnPAzGfzytyTGUQDofFU7qPqIRDoVDTwTY9PS2ZbGwGXSgUmtp5zc/P19USA7WKmmAw6HilQ/J4PIhGo8jn85IFKmwqoccee0wuDHbzHhsbE7iiDJsNrNmIhu6c5eVlzZNh7i35tXPnzqbc6HXr1skNxYOTM2cikQgOHz58UtBkzWpLlixZWoFWhRzz+TxGRkYwNjYmTcwgAjXs8vIynnnmGQC1rjIbNmwQ8uMIACKZPXv2KDBA7Xz66afL5DPrVgHUTT5k09XDhw+rfRl/DzVFPB5HR0eH4ytk2PGora2taa40tamZFkKN3N7erpQHEvnj8XhUb0oNm0gkhFLMjjRAFVXyNeaDeTweBWTY+YjmfjKZxCuvvOL4So58Po+xsTG0tLTIkU8XgRlgoYzRynC5XDKdyW/KeXd3t2STKNF07lPemDqyefNmoSmay/l8Xp+ldcB1mpyclEnvdCqVSkin04jH40LmtBTpjti0aZPOgO9///sAqul5fJ/7nWk7oVBI/KT8XXfddU2zY5hXac6DoTX6kY98ROlnRIi8Znl5GR6P56RWj0WOlixZsrQCrbpCJhqNYv369TqRG/vW7d+/X9qVCMXn88nRT0RHVNTd3V035Q2o+hh4HdEKNevMzIx8PfTn7Nu3TxqYqRFEW2vWrMHw8PBJM+GdQKytjkQi8hkSrRCpDQ4Oqnkok+RdLpcQNP2QbF573XXXyTlNfgQCAWlwpkUwtWdyclKpU0y7GB4elv+X2prIdHJyEhs3bjxlusdkMhmhNqJlIopSqSQ+8jnXrFkjuSLioK8ykUjoOqJQMxGZf8mbcDis1+hLXrt2rSworgn3icfjOWXmVodCIWzbtg1btmxpmh9PeTr77LP1b8rn7t275c/m+cH1mZmZkQxSdvP5vJLxufd5/uzatUt+S6atPfTQQ7jhhhsAoKlQ4ujRo+/aBNsiR0uWLFlagVaFHL1eLzo6OvDaa6/JN0JEx5SIQCAgpMPuMu3t7bLtGQk00RC1OJNDzagpo9o/+MEPAFQ7ANPHRi1y9OhRlR1RQxB1DQ8PnxJDoIBad2LylJF6ot6FhQVpRT7n3//+96ZIHz+XTCbFR6L4XC4ntEKfMGlwcLCu7heolgwyosqxF1wvE/k4mbxeLzo7O5FOp2VZENmQj+l0WlkCRBOVSkVyS3ni56anp9V70Uy5YhYHI6ZMpq9UKk218plMpqlTNZFQoVBwfBYAKZ/PS16YckeUSORdKBSUosZ66ksvvVSJ7j//+c8B1HzAo6Ojuifrs1taWpQGxHsx0+LQoUNNPR4/9alP6R4k7q1Dhw4hFoudNCNg1XOrE4kE1q1bJ9OZTDDNEzr12U7o7rvvxm233aYHBGrmby6Xk9PaHBbPe7AOk+bhNddcg4cffrjud83Ozkqg+bt4GPb29uLw4cOOd26zqUcul9Ozc8OYuXZUQuR7a2urTJLG+vVyuayNS8UzPDysDU6zkC6S559/XrlozDk9ePCgNjUFi5t7bm4OPT09jlc8bMY6NDQk/jFth88bjUa14ahsSqWSDk/ylpu3u7u7TuEAVX6YdfBAraHwSvmgLS0tUnwMwvH/fr/f8UFEk9xuN44dOyaXF/nFdL7p6Wl84QtfAFDLTQTqq+eAGi937NghuaJ7YXR0VAqa6T3cBy+99JKCOvfddx+Aah4uA7Vcl6uuugpArb2cnT5oyZIlS6ukVakmv9+PwcFB7Nu3T5Cf5jWd2YODg0rXYaLmmjVrdHKzWw7h7tNPPy2kc9ZZZ+m7zAl3AOomDhJ9UgukUindnwjJhOebNm1yvBZ2uVzw+/0488wzheSIYOg+eOutt4Q+iCoHBwfF+6NHjwKoVcqkUqmmgWP5fF4amUEdmkIXXHCBWr2x3t2co8378rt7enowOjrqeFROSiQSMnMZAGHqVygUEmrja5FIRHJKOed7Y2NjCh7wXuvWrZMFxXsRXba0tAglcV0rlYrWhfc3O/Y4XWZJrJzzeDx6fgZZ6Xro6emRCcxRH8ViEXfccQeAWncdVssLF+ZkAAAgAElEQVStX79ecs1E7nXr1jVZqrQoZ2dnZRGxKuayyy7Db3/7WwC1FELupXK5jLa2tpPy2CJHS5YsWVqBVl1bXalUEA6HpfEaO8KsW7dOvkMmcX71q1+Vn5DlP0wPoaYE6tv2m33dgJoGisViTUhm48aNQjPUwNQwfX1979rU0gnkdrvh9/tx+PBh+WOJUpiQPTIyIkRHn86+ffuU9EpESCQzMDCghrZEnEeOHJF/i/4brqXb7RaK5Lrs3r1bfjMGd4jwmezv9LG3Xq8X8XgcHo9HckrfFuVieXlZ/KMsmWikUd77+/vFI/rZksmk5Jq+TSL3hYUFvUf+R6NRWUH8HgZyWltbJfNOJ6bqLS8vy8fHxG1zdAfliL7BoaEh8YSW4bnnngugygeeH/Sp79u3T3JMny7jGtFoVGt76623AqhaCjfddBOAWooU15213icrH1w1bi+Xy/D7/XVRO6AWsbv00ku1WQiRh4eHdaCxIzUPvaWlJR2KzHafm5tTZ3FuSJroW7du1QHB6OIbb7yhh+aBQsHt7OxUxMzJVCqVsLi4iKNHj2pzciPSVXDhhRcq94vmxOLiojYu8xy5Jq+++qrWhYfp1q1bJVBcJ5oaoVBI7/E3bN68WS4OVj8w2mi2S3M6uVwulMtl8ZKbwsyi4Gs0hVtbW7UJeaCRj5FIRNfzEGtpadEGZSCRPDNbu5HvExMTOhzJRzOwaVZEOZkqlQpKpRJ2796tg48Km8pheHhYe5n7d25uTgExAgK6Mc466yxlCJiNgCn/PFTJt6WlJeVYMo+SbdT4/UBNrhcXF9HZ2WnNakuWLFlaLb2nZrft7e1NzUKp5T70oQ/JUc1Te2RkRIEVIjum7xw4cAA33nhj3T3C4bDy+ThJjKk6hUJBKJEafmhoSOkBDPHzvWKxiIGBAcfPkCkWi5iamkJPT4+QLrUiuxAdPnxYfLn22msB1BAnUEtLIfn9fpkhNCsOHjyotWNTUKKbeDwuPhO5JxIJrTF5S4Tf0dGBI0eOON6s5vyYtrY2yRj5QlM6Ho/LHUE0YeYakmdEPwwWALV1CgQC4h/XhAGgQCAghE5Tc3l5WajfbBbNv6dKniPPBbN5rDmqAwA+97nPaQ8+8sgjAKpydNdddwGoBQVffPFFAFW3GC0WjlqIRCKSNXbsIfIeGRlRVR3dHOeff75younqY1AsmUyK5+9EFjlasmTJ0gq06goZnrx0ktJHwEThn/3sZ/I38JT/2Mc+JjREhy39YvPz8/KV0R85NDSkz9JnQQ1w8803CyH9/ve/13dTkxOtsvqjv78f4+Pjjk838Xg8iMVidUnVRL/Uvm63W6icvrN0Oi3nP+vQzYAMfVj0/0ajUaFIDkDjmuZyOfGZaRezs7NCM9TI5CX9o05PAidvR0ZG9Az0cRFRpFIp+dGJ/kKhUN3IBKAWMCkUCvK9UrbL5bJ4Q/k266753ZTVWCy2YtNdoIr6T6Xpg0BVPsgv+gTvvfdeANXUPMYBWNN/++23KzGcidv0kU9PT0suGZAMBAJ1aVBALYBz66234g9/+EPd/a+//nqdFTynaC21trZiamrqpOeCs6XakiVLlj4gWhVyLJVK6l7MsHxjK/d4PC6tyd5sV111lTQK00e+8pWvAKj6HHmasxN4sVhU5Il+Lqak3H777XjiiScA1NDqOeecI8TI9B7+nZiYQDAYdDy6YULw2NhY03AmRpCnp6eFDumPeemll4Ts6Mtiwuv//M//qPSKQ8l8Pp9K54h4iFrcbreievQdeb1eISn6eYhazz77bMTj8VPCN+ZyudDe3q7fTrniX7MDjonmiGQaez2uXbtWUWp+NhAI6DWWWhKZ5vN5rSdRTzab1e8hv4lMzbSjU4EqlQpGRkbkk3300UcB1Eat9vT0aOTJT37yEwDV7AvuS0a56Y8888wz8eUvf1n3Bqr112eeeSaAGmLk3ti6dSt++MMfAqil8mSzWa0NESL5HI1G4fF4ThqLWLVZ3dXVhbGxMTWV4AbjBjGbht58880AqkLGPKb7778fQM3s/eIXv6hN/elPfxoA8OSTT4rJhMOclVwqldTmiHB7ampKh2/j5MNoNIp0Ou34BgkulwterxflclkCQx6w2sfn8yl/k4Gt9vZ25R0yaMDW89PT0/o3gwELCws6YPk9dIYfO3ZM60qT3uPxyNQmD80cwXw+7/iADHnb1tbWlMJjum94eJGPnZ2dOryogJg+Njc3J35QEXs8HskhP2e25uNrphuDwR8GFnivRCLRVHfsZHK73ejq6tLhc8sttwCouYRCoZCUK/f+3r17ceeddwKouSHMZrlcG67Hjh07xHNebza8ufzyywHUAob79++XW46HKJXd4cOHEYvFTgqanA2nLFmyZOkDItdqtL7L5ZoBcPz9+znvKw1VKpWuD/pHvBNZ3r5/dIrzFrD8fT/pHXm7qsPRkiVLlv6vkDWrLVmyZGkFsoejJUuWLK1A9nC0ZMmSpRXIHo6WLFmytALZw9GSJUuWViB7OFqyZMnSCmQPR0uWLFlagVZVPtjS0lJpb29HsVhU2RPLeViOVSwWm2ptXS6XSrNYc8rSuFwup1pilh4tLy+rYy/vxe4agUCgqbV5qVRSjSTLlVjGVS6X4XK5MDc3h0wm49gi4EgkUmlra4PH41HZFJ+dz+Tz+cRv1oqy5BCodXThs+dyOZWj8RqPx6P7cQ35OZ/Pp9JA3qNYLKr3IWusWXLlcrm0touLi47lLeXWHI9KHpt5vnyPPPD5fOIV12IlOV9p9nFjeSJLGE0qFAp1vSOB+l6S/Oz09PSsk5PATdmlXFJGKHder1fPQzkCanXsfM8s8+VrlGFzjnjj9ZVKpYmXbrd7xXXmPSuVCpLJ5DvK7qoOx/b2dnzve9+ra/TJB2Vb+MOHD+vHsa3Z2rVrVUTPtkWcQri4uIi//OUvAGp1q9u3b5fAkTG7d+8GUK2bZAPRz372swCABx98UAX7bGnEmtbx8XG0t7fjnnvuWc2j/q9TLBbDN77xDWSzWbV7YhMD1j5PT09LabBONxwONzVi5TWZTKbpHjMzMxJcKiWuodfrVS2q2ViE7b0omDxMe3p6EAwG1UjAqRSPx3H77bdjfHxcDTuorE0lTV5R9hYXF/Ua5ZAyPTs7Kzln84pEIqHNTuViKifuATZMWVpaUhszyi83eyqVUk37bbfd5ujqk9bWVtxyyy3o6emRYmmcod7Z2al/U+6GhoYkW6bCBWpACagBgb6+Pt2X/GKtNFCrf+cZY87+5v3NWvZsNou77777HZ/rPc1+5FhDoNZvkUwZGxtTF2Bu8nQ6rYdh78Z///vf+rE7duwAUJuL4vf71aCCgkSh6+7uFoPYt+3ss8/WgcnBPmzQ0NXVhcnJSccP2CqXy1haWoLX65XwmIObgKpG5L+pBMy1oEIgryKRiNaACi0UCukw5fVsepBKpXQwUEhnZmbUeYmfa5y74vQqq0KhgKmpKXR1denwIV/Y2CSfzzdZQ5FIpAkts2tRV1eX3uNaxGIxNUNh4w7Kb29vr5QK77W0tCSZb7So0um0moU4nbxeL7q7uzE3N6ffz2elbGWzWfGCezGVSglUcU9T6Xd0dGht2BPz2LFjkk8qeza+WVhY0EHJ73S5XOI1fw+v93g8CIVCtvGEJUuWLK2WVoUci8Uikskk+vr61IKMJzi7T/f396s3G03Z7du3SzOwvxq7UP/4xz+WhqB5cs8992Dbtm0Aqu3LgJr2GB0d1f3Z6uzuu+/GJZdcUnfdq6++CqCqPYaGhhw/Q8blcsHn86G1tVVmMdE4EUqpVBKKI7pZXFyUpiQ65LOWy2VpWl6zsLAgk48Ilddv2LBBCN80/WjW8D2z27PTW8EBVdN2YGAAuVxOph3NNspcpVIRH9gibnJyUmY05db0YRGNmNME2a+UJh7RqOmn53vz8/NNs2PIa7/fLxTmdMrn8zhx4gSCwaCsC7rIKLujo6NqwUaUXCgUms4FXpNOp5v8luVyWTzk93Ady+WyECn3TTgcFoInL7nGxWIRmUzmpKNZLXK0ZMmSpRVoVcjR5XLB4/GgXC5L41ITm74cznbh3I09e/aowSWjzvRV7tu3T9qCPsRNmzap2zdnztAvOTExgQMHDgAAfvWrXwGodgUm2iJypD9t48aN7zq82wnkdrvVsZwIrXHgezAYbJqal8/nxVNqUWprn8+n680OyPRlUYPzmomJCfniyK9sNqsGpPwdpm8unU6fErz1+/2YnJwU8iY6JFKLxWJCb0SC0WhU6Jp8IRIxI6dmE1v6tHgdkYrf79d9ec3Q0JCsJtMPCVR5TDlwOlF2zU7rfFY+XzAYbMo8icVi2reUKRNB0kIxLaLGjum0cLLZrOST8jw6OqoAnDm3B6j68bu6ulbMNNBzvSduWLJkydL/5/Sepg+Ojo5KMzB6ytkOu3btki9w7969AKoIiFpg69atAFA3YY+nN6OzIyMjij5zVgTnKGezWVx11VV1393b26vreS+OAlheXkYgEHD8nBP6HMPhsNAKtS79XiMjI9Kw5mzrxvwuMypKvpua1vTr8LuBKjqiJudvKJfL0s5sTU/0lc/n0dHRcVLt6wTKZrM4cuQIotGoUpSIEvnbT5w4oWenbPr9fqEcPjt9aalUSmk6vP748eMaWcEoLH1d+/fv13tE7plMRuvDlBbO9wkGg47PsCB5PB60trZiZmamKe+Zz18ulyWXlL9wOCw5JuqjNTM/P1/nawSqck1ZNNPVgKrFSP8l0eWaNWtk2Tb673O53LvOlVrV4ZjL5TA8PIzW1lb94MaRlW63W0GaZ599FgBw4403an4EcxMJczs6OnD48GExBKgK4ne/+10xxPyeF154QRv3gQce0HfSfLn00ksB1DtxBwYGJMhOpWKxiEQigVAo1JQ/x7ytYDCozc0ZMktLSxJACgWd1bFYTMJAoTpx4oR4wWAAlUxfX58OAd7f5XKJ340Cmc1msbi46PhN7Pf7sWbNGrjdbv12ppuZLgMeVDTt/H6/ZJKHFjf92rVrZTqTn21tbXUpZECNZ0ePHtVGZdDGDMjwOh6+8/Pzjlc6pEqlgkKhgLa2Nskq+cD9u2HDBikAc1xtY9EG3Rft7e1SYKb88d88VHl9LpcTL83gMIED1418puyeLKBozWpLlixZWoFWhRw9Hg/i8bjMqZXowgsvFOrgqTwzM6PgApNkaV67XC4hzT/96U8AqlMIaUo2lgvFYjGZm0zfOeecc/DMM88AgII1nEpWKBRwySWXOF4LezwetLW1IZFIiLcMFpAH+XxeCNBM0SE6JGLkNYFAQJqciKlUKgnpUFsTFU1PTwuh83Pt7e0yP2iakLfr1q1Dd3e37uNUYgpaJpPRs1Me+WzhcFgImkg8m802VWrRdAsEAkIxDO6cd955Wgt+jsjo+uuv1+hhmuqZTEbXcTqeSVwzpxNdQpVKReiNlhyfIZVKSY7NChaiSL5npjtR3mhqLy0tCU02ngv5fL5plC3XyryeFm6hUMDs7Kz22EpkkaMlS5YsrUCrLh8sFotIp9MKlFAz0I/y4IMPqiaUf8877zy8/vrrACD/Ih2wgUBA/oNPfvKTAKo+AwZgqD14/1QqhaeffhpAFTECwBtvvIFvfvObAGpa5q677gJQHXC/f/9+aXmnEhsTJJNJITHyhdoxFAoJFRJ9DA4Oyq/TOLN7ampKqJAo/u23325KhKaPJhwO6zV+98jIiLQ7tTaR/sjICDo7Ox2fyuPz+dDT04OFhYWm+nAi5ampqabywXK5LJ4SOVK+jhw5grfeegtA1acOVK0WXnfFFVcAqKH4f/3rX7J4GKzZtm2beG+mawHA+eefj9/97nf/TTa8b8S68dbWVlkVjeWQLpdLqJLI0efziV9cDyLpVCol3hGZx+NxIXHewywn5J5gcHZ6errJQiB1dHQgmUyeNFC7qsORTOjr69NhZ0bvgKq50tj5ZOvWrcpzpMOfApLNZnXQvvbaawCAr3/963jhhRcAVE1soCY8v/nNb8R4muZmZOvee+8FUGPo+vXrceaZZ8px61Qql8vI5XLweDxNw9+5sIVCQfxj/taxY8fqTEOglkPa39+vzceDLRAIyPTj95B3sVhMZgeDQcViUZ/lgcnvc7vddU51p1KhUMD4+Dj6+vqaOh5RUZjPwOctlUratJQnbtiOjg7ccccdAGrVWL29vZJJ7gvKXU9Pj+7L70yn0zjttNMA1IJA/L5UKiU3idOpUqmgWCwin8/rMDIrUYCqrJiVXgDqgnnkE9fFDA7yc5FIRDLL7+FZs7y8rO/ke6VSSZ9tzNpob29HOBy2tdWWLFmytFpadZ5jZ2cnRkdHhSyIGFlrvWfPnrrqCgD4xz/+odA+8yFpEg8PD+Nvf/sbgJoW6OzsxKZNmwAAr7zyCoAaIvzWt74lSE0Hd3d3tzpyEFVSc8/Ozjo+xxGomhhdXV1obW3V72XqA1FzNpsVb+nO6O3treuqw+uAqunB4Bg1Z6VS0WtMp2Jay9TUVF0LL6Cq3YlEzd/Bz7399tuO52+lUkG5XMbY2JgQt2naAVWZY0cnIpDl5WXJExE40fy2bdsU/ONr69evl0wSEZmpJ43BtHQ6LZcFzWmahA8//HBdOy4nk8fjQTQahd/vb6okoqyZvRX52vj4eFOFDM1ymulAzRKanJyUrFE+zRxd8ov3MNePa0rZnZ2drataWokscrRkyZKlFeg9JYGbdY9EK+xzd/DgQQVi6E/56U9/qooVntxEKCdOnJAm4Sn+ox/9SMiRWvlLX/oSAOCRRx5RpQH9CQMDA/jzn/8MoOYvYppPW1sbAoHAu2bDf9BEn+PExISCKCTyOhaLyfdFrbq0tCRHP1EKgwz5fF4+GqJDoFahQR8lE6F7enrkV6S2jsViQoy0Dmg1HD9+HOvWrXN8xyPW/qbTaaXrEIEztSydTgt5kH+FQkHIkjJKOX7hhRdUKWT2emQKGn1bZ5xxBoBqk+bGlKt4PC7LaOfOnXXffeONN8racjq53W6lQlEu+Rym9dPY7TwYDOoZuc9JZkK56RNv9B2aSdy8P+W6vb29KUjD8yEej2N6etp25bFkyZKl1dKqu/L4fD6sWbNGtj7RxMUXXwyg6nehL4bob2JiApdddhmAWmSPKOfYsWPqvENEcvXVV8svw3tRO+/cuVMI0+xMw7psaht2Gr/88ssRj8cdXz4IVNEMu1YDNbRC5DY5OSkNaCIgU1MC9Z1dGv2EiURCPkr+JSWTSaFWrqvb7dZa8F7Utn19fXWzTpxKxWJRCe6UOz4DfdPxeFylmeTVueeei127dgGArJWXX34ZQNVHyXvRr7Vz5051liJyIjLauXOneg3wuzdt2qQ9Qh8af8MZZ5whK+FUINbgUy7pezTLLs3IMq/hfiUiNJO8uTZEhIuLi+JPI6Kfn59vimSbfQcoo/wN09PT6OvrO+m5sOrD0ev1olAoyExrzIvbu3evzGlu2iuuuEIPffTo0bqHMov7v/3tbwOoCjOF5tChQ3UPfPDgQQkXP7dx48a61CCgFvg5duwYXC6Xvt+pxDSprq4uCRZdFhSIwcFBmWRm81q6KGhec2MuLy83pUPE4/G64AyAuqoGfqdZu93YToumY6FQQDgcdnxAJhAI4LTTTsPbb78tFwCfmfw8cOCAmiibg7Auv/xy3QOoyZff75fJeP755wNAXXUTzT4Gcrq7uxUMMlO0yFOa6DxMXn/9dSkop1OpVML8/HxdhUpjYKanp6dJdlOplA5AyiJ5MzExUTeIC6gejuQhv4vXmI1AqGi6u7ul0PmamWb4bkrdmtWWLFmytAKtOpWnq6sL4XBYmpSoxmzMSsc2q1y2bdsmZEcHOD+3fft2NbLl6IRkMoktW7YAgMzxN998E0DVTLnuuusA1BJnH330UaVEENFSSzGJ2elVHOVyWfWkdGoTvVFLHjt2rC7YAlRdEY1T3YgW+/r6pDnNRO7GtAauRVtbm+7B5N3e3l5dT8RIDe31ejEyMtKk4Z1GbMprts4jgiCP9+3bJ7Rz8OBBAFXLhClnzz//PADgox/9KIBqoIEFCvfddx+AqrXC9SH6pLtnaWlJ380RIM8884ysLL7Gz5fLZbmbTgVyuVwIBoNNaWLcdy6XS2jaHExGOWtMzo9Go/osr+nq6moyj8nTvr4+ySkRvcfj0V4gIm0ctXsyssjRkiVLllagVSHHYDCILVu2aJA7UEvJoZYrFAoqA/za174GAPjFL34h5/L27dsBANdeey2AaoCG4yl5/fj4uFIm6GPgbOsNGzbgoYceAlBDqxMTE9L2TEshunzuuecwNjbm+BI3j8ejtBn6oegnobbs7++Xw9schUB0yLWgVjXLz/hvr9crTcz7U6uGQiGhQvqSmVDL7zLfy2QycLvdjvc5ut1utLa2YuvWrULG5Cl7jobDYZWsMrj45JNPiqdEkOZYUSZ8szQWqKVJETlyvbq6uprqqDds2CALqbGbjzlgyunkdrs15pSojcFVyozZ8cksleQ5QtRuJnwz+Gim/lAeaV3x+8zgIr+Te4r/NokW8Ml4vKrDkU0tx8bG6h4CqM2cnpubU9CFm2bz5s2qOSX05WGWTCZx9dVX1z3oli1b6pyqQK2l06FDh5qisn19fXJk8y9hvcfjwfbt2/HYY4+t5lH/14lttebm5vTM3MBm/SlNDbNlHIMLjfNLPB6P3AwUwtbWVkUIGxutlkolKTEegPF4vK4aB6if9cx7OJkikYgOMG4immMXXHABgGplF5ub/PWvfwUA3HDDDZJbRp3ZbGLbtm1aF+ba5XI5HXbc7DxAJyYmdB3vOT4+rt9B3rJazOv11uWmOplKpRIWFhbq3Bb8S7BiZj1QrpeXl/XclFkeVh0dHU3d14eHh+t6CgC19QyFQnVt+YBqBNucFmn+LZVKSCaTNs/RkiVLllZLq0KOhMGTk5Ny8FMb8gT3+XzKCaPDv7e3V6c6nf9Ef9dccw0ef/xxADUE8/TTTwspMl3nueeeAwB8/OMf1+/hPXO5nJy9dJzTjOzt7T0lNLDf78fg4CAKhYKehUiQAS632y1NR/TH5sNAzUympj1x4oSuo3kRCoV0HYNYvGepVBKvzFpXU9Ob7xWLRWSzWcfPrl5cXMTu3bvrECR5TBfDpk2bVOVF2czlcuo+RUTNAMvAwAAeeeQRALUqmHw+LzllAJJWQG9vr9aA38N5zwCwe/fuut915ZVXygJzOtGinJ2dVUCGMkZ5MmurzXnclHFafDxXMpkMNm7cCKB2BgwNDWkd6JrgGRAOh2XFmEFF1rNznWlyJ5NJDA4O2umDlixZsrRaWhVyXF5exoEDBzA/Py9/YmOXk82bN6u22kwp4QlPVEPfzNTUlP7NUzyZTCrA05jiMDg4KOTy4osvAgAef/xxIVdqLmqsSCSCyclJxwdkKpUKcrkcFhYWmlrNm4nZRHl8XpfLJY3M68jH7u5uVQ2QZx0dHVoLInV+zu/3N2l+szsK/bjUvrFYrC6I41Ty+XxKa6I1c+GFFwKoJWmXSiUVHlCWe3p6FACgD42827Vrl3yHtIbMGd60XMhHn88nP67po2TzZ6b0EFXNzs4qWOR0YreuVColuaSvkbJozkvn80ej0aYRHORfKBSqG4EAVOWvsTcD759IJJRqxtfK5bJQJPcUzwH2Oj3ZuWCRoyVLliytQKtCjqFQCNu2bcN//vMf+U3M0ZZAFS3SL0DfY39/v+pK6UehFkmn0/ItsP1+LBbDRRddBAB44oknAAA333wzgCpyZMSQ2vbEiRPSJPRhUHMvLy/jnHPOcTy6Yd16Pp+vG54F1KctkM/UvslkUtqPNb5EeIFAQH5Fat/JycmmEa783IkTJ3QdtfDg4KB4SvREFOrz+ZTC4WRyuVxNyO/+++8HUMuySKVS8u3SN/jkk0+qrO+f//wnAOAzn/kMgCoqp3XDa1wul3ySRKRELv39/fIncn8MDAzUdXkHavtidnZWY4ydPi6Bpa/0rwI164K+vmKx2OSbXlhYkG+2cW73+Pi4eMd7dXd36zWmA5lpO43d2svlclPXe/qTE4kE4vH4SX2Oq54+GIvF6kxb1j5TGEZHR5USwR9Lh7j5w/n/9vZ2fZbmydGjR2VuEGYzB21wcFDmBt8zp5KZc2+Bat31qWBWl0olLC4uIhAIaCNTsMjHlpYWPRdTGdrb2yUANMO5yfP5vO5B5ZHJZCQodI1wQ/LQBGopFZw4aV7PQzuTyWB6evqkE9ycQAx8mK32+JtZ8ZJKpZr4QlcOAHziE5/QvYCqvNPEo1vCNMN5SPKeU1NTUkbkrVkFwnxI/u3v7z9laqtdLhdcLheSyaSejTw0XWWUL7M2n3u/seltqVRqUvaZTEb7m7JORZZOp+WyIw8XFxflXmsc8REIBFAsFm2zW0uWLFlaLa0KOebzeYyMjGB6elpwlgETIhpTe1DzZjIZBW7Y+YTO71gsJg1JrTswMKBWZTS5+feiiy6qa6UOVCcTEmlSY/P3VCoVZDIZx6ebeDwetLS0IJVKCYlQ0xIJmu8RzRWLRWnTRqS5Zs0aJWxTM09PT4tHfI9kDuSi5jfNdn4nTdNkMom2tjbHV8hQbn0+n0xgyhyfpaurS8iOz2uacUxSJu3YsUP1/rzH5OSkqmu4dkSO3d3dQkIMJL722msyRdlFyhwDwDVzOnHAljknms9PXmazWbmEyNNMJlM3kx2o8cvn8wntce+2tbXp3+QNrZhEIiGEaY5waZzMyTOjpaUFiUTipOeCRY6WLFmytAKtCjm63W60tLTA6/UK2VFr0m9l+p+IHE8//XSl9TSG+AuFgpJo6XMMBoPSDNQ8DNakUilcc801AKDRCG63W0iR379nzx4A1ZShUqnk+Ias1L5moje1GnlcKBSaEsPb2toUHLU0wdMAAAZSSURBVGsci5lOp5VWxWDAhg0bVApH1EI/3NzcnLQutbDX662rbeV1QBWdR6PRkzq1nUA+nw+9vb3o6+uT1cEiAwZVTjvtNPGFaR9mORzlkc++d+9eIXRaSldddZV8u1wToqSpqSmlq/CeHR0dQkqNIxH8fr/u4XRiMNGUg8YZ1e3t7YoL8CxoaWkRouM+p3z7/X7xi5ROp5uu414Jh8PaLyaC5d5hrMOcW/5fbXabz+dx/PhxRKNRbSJuUv6w2dlZ/RBOc+vt7RUTeIiRQb29vXpQRqgPHjyog5JCSTMoHo/j0UcfBVCr8Hj22We1gRntMjsAvxsTnEKVSgX5fF4O60andrFY1GsUtFwup0OLhyJNFLfbLXOQ68UaWKB+fjJQ3bQUPnOduMaN+ZHFYhGjo6OOb1nGyq7FxUUpSbphyJ9sNiue0om/sLCgw41/zYmAzJbggfnWW2/pkOO9KHfpdFr85oZubW3V7+F7PBCi0egpM32Q/F2/fn1T4IP7cHZ2VjLFvgDBYFDPz/3Oz5m10nSFTExMNDWo4Dnicrl0IPNcmJubkyuIhzTXMRgMvmu7PWtWW7JkydIKtOoxCR6PB4lEom62L1CDuWardKK9+fl5neA0O6g9X375ZZl+v/71rwFUzXA6rxtTV/r7++X0ZnPcD3/4w02mHTUWp/o5PSBDs7pQKMjsoquCSDwUCjXlJi4sLAidMPfLnAzJQBgplUoJxTfWZJsjD+j+GBgYkClKjUzXBWfOmGMFnEqVSgUTExPYvHkzgJqlw/8nEom6KYxAFSmTl5RXIvDBwUHtAXOGMvdBIyJcv369AmGU5XK53OT2IDIykZbTieleqVSqKYhCHnm93rrcXKDKG75P64dWic/nE88pf6VSqW5ONQDxb35+Xq/xTIpGo7IMiML5+fn5+Xedf2SRoyVLliytQKtOAueUNqIOogYimo6ODp3STBCfm5uTtmAaA30G5sxj03dGTcqTn36ydevWyT/Be7a0tEgjUDvRd+b3++Hz+RyfbuJ2uxGJRJBIJOQfaXwml8vVVIvK9B+g1gmGfMnlcgoa8B7xeLyutheorUUymZTfhhrZ5XJJm1MzU9smk0kkEolTYgRFLpdDNpsVGifa5v89Hk/dLHCgiqzNZHig5rs6evRoXVoIUG81NdZkl8tlBbkYqPR4PPoM/Wv0d46PjzelDzmVWIGUSqXqasmBGk+KxaIsDhNVUnZoHfEcCQaDQoDkfVdXl84dBqt4ZmSz2abaaq/XK9nmOnKvdHV1YXZ29qTVXRY5WrJkydIKtCrkWCwWMTMzg61btwqRUOPxRI9Go5pNTQSZzWalEVhaSF8Yo98AcOuttwKoor6nnnqq7ruJQrPZbF0EDKj631izTc1L9OT1et+1+4YTqFwuKym2MWJMP1cymRR6I79ZugXUUBA/F4lEmkr+crmcIqlENaSOjg75Land3W53k9blX3ZbcjoqB6pod2lpSfJKHtAHPjExoeegfzwcDjd116FFA9RQkenPJuokv+mnnZmZESonjzOZjOSVSIu/r1KpnBJ8BarnwuTkJCKRSF1HHKD2XC0tLZJj8nJ2dlaRaNZWEwkGAoGmkcBut1vou5FisZhQvTnOg6lSXDf+PrOHwTvRqgMyfr8fyWRSgmHOwwCqG4bCZR6ObFjJvDIeXjwUTNqyZQvOPfdcALXZMRyWfvXVV+uAeOCBB3QvCjtNPrZB8/l8iEajjk/lYUDG4/HoWchbLvDS0lJdaghQFYrGNBNeYzYVpVAtLy/LlcE14KblLBDzuycnJ6W8SMyP5Dxwpwe7mOc4OTmpzUj+caOuXbtWypYyNDc3p2cjj3hgeb1eXUfTjW3ngPrACj9PvpkHiGkCAjVz3OPxnDKHI/McFxcX5ZrgX7oGzOAWzevOzk4pebpxmArlcrkk16Tjx4+rso5nBmWZfAZqwTPTzGcwjOdQIpFAX1/fSYOJ1qy2ZMmSpRXItZrKEZfLNQPg+Lte6EwaqlQqXR/0j3gnsrx9/+gU5y1g+ft+0jvydlWHoyVLliz9XyFrVluyZMnSCmQPR0uWLFlagezhaMmSJUsrkD0cLVmyZGkFsoejJUuWLK1A9nC0ZMmSpRXIHo6WLFmytALZw9GSJUuWViB7OFqyZMnSCvT/AAe4p9MbVrQJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Weights with 500 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin, vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights with 10000 data points:\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "vmin, vmax = best_mlp_large.coefs_[0].min(), best_mlp_large.coefs_[0].max()\n",
    "for coef, ax in zip(best_mlp_large.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin, vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 9\n",
    "\n",
    "Describe what do you observe by looking at the weights.\n",
    "\n",
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "The weights try to identify the most important features of the images. I can recognize shapes of some clothes. In other weights is not possible to recognize something due to the noise. The weigths of 10000 data points are the most clear to understand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "\n",
    "Pick another classifier among the ones we have seen previously (SVM or something else). Report the training and test error for such classifier with 10000 samples in the training set, if possible; if the classifier cannot run with so many data sample reduce the number of samples.\n",
    "\n",
    "*Note*: if there are parameters to be optimized use cross-validation. If you choose SVM, you can decide if you want to use a single kernel or use the best among many; in the latter case, you need to pick the best kernel using cross-validation (using the functions available in sklearn).\n",
    "\n",
    "**[WRITE HERE WHAT CLASSIFIER YOU ARE CHOOSING AND WHAT PARAMETERS YOU NEED TO SET.]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kernel is \n",
      "linear\n",
      "RESULTS FOR OTHER CLASSIFIER\n",
      "\n",
      "Best training error (other model): 0.003000\n",
      "Best test error (other model): 0.193121\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR CODE\n",
    "from sklearn.svm import SVC\n",
    "kernels = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(svm, kernels, cv = 5)\n",
    "\n",
    "#Reducing the dataset. My computer takes too much to compute the training for 10k samples\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_kernel = grid_search.best_params_['kernel']\n",
    "\n",
    "print(\"Best kernel is \")\n",
    "print(best_kernel)\n",
    "\n",
    "best_svm = SVC(kernel = best_kernel)\n",
    "\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "training_error_other = 1. - best_svm.score(X_train, y_train)#ADD YOUR CODE\n",
    "\n",
    "test_error_other = 1. - best_svm.score(X_test, y_test)#ADD YOUR CODE\n",
    "\n",
    "print ('RESULTS FOR OTHER CLASSIFIER\\n')\n",
    "\n",
    "print (\"Best training error (other model): %f\" % training_error_other)\n",
    "print (\"Best test error (other model): %f\" % test_error_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Compare the results of NN and of the other classifier you have chosen above. Which classifier would you preferer? Provide a brief explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "The results here are little worse than above. But this is due to the sample size for the training data. For SVM I used only 2000 samples and in the above classifier I've used 10k samples. In any case I would chose the above classifier (i.e. NN with 2 hidden layers) because the computation power for SVM to train 2k data was higher than the computation of the NN to train 10k samples. I tried also to train with 10k samples but it took above 30 min to complete. I obtained better results, but nothing that justifies the time spent on waiting the completion of the computation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with K-means\n",
    "\n",
    "Clustering is a useful technique for *unsupervised* learning. We are now going to cluster 2000 images in the fashion MNIST dataset, and try to understand if the clusters we obtain correspond to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that the code below assumes that the data has already been transformed as in the NN part of the notebook, so make sure to run the code for the transformation even if you do not complete the part on NN.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's consider only 2000 data points\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Cluster the points using the KMeans() and fit() functions (see the userguide for details). For Kmeans, set: n_clusters=10 as number of clusters; n_init=10 as the number of times the algorithm will be run with different centroid seeds; random_state = ID. You can use the default setting for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 10, n_init = 10, random_state = ID)#COMPLETE\n",
    "# ADD CODE\n",
    "predicted = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of clusters with true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Now compare the obtained clusters with the true labels, using the function sklearn.metrics.cluster.contingency_matrix() (see the userguide for details). The function prints a matrix $A$ such that entry $A_{i,j}$ is is the number of samples in true class $i$ and in predicted class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   4   2  55   6  23   0   0 118   0]\n",
      " [  0   0   1   3 173   4   0   0   8   0]\n",
      " [  0  78  52  58   0  16   0   0   1   3]\n",
      " [  0   1   4  14  94  11   0   0  39   0]\n",
      " [  0  39  90  32   3   2   0   0  34   2]\n",
      " [ 36   0   0   2   0 155   8  15   0   0]\n",
      " [  0  33  36  75   2  30   0   0  33   0]\n",
      " [156   0   0   0   0  28  27   3   0   0]\n",
      " [  7  17   2  15   0  13  73   0   2  75]\n",
      " [  9   0   0   0   0   7  62 108   1   0]]\n"
     ]
    }
   ],
   "source": [
    "# compute and print the contingency matrix for the true labels vs the clustering assignments\n",
    "#ADD CODE\n",
    "matrix = sklearn.metrics.cluster.contingency_matrix(y_train, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "Based on the matrix shown above, comment on the results of clustering in terms of adherence to the true labels.\n",
    "\n",
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "What I would expect is a diagonalized matrix with the highest values in the ith element of the column. In this case though, the values are scattered. Perhaps the true classes and predicted classes in the matrix are not ordered (e.g. index [1][1] of the matrix could represent the real class 1 but the predicted class 5) so this causes that the values are not diagonalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of k with silhoutte coefficient\n",
    "In many real applications it is unclear what is the correct value of $k$ to use. In practice one tries different values of $k$ and then uses some external score to choose a value of $k$. One such score is the silhoutte coefficient, that can be computed with metrics.silhouette_score(). See the definition of the silhoutte coefficient in the userguide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Compute the clustering for k=2,3,...,15 (other parameters as above) and print the silhoutte coefficient for each such clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhoutte coefficient for number of clusters=2: 0.19612756192080036\n",
      "Silhoutte coefficient for number of clusters=3: 0.1890178555805291\n",
      "Silhoutte coefficient for number of clusters=4: 0.18488895200730557\n",
      "Silhoutte coefficient for number of clusters=5: 0.1679785786657032\n",
      "Silhoutte coefficient for number of clusters=6: 0.15662039267770037\n",
      "Silhoutte coefficient for number of clusters=7: 0.16725443591210404\n",
      "Silhoutte coefficient for number of clusters=8: 0.15959125424877288\n",
      "Silhoutte coefficient for number of clusters=9: 0.16372468453788422\n",
      "Silhoutte coefficient for number of clusters=10: 0.14298055767580878\n",
      "Silhoutte coefficient for number of clusters=11: 0.14540400582919905\n",
      "Silhoutte coefficient for number of clusters=12: 0.13626122633471188\n",
      "Silhoutte coefficient for number of clusters=13: 0.1331638663565468\n",
      "Silhoutte coefficient for number of clusters=14: 0.12853434122614185\n",
      "Silhoutte coefficient for number of clusters=15: 0.12834644019518093\n"
     ]
    }
   ],
   "source": [
    "#run k-means with 10 choices of initial centroids for a range of values of n_clusters\n",
    "\n",
    "for i in range(2,16):\n",
    "    #ADD CODE\n",
    "    kmeans = KMeans(n_clusters=i, n_init = 10, random_state = ID)\n",
    "    kmeans.fit(X_train)\n",
    "    silhouttescore = metrics.silhouette_score(X_train, kmeans.labels_)#COMPLETE\n",
    "    print(\"Silhoutte coefficient for number of clusters=\"+str(i)+\": \"+str(silhouttescore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "\n",
    "Based on the silhoutte score, which $k$ would you pick? Motivate your choice. Does your choice match what you know about the data? If yes, explain why you think this is the case; if no, explain what you think may be the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ADD YOUR ANSWER HERE]\n",
    "\n",
    "I would choose the k = 2 cluster because it has the higher score. I think that the data are clustered in shoes and clothes. It's easier to cluster data into 2 macro-categories than having the clusters more specialized. The common way of thinking, as a human usually do, is to separate the data into clothes and shoes. When we trying to cluster the data in subcategories, we usually commit more errors. I think that also for the algorithm is easier to cluster only 2 categories of objects. For example shouse, boots, sandals are clustered in the shoes cluster, dresses, shirts, t-shirts etc are clustered in the clothes cluster. So that's the reason, in my opinion, why the silouhette scores higher the k=2 cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
